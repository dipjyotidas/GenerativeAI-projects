{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c75b205c-b82b-49ff-829f-52cca37915d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the Llama model 7B from Hugging Face repository and store the .bin file in a directory (around 3GB size requirement)\n",
    "# https://huggingface.co/TheBloke/LLaMa-7B-GGML/tree/main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6127461a-8f4d-4f32-8e22-72e3289f39c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If there is an error for installing llama-cpp-python below:\n",
    "# pip install llama-cpp-python\n",
    "# Error: could not build wheels for llama-cpp-python, which is required to install pyproject.toml-based projects\n",
    "# Download Visual Studio 2022 Build Tools\n",
    "# Check : https://github.com/imartinez/privateGPT/issues/445"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3f1da25-d07d-45f7-bc61-ac858ce857ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the dependencies\n",
    "from llama_cpp import Llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "624c0a40-d593-436f-92f2-9407c2295ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llama 7B model path\n",
    "llama_7B_model = \"C:/Users/Dipjyoti/Downloads/llama-7b.ggmlv3.q2_K.bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "391894f3-cc2f-481c-baca-402945c29f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | VSX = 0 | \n"
     ]
    }
   ],
   "source": [
    "# load your llm from the saved directory\n",
    "llm = Llama(model_path= llama_7B_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ecc9b3f-9d41-4d11-91b2-1dda609d8e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass a prompt to your llm\n",
    "response =llm(\"Who directed The Dark Knight?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41d8a7ed-17a0-4905-a631-9a1f66fac4c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Christopher Nolan is the director of both Batman Begins, starring Christian Bale, and its sequel, The Dark Knight. Other actors in the films include Maggie Gyllenhaal as Rachel Dawes, Gary Oldman as Lieutenant Gordon, and Michael Caine as Alfred Pennyworth, Bruce Wayne’s (Bale) butler/chauffeur.\n",
      "Who is in the movie “Pirates of the Caribbean: 3”?\n",
      "Who is in the movie “Transformers: Dark of the Moon”?\n"
     ]
    }
   ],
   "source": [
    "# Check the response\n",
    "print(response['choices'][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6ee3ab-5edf-444a-9e50-315b06d8ccb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# successfully executed our first LLM on the CPU, completely offline and in a fully randomized fashion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85933207-8e8f-42cf-a2f6-01d8be75a2c5",
   "metadata": {},
   "source": [
    "#### Getting Started with LLM — LangChain Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae0b647-d91a-413b-9497-b902d8953701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangChain framework to develop applications using LLMs\n",
    "# Prompt Engineering : prompt template. It is a reproducible way to generate a prompt. It contains a text string the template, \n",
    "# that can take in a set of parameters from the end user and generates a prompt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9227ff65-aaec-43a2-bfec-1de5ee549d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import PromptTemplate\n",
    "from langchain import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4fb83ff-7f2c-44b3-a01d-cd588aa258e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An example prompt with no input variables\n",
    "template=\"Tell me a joke\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8eb8d50f-98fb-431a-9040-929b5d3501f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create prompt from template\n",
    "prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91601ea9-4c90-4a18-9d0b-0415074c86df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=[], output_parser=None, partial_variables={}, template='Tell me a joke', template_format='f-string', validate_template=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check prompt variable\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88f08297-1dff-4e08-a34c-3e48e487d542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check input variables\n",
    "prompt.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01525160-0f13-4569-97a7-969d9f4f7bba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me a joke'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check prompt template\n",
    "prompt.template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bdfb19-7f31-452f-a41e-84c76c52e370",
   "metadata": {},
   "source": [
    "##### Example prompt with one input variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75e2211a-2b29-43d3-aeff-8366e2595254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['adjective'], output_parser=None, partial_variables={}, template='Tell me a {adjective} joke', template_format='f-string', validate_template=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a template\n",
    "template=\"Tell me a {adjective} joke\"\n",
    "#Create prompt from template\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "#Check prompt variable\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd993f16-9946-4ef6-b3c0-5e4ea53e105a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adjective']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check input variables\n",
    "prompt.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11530e87-55fa-45ec-a7a2-144315a5dde8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me a {adjective} joke'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check prompt template\n",
    "prompt.template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c3e64f7-c4b7-4879-aaa9-c677933b7142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me a funny joke'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Format the prompt\n",
    "formatted_prompt = prompt.format(adjective = \"funny\")\n",
    "formatted_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e15918-c1b0-49ac-8d66-f85ec2fbee88",
   "metadata": {},
   "source": [
    "##### Example prompt with multiple input variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2bc36e63-5c11-47e0-9452-b414954f5988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['adjective', 'content'], output_parser=None, partial_variables={}, template='Tell me a {adjective} joke about {content}', template_format='f-string', validate_template=True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a template\n",
    "template=\"Tell me a {adjective} joke about {content}\"\n",
    "#Create prompt from template\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "#Check prompt variable\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d6f3b56e-6a3d-4fc6-a31a-1ebfddc8dec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adjective', 'content']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check input variables\n",
    "prompt.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c1d89ac0-aaf7-43d9-8f05-33b613b4cc59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me a {adjective} joke about {content}'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check prompt template\n",
    "prompt.template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4133395f-1d33-4507-8843-4111c0548fc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me a funny joke about chickens'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Format the prompt\n",
    "formatted_prompt = prompt.format(adjective = \"funny\", content = \"chickens\")\n",
    "formatted_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ebc952-c616-4fc2-b3a9-15c0e2c11a4a",
   "metadata": {},
   "source": [
    "#### Prompt the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "681cad10-ab84-4f5c-a109-e8125c646c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the dependencies\n",
    "from langchain.llms import LlamaCpp\n",
    "from langchain import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8ab9784d-2809-421d-aeac-6b4f113d8dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | VSX = 0 | \n"
     ]
    }
   ],
   "source": [
    "# Import LLM\n",
    "llm = LlamaCpp(model_path= llama_7B_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9604c8ac-1315-4def-a464-3b137820f4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a template\n",
    "template = \"\"\"Q: Who directed {movie_name}\n",
    "Answer:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "071fa134-f16b-4f12-926f-8bf96089af99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create prompt from template\n",
    "prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "13da1215-5826-4aad-8458-583b39ca98dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['movie_name'], output_parser=None, partial_variables={}, template='Q: Who directed {movie_name}\\nAnswer:', template_format='f-string', validate_template=True)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check prompt variable\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4a67e47d-ca8f-4727-aebf-6a986c47e8ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['movie_name']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check input variables\n",
    "prompt.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d24362a4-0b3e-4485-b64c-c7da86284117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Q: Who directed {movie_name}\\nAnswer:'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check prompt template\n",
    "prompt.template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "19e35b91-e0c1-4262-88c4-da49f50860c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Q: Who directed The Dark Knight\\nAnswer:'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Format the prompt\n",
    "formatted_prompt = prompt.format(movie_name = \"The Dark Knight\")\n",
    "formatted_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d40e4207-b92e-4edd-98a6-d8af34256736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Christopher Nolan'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prompt the LLM\n",
    "llm(prompt = formatted_prompt, llm=llm, stop = [\"Q:\", \"\\n\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab76cb1b-2f14-45b3-8097-e4e0ed3cafad",
   "metadata": {},
   "source": [
    "So far we have used individual components. We took the prompt template formatted it, then took the llm, and then passed those params inside llm to generate the answer. Using an LLM in isolation is fine for simple applications, but more complex applications require chaining LLMs — either with each other or with other components."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9426781-df37-49e9-a7f0-a74aca12cdaf",
   "metadata": {},
   "source": [
    "LangChain provides the Chain interface for such chained 🔗applications. We define a Chain very generically as a sequence of calls to components, which can include other chains. Chains allow us to combine multiple components together to create a single, coherent application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6376f23-7a5d-4019-a0e2-e1fe194edf0b",
   "metadata": {},
   "source": [
    "For example, we can create a chain that takes user input, formats it with a Prompt Template, and then passes the formatted response to an LLM. We can build more complex chains by combining multiple chains together, or by combining chains with other components."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedef055-72aa-42c3-9c4b-9c2ac927203c",
   "metadata": {},
   "source": [
    "#### LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f17c4e3-240a-4d6f-820a-4de0b8706c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a very simple chain 🔗 that will take user input, format the prompt with it, and then send it to the LLM using the above \n",
    "# individual components that we’ve already created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eb6f9161-de6d-4622-a012-064ed253db2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['movie_name'], output_parser=None, partial_variables={}, template='Q: Who directed {movie_name}\\nAnswer:', template_format='f-string', validate_template=True)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "97c93e5b-3288-4d38-a8bb-0262edb3c2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the dependencies\n",
    "from langchain.chains import LLMChain\n",
    "# Define chain\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c7284afa-49a0-4c00-9e86-5964d7a31c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Christopher Nolan.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the chain only specifying the input variables\n",
    "llm_chain.run(\"The Dark Knight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370d63ce-045e-484d-8a99-ce4d6804b947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When dealing with multiple variables, we have the option to input them collectively by utilizing a dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0dd2af4-636e-484f-87df-aa7c15e915c0",
   "metadata": {},
   "source": [
    "#### Generating Embeddings and Vectorstore for Question Answering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11511821-093c-4779-abad-cc608abf1498",
   "metadata": {},
   "source": [
    "##### Loading & Transforming Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "af82d62e-8803-4eb8-a3be-adf7ef063f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the dependencies\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c06a181c-ba2b-4d18-9145-3712704dedc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Doc - a text file with wikipedia paragraphs of DC Superheroes\n",
    "loader = TextLoader(\"raw.txt\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6774e5d9-4434-4706-9c2c-6bcc02b3bdbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Batman does not possess any superpowers, instead relying on his intellect, fighting skills, and wealth.\\n\\nAs a baby, his parents sent him to Earth in a small spaceship shortly before Krypton was destroyed in a natural cataclysm. His ship landed in the American countryside near the fictional town of Smallville. He was found and adopted by farmers Jonathan and Martha Kent, who named him Clark Kent. \\n\\nIn her homeland, the island nation of Themyscira, her official title is Princess Diana of Themyscira. The character was being written as a very \"confident\", \"impulsive\" and \"good-hearted\" character in her. He referred to her trait of feeling compassion as both her strength and weakness.\\n\\nThis new Flash was Barry Allen, a police scientist who gained super-speed when bathed by chemicals after a shelf of them was struck by lightning. He adopted the name The Scarlet Speedster after reading a comic book featuring the Golden Age Flash.', metadata={'source': 'raw.txt'})]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "41b0df11-5dcd-44d3-a5b1-36a4ea75dd86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 103, which is longer than the specified 10\n",
      "Created a chunk of size 294, which is longer than the specified 10\n",
      "Created a chunk of size 287, which is longer than the specified 10\n"
     ]
    }
   ],
   "source": [
    "# Transform into chunks\n",
    "text_splitter = CharacterTextSplitter(chunk_size=10, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "957fc089-d889-4ce2-824c-d6ce14d23c53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare the size of doxs and texts\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f3a41895-7ea9-40e4-8d7e-a1664520103d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b7a60bcd-33e2-4f09-98c1-cbc4a7de76cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='Batman does not possess any superpowers, instead relying on his intellect, fighting skills, and wealth.\\n\\nAs a baby, his parents sent him to Earth in a small spaceship shortly before Krypton was destroyed in a natural cataclysm. His ship landed in the American countryside near the fictional town of Smallville. He was found and adopted by farmers Jonathan and Martha Kent, who named him Clark Kent. \\n\\nIn her homeland, the island nation of Themyscira, her official title is Princess Diana of Themyscira. The character was being written as a very \"confident\", \"impulsive\" and \"good-hearted\" character in her. He referred to her trait of feeling compassion as both her strength and weakness.\\n\\nThis new Flash was Barry Allen, a police scientist who gained super-speed when bathed by chemicals after a shelf of them was struck by lightning. He adopted the name The Scarlet Speedster after reading a comic book featuring the Golden Age Flash.', metadata={'source': 'raw.txt'})]\n"
     ]
    }
   ],
   "source": [
    "# visualize chunks and doc\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b83e643f-949c-4aee-9eed-4638bd39c4e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Batman does not possess any superpowers, instead relying on his intellect, fighting skills, and wealth.' metadata={'source': 'raw.txt'}\n"
     ]
    }
   ],
   "source": [
    "print(texts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746a306a-a7e6-484e-92fd-ed10e9f017fc",
   "metadata": {},
   "source": [
    "### Embeddiings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b2f43c-de17-47cd-a852-a3c1e0be8cc2",
   "metadata": {},
   "source": [
    "Word embedding is simply a vector representation of a word, with the vector containing real numbers. Since languages typically contain at least tens of thousands of words, simple binary word vectors can become impractical due to a high number of dimensions. Word embeddings solve this problem by providing dense representations of words in a low-dimensional vector space.\n",
    "\n",
    "When we talk about retrieval, we refer to retrieving a set of vectors that are most similar to a query in a form of a vector that is embedded in the same Latent space.\r\n",
    "\r\n",
    "The base Embeddings class in LangChain exposes two methods: one for embedding documents and one for embedding a query. The former takes as input multiple texts, while the latter takes a single text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "348c53aa-209f-4d2c-bf34-85bf825fe312",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | VSX = 0 | \n"
     ]
    }
   ],
   "source": [
    "# Import Depednencies\n",
    "from langchain.embeddings import LlamaCppEmbeddings\n",
    "embeddings = LlamaCppEmbeddings(model_path=llama_7B_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "82840822-b86b-4750-a0a7-69ed6db06403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert lancgchain doc to str\n",
    "_texts = []\n",
    "for i in range(len(texts)):\n",
    "    _texts.append(texts[i].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e1a76407-5227-4b07-ba80-44f5f515ee84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Batman does not possess any superpowers, instead relying on his intellect, fighting skills, and wealth.', metadata={'source': 'raw.txt'})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize\n",
    "texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cdb5ef6c-885b-4d3b-85f5-b5e318c725ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Batman does not possess any superpowers, instead relying on his intellect, fighting skills, and wealth.'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cf29ab2a-8732-43a0-83a8-335b42b370cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed list of texts\n",
    "embedded_texts = embeddings.embed_documents(_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4370f869-c250-451f-ba4e-6613f972903e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 4096)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedded_texts), len(embedded_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d7cb5cd3-8cc8-42be-b9a0-4ee6fb2c89a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5122052431106567,\n",
       " 0.07216522097587585,\n",
       " -1.0619093179702759,\n",
       " -2.156808614730835]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualize embedding\n",
    "embedded_texts[0][:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "91f50e2d-5bd2-46a3-8aea-be304564fbf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4096"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Embed query\n",
    "query = \"What skills did Batman has?\"\n",
    "embedded_query = embeddings.embed_query(query)\n",
    "len(embedded_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "03f69729-deb5-401a-894c-55e5ba748455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.7351198196411133,\n",
       " -0.13924887776374817,\n",
       " -0.7899298071861267,\n",
       " -2.5887067317962646]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_query[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad752dbb-dab6-43c1-b28a-8e0404a5587a",
   "metadata": {},
   "source": [
    "#### Creating Vector Store & Retrieving Docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafb7aab-c22a-4399-af1b-ac7fc772c7e2",
   "metadata": {},
   "source": [
    "A vector store efficiently manages the storage of embedded data and facilitates vector search operations on your behalf. Embedding and storing the resulting embedding vectors is a prevalent method for storing and searching unstructured data. During query time, the unstructured query is also embedded, and the embedding vectors that exhibit the highest similarity to the embedded query are retrieved. This approach enables effective retrieval of relevant information from the vector store."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e085f51e-de96-446a-bcfe-3d8e86537edf",
   "metadata": {},
   "source": [
    "##### Use Chroma, an embedding database and vector store specifically crafted to simplify the development of AI applications incorporating embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d8c086d8-db24-492b-85bc-753de9757319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies\n",
    "from langchain.vectorstores import Chroma\n",
    "# Create a Chroma vectorstore from a list of documents\n",
    "db = Chroma.from_documents(texts, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d8c75942-e76a-4630-b82c-a0a74112cceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='This new Flash was Barry Allen, a police scientist who gained super-speed when bathed by chemicals after a shelf of them was struck by lightning. He adopted the name The Scarlet Speedster after reading a comic book featuring the Golden Age Flash.', metadata={'source': 'raw.txt'})]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform similarity search with the query over db\n",
    "query = \"Who is an orphan here\"\n",
    "docs = db.similarity_search(query, k=1)\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2b1259e0-3895-4a70-8201-5a5061b409d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='This new Flash was Barry Allen, a police scientist who gained super-speed when bathed by chemicals after a shelf of them was struck by lightning. He adopted the name The Scarlet Speedster after reading a comic book featuring the Golden Age Flash.', metadata={'source': 'raw.txt'})]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Search for documents using query vector\n",
    "query = \"Who is an orphan here\"\n",
    "query_vector = embeddings.embed_query(query)\n",
    "docs = db.similarity_search_by_vector(query_vector, k=1)\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdff5c0e-0b59-4e78-9fc1-91a499ee616e",
   "metadata": {},
   "source": [
    "### Question Answering bot with LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e8aa944f-6536-40bf-a7ed-88f162444fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ee0c6555-9bbd-4eba-be97-81a38d5ca304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Craft a prompt template that works best for your LLM\n",
    "\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "{context}\n",
    "Question: {question}\n",
    "Answer:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "edafc57f-a6bf-431e-8f2e-f9bc01d3c931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['context', 'question']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# context will be the similar doc and question will be query\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "prompt.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "448cfab0-ed05-4bf7-977e-0d990f39489b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare context from query\n",
    "query = \"Who is an orphan here?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "68a4218f-1608-4cf1-80da-7d45d93f5d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In her homeland, the island nation of Themyscira, her official title is Princess Diana of Themyscira. The character was being written as a very \"confident\", \"impulsive\" and \"good-hearted\" character in her. He referred to her trait of feeling compassion as both her strength and weakness.\n"
     ]
    }
   ],
   "source": [
    "similar_doc = db.similarity_search(query, k=1)\n",
    "context = similar_doc[0].page_content\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "74584d50-a6d5-47d3-9d6d-47cd527ea2cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Wonder Woman (Diana Prince)\n",
      "Post by: 20ofcourse on December 31, 2018, 05:40:16 PM\n",
      "I believe that one was a question in a previous thread...\n",
      "In his homeland, the island nation of Atlantis, he is known as Arthur Curry, a part-time police officer with the ability to \"speak\" (and think) through telepathy. The character was created by writer Robert Bernstein and artist Ramona Fradguson.\n",
      "Post by: 20ofcourse on January 18, 2019, 07:56:34 PM\n",
      "While the first Aquaman is in the golden age, the second one is part of the silver age. The first being in the 1940s and the second in the 1950s\n",
      "Answer: Arthur Curry (Aquaman)\n",
      "Post by: 20ofcourse on January 19, 2019, 06:35:28 AM\n",
      "While the first Superman is in the golden age, the second one is part of the silver age.\n"
     ]
    }
   ],
   "source": [
    "# Use LLM to Generate Answer from the context\n",
    "query_llm = LLMChain(llm=llm, prompt=prompt)\n",
    "response = query_llm.run({\"context\": context, \"question\": query})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f4cbdd-f14a-4623-8051-41f3c289f95e",
   "metadata": {},
   "source": [
    "#### End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
