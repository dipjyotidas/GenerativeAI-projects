{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57ce086e-5bd2-42f2-8443-ce05d737338e",
   "metadata": {},
   "source": [
    "#### Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6a3e83-962d-45f4-ab75-245ecc1c5b02",
   "metadata": {},
   "source": [
    "Very closely related to the concept of Chains, Agents are also used to execute multiple steps using an LLM. A major difference being the way multiple actions are executed by Chains and Agents. In case of Agents, the backend uses an LLM to decide over what action to take (of all options/tools available), hence flexible while in case of Chains, a hardcoded sequence of steps are taken. Also, agents are more diverse and can integrate with multiple, different tools."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f4f782-1b6c-4db2-b42e-4ce91df3cafa",
   "metadata": {},
   "source": [
    "You have an agent that has access to\n",
    "* Google search\n",
    "* Maths-Calculator\n",
    "* A retriever for some external document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad816e06-76f3-4c96-a3c2-4cf7a8d99cb3",
   "metadata": {},
   "source": [
    "* When you run a query, the LLM will decide which tool to use depending on the query or maybe it won’t use any tool if the query doesn’t require it like ‘Hello LLM’. But in case of a chain,\n",
    "\n",
    "* You might not be able to provide multiple, diverse functionality with pre-defined chains in Langchain.\n",
    "\n",
    "* Even if you do, you need to hardcode the whole code and sequence of steps. So even if the query don’t require any tool, it will use it (& may throw an error as well due to lack of compatibility). Hence no flexibility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecb09a5-eda3-4e3e-92d5-94f08161fe74",
   "metadata": {},
   "source": [
    "* So, if you want a more flexible, dynamic app, Agents are a better option but if your use case is constant, chains can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b2fb71-ea2c-4047-b987-f4a309036fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent is like a Chatbot which can do specific tasks, they can interact with api, tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d9b74f-ca56-48e0-bc7c-1b8239f1b745",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain openai google-search-result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fea612d-4f32-45b4-b863-cd2bc2e9c008",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import Tool\n",
    "from langchain.agents import AgentType\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.utilities import SerpAPIWrapper\n",
    "from langchain.agents import initialize_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86423f4a-7ebc-4842-82c1-47e7cfefb076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your API key : https://platform.openai.com/account/api-keys\n",
    "# store the API key in Environment variable : https://networkdirection.net/python/resources/env-variable/\n",
    "import os\n",
    "api_key = os.environ.get('OpenAI_API_Key')\n",
    "serp_key = os.environ.get('serp_api')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "286ce403-b90d-48a5-941e-a4547ab9d91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#You need to get serp_api and openai_api for this.\n",
    "search = SerpAPIWrapper(serpapi_api_key=serp_key)\n",
    "llm=OpenAI(openai_api_key=api_key)\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name = \"Current Search\",\n",
    "        func=search.run,\n",
    "        description=\"useful for when you need to answer questions about current events or the current state of the world\"\n",
    "\n",
    "    ),]\n",
    "search_me = \"Explain what happend in G20 meeting, 2023 that happened in Delhi?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6312443-9f28-487c-b6d4-be4173e3580e",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_chain = initialize_agent(tools, llm, agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4fe2eef3-5ab9-4340-8781-8a8d3cc87b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': 'Explain what happend in G20 meeting, 2023 that happened in Delhi?', 'chat_history': [], 'output': 'The G20 meeting in 2023, which was held in Delhi, India, was focused on the global economic recovery and strengthening international cooperation. It was attended by the heads of states from the G20 countries, as well as representatives of international organizations. The meeting discussed issues related to climate change, global trade, and the digital economy, as well as other topics of global importance. The participants also agreed on a new framework for global financial regulation.'}\n"
     ]
    }
   ],
   "source": [
    "out = agent_chain({\"input\": search_me, \"chat_history\": []})\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c127c8-c678-4a91-8020-dcd25cf9334e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# refer : https://github.com/langchain-ai/langchain/issues/3106"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f52aba-985f-47bf-92fd-3bcd4384a93e",
   "metadata": {},
   "source": [
    "#### How to build Langchain agents?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1578f608-1532-4e6d-a4c7-244064f7b9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second example: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73dd124-df85-4f15-96ab-14460084ef87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install langchain openai arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd600adf-986d-4cd5-8113-d3f4ebcdc9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import Tool, ZeroShotAgent, AgentExecutor\n",
    "from langchain import OpenAI, LLMChain \n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.tools.arxiv.tool import ArxivQueryRun\n",
    "from langchain.tools.shell.tool import ShellTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27c1914c-a052-46f7-8c97-e2a10a4e2d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain.tools as lt\n",
    "#help(lt) # langchain different packages\n",
    "# if we create an agent it can interact with all the tools below to do specific tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0ad406-2be3-4820-aa1e-c75ddb25617e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# arxiv : what is happening around latest research papers, arxiv query run tool\n",
    "# shell tool : will be doing it in a shell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c67be5b8-73c5-4c69-aa3c-398cc6538c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tool list\n",
    "# we can use multiple tools for multiple tasks\n",
    "papers = ArxivQueryRun()\n",
    "shell = ShellTool()\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"papers\",\n",
    "        func=papers.run,\n",
    "        description=\"useful for when you need to answer about research paper\",\n",
    "\n",
    "        ),\n",
    "    Tool(\n",
    "        name=\"shell\",\n",
    "        func=shell.run,\n",
    "        description =\"useful for shell scripting and related stuff\",\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc62f7e2-a8b6-414e-a095-d9d11d0a9c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Designing a prompt\n",
    "prefix = \"\"\"Have a conversation with a human, answering the following questions as best you can. You have access to the following tools: \"\"\"\n",
    "suffix = \"\"\"Begin!\"\n",
    "\n",
    "{chat_history}\n",
    "Question: {input}\n",
    "{agent_scratchpad}\"\"\"\n",
    "\n",
    "# chat_history : is to provide memory to the agent \n",
    "# input : prompt\n",
    "# agent scratchpad : what the agent is actually doing in the background\n",
    "prompt = ZeroShotAgent.create_prompt(\n",
    "    tools,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=[\"input\", \"chat_history\", \"agent_scratchpad\"],\n",
    "\n",
    ")\n",
    "# ZeroShotAgent : agent which has no examples to learn from the particular tools\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "# provide chat history to the agent, it will remember the response of the previous questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c308c50-6461-495a-bbef-07f037105809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a LLM agent:\n",
    "llm_chain = LLMChain(llm=OpenAI(temperature=0, openai_api_key=api_key), prompt=prompt)\n",
    "agent = ZeroShotAgent(llm_chain=llm_chain, tools=tools, verbose=True)\n",
    "# creating a final chain:\n",
    "agent_chain = AgentExecutor.from_agent_and_tools(\n",
    "    agent= agent, tools=tools, verbose = True, memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "78e5e5de-38b5-4979-bf18-202c7e6992e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I should research the latest developments in LLMs.\n",
      "Action: papers\n",
      "Action Input: Latest developments in LLMs\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mPublished: 2023-10-09\n",
      "Title: A Survey of Large Language Models for Healthcare: from Data, Technology, and Applications to Accountability and Ethics\n",
      "Authors: Kai He, Rui Mao, Qika Lin, Yucheng Ruan, Xiang Lan, Mengling Feng, Erik Cambria\n",
      "Summary: The utilization of large language models (LLMs) in the Healthcare domain has\n",
      "generated both excitement and concern due to their ability to effectively\n",
      "respond to freetext queries with certain professional knowledge. This survey\n",
      "outlines the capabilities of the currently developed LLMs for Healthcare and\n",
      "explicates their development process, with the aim of providing an overview of\n",
      "the development roadmap from traditional Pretrained Language Models (PLMs) to\n",
      "LLMs. Specifically, we first explore the potential of LLMs to enhance the\n",
      "efficiency and effectiveness of various Healthcare applications highlighting\n",
      "both the strengths and limitations. Secondly, we conduct a comparison between\n",
      "the previous PLMs and the latest LLMs, as well as comparing various LLMs with\n",
      "each other. Then we summarize related Healthcare training data, training\n",
      "methods, optimization strategies, and usage. Finally, the unique concerns\n",
      "associated with deploying LLMs in Healthcare settings are investigated,\n",
      "particularly regarding fairness, accountability, transparency and ethics. Our\n",
      "survey provide a comprehensive investigation from perspectives of both computer\n",
      "science and Healthcare specialty. Besides the discussion about Healthcare\n",
      "concerns, we supports the computer science community by compiling a collection\n",
      "of open source resources, such as accessible datasets, the latest\n",
      "methodologies, code implementations, and evaluation benchmarks in the Github.\n",
      "Summarily, we contend that a significant paradigm shift is underway,\n",
      "transitioning from PLMs to LLMs. This shift encompasses a move from\n",
      "discriminative AI approaches to generative AI approaches, as well as a shift\n",
      "from model-centered methodologies to datacentered methodologies.\n",
      "\n",
      "Published: 2023-09-20\n",
      "Title: Safurai 001: New Qualitative Approach for Code LLM Evaluation\n",
      "Authors: Davide Cifarelli, Leonardo Boiardi, Alessandro Puppo\n",
      "Summary: This paper presents Safurai-001, a new Large Language Model (LLM) with\n",
      "significant potential in the domain of coding assistance. Driven by recent\n",
      "advancements in coding LLMs, Safurai-001 competes in performance with the\n",
      "latest models like WizardCoder [Xu et al., 2023], PanguCoder [Shen et al.,\n",
      "2023] and Phi-1 [Gunasekar et al., 2023] but aims to deliver a more\n",
      "conversational interaction. By capitalizing on the progress in data engineering\n",
      "(including latest techniques of data transformation and prompt engineering) and\n",
      "instruction tuning, this new model promises to stand toe-to-toe with recent\n",
      "closed and open source developments. Recognizing the need for an efficacious\n",
      "evaluation metric for coding LLMs, this paper also introduces GPT4-based\n",
      "MultiParameters, an evaluation benchmark that harnesses varied parameters to\n",
      "present a comprehensive insight into the models functioning and performance.\n",
      "Our assessment shows that Safurai-001 can outperform GPT-3.5 by 1.58% and\n",
      "WizardCoder by 18.78% in the Code Readability parameter and more.\n",
      "\n",
      "Published: 2023-09-07\n",
      "Title: Enhancing Pipeline-Based Conversational Agents with Large Language Models\n",
      "Authors: Mina Foosherian, Hendrik Purwins, Purna Rathnayake, Touhidul Alam, Rui Teimao, Klaus-Dieter Thoben\n",
      "Summary: The latest advancements in AI and deep learning have led to a breakthrough in\n",
      "large language model (LLM)-based agents such as GPT-4. However, many commercial\n",
      "conversational agent development tools are pipeline-based and have limitations\n",
      "in holding a human-like conversation. This paper investigates the capabilities\n",
      "of LLMs to enhance pipeline-based conversational agents during two phases: 1)\n",
      "in the design and development phase and 2) during operations. In 1) LLMs can\n",
      "aid in generating training data, extracting entities and synonyms,\n",
      "localization, and persona design. In 2) LLMs can assist in contextu\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: The latest developments in LLMs include a survey of large language models for healthcare, a new qualitative approach for code LLM evaluation, and enhancing pipeline-based conversational agents with large language models.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The latest developments in LLMs include a survey of large language models for healthcare, a new qualitative approach for code LLM evaluation, and enhancing pipeline-based conversational agents with large language models.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_chain.run(input=\"Suggest the latest developments around LLMs?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6980c1-756f-4735-995a-39be8cd4911f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we won't get an answer like this if we use ChatGpt 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83da7239-9bd6-4424-8561-ecae81a62674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the shell tool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e3ceae2b-0b87-4285-af15-6feae0d1b453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to find the code to print 'Hello World' and execute hello.py\n",
      "Action: shell\n",
      "Action Input: echo \"print('Hello World')\" > hello.py followed by python hello.py\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: echo \"print('Hello World')\" > hello.py followed by python hello.py\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'echo \"print(\\'Hello World\\')\" > hello.py followed by python hello.py'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_chain.run(input= \" code to print 'hello world' and execute hello.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81259dd-7330-4d67-9a22-91b98ba0ee8b",
   "metadata": {},
   "source": [
    "#### How to create Custom tools for Langchain Agent ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aefd23a-6db0-427b-aa4a-3e7b30c6f6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install langchain openai langchain-experimental yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f9827cb-3a45-40bd-bf47-1768fd2f8c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "babf752b-9ed7-44c4-abf4-d3cc1d60b8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_stock_price(ticker):\n",
    "    \n",
    "    \"\"\"Method to get current stock price\"\"\"\n",
    "\n",
    "    ticker_data = yf.Ticker(ticker)\n",
    "    recent = ticker_data.history(period=\"1d\")\n",
    "    return {\"price\": recent.iloc[0][\"Close\"], \"currency\": ticker_data.info[\"currency\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "760a1f99-c01b-452d-a7b9-9ad14cb73974",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stock_performance(ticker, days):\n",
    "    \"\"\"Method to get stock price change in percentage\"\"\"\n",
    "    past_date = datetime.today() - timedelta(days=days)\n",
    "    ticker_data = yf.Ticker(ticker)\n",
    "    history = ticker_data.history(start=past_date)\n",
    "    old_price = history.iloc[0][\"Close\"]\n",
    "    current_price = history.iloc[-1][\"Close\"]\n",
    "    return {\"percent_change\" : ((current_price - old_price)/ old_price) * 100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ef8bdee-da78-49b5-b0fb-70194dad7010",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Type\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.tools import BaseTool\n",
    "# for the tool we need two classes - input for the particular tool\n",
    "\n",
    "class CurrentStockPriceInput(BaseModel):\n",
    "    \"\"\"Inputs for get_current_stock_price\"\"\"\n",
    "    ticker: str = Field(description=\"Ticker symbol of the stock\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "289fbef8-1f4e-4902-889f-c8905f36d28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CurrentStockPriceTool(BaseTool):\n",
    "    # inheriting BaseTool which is coming from langchain.tools. So, we are not using an existing tool with LangChain, we are using custom tool\n",
    "    name = \"get_current_stock_price\"\n",
    "    description = \"\"\"\n",
    "        Useful when you want to get current stock price.\n",
    "        You should enter the stock ticker symbol recognized by the yahoo finance\n",
    "        \"\"\"\n",
    "    args_schema: Type[BaseModel] = CurrentStockPriceInput\n",
    "\n",
    "    def _run(self, ticker: str):\n",
    "        price_response = get_current_stock_price(ticker)\n",
    "        return price_response\n",
    "    \n",
    "    def _arun(self, ticker: str):\n",
    "        raise NotImplementedError(\"get_current_stock_price does not support async\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ccfcd79-bc91-47ee-927e-21b7a18ecb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StockPercentChangeInput(BaseModel):\n",
    "    \"\"\"Inputs for get_stock_performance\"\"\"\n",
    "    ticker: str = Field(description=\"Ticker symbol of the stock\")\n",
    "    days: int = Field(description=\"Timedelta days to get past date from current date\")\n",
    "\n",
    "class StockPerformanceTool(BaseTool):\n",
    "    name=\"get_stock_performance\"\"\"\n",
    "    description = \"\"\"\n",
    "        Useful when you want to check performance of the stock.\n",
    "        You should enter the stock ticker symbol recognized by the yahoo finance.\n",
    "        You should enter days as number of days from today from which performance needs to be checked. \n",
    "        output will be the change in the stock price represented as a percentage.\n",
    "        \"\"\"\n",
    "    args_schema: Type[BaseModel] = StockPercentChangeInput\n",
    "\n",
    "    def _run(self, ticker: str, days: int):\n",
    "        response = get_stock_performance(ticker,days)\n",
    "        return response\n",
    "        \n",
    "    def _arun(self, ticker: str):\n",
    "        raise NotImplementedError(\"get_stock_performance does not support async\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4123391c-9a7f-43a4-8d16-e11a6115fec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentType\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.agents import initialize_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "303cc94b-8794-48ab-a420-3562e985a655",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(openai_api_key=api_key)\n",
    "#using the custom tools\n",
    "tools = [CurrentStockPriceTool(), StockPerformanceTool()]\n",
    "agent = initialize_agent(tools, llm, agent=AgentType.OPENAI_FUNCTIONS, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ae36362-9714-45d2-8e96-a3ced414dae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `get_current_stock_price` with `{'ticker': 'MSFT'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m{'price': 329.32000732421875, 'currency': 'USD'}\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `get_stock_performance` with `{'ticker': 'MSFT', 'days': 180}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m{'percent_change': 11.974368403663815}\u001b[0m\u001b[32;1m\u001b[1;3mThe current price of Microsoft stock is $329.32 USD. \n",
      "\n",
      "Over the past 6 months, Microsoft stock has performed well with a 11.97% increase in its price.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The current price of Microsoft stock is $329.32 USD. \\n\\nOver the past 6 months, Microsoft stock has performed well with a 11.97% increase in its price.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"What is the current price of Microsoft stock? How it has performed over past 6 months?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130792f9-668d-459e-ad0e-66043c63f072",
   "metadata": {},
   "source": [
    "#### Callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007e2f0b-56a1-4ec6-b804-a28262a2e3b7",
   "metadata": {},
   "source": [
    "LangChain offers a callback system enabling us to integrate with different phases of our Language Model application, serving purposes such as logging, monitoring, streaming, and other essential functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ab75c47-83fa-4668-8094-b8cd4dca5dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks import StdOutCallbackHandler\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b8f9b70-3be3-412e-bf50-3f2462f4441c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code snippet explains how to log every event using the Standard Output callback\n",
    "handler = StdOutCallbackHandler()\n",
    "llm = OpenAI()\n",
    "prompt = PromptTemplate.from_template(\"Write {number} lines about {animal} \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "819ca3d6-0007-47fa-83f4-b10619f8d4bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite 3 lines about tiger \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\n1. Tigers are the biggest species of cats in the world. \\n2. They are native to Asia and are known for their striped coats. \\n3. Tigers are apex predators, relying on their strength and power to hunt and survive.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Constructor callback: First, let's explicitly set the StdOutCallbackHandler when initializing our chain\n",
    "chain = LLMChain(llm=llm, prompt=prompt, callbacks=[handler])\n",
    "chain.run(number=3,animal='tiger')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa78eec2-78b2-4840-9a50-4a9c945e46ef",
   "metadata": {},
   "source": [
    "#### End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
