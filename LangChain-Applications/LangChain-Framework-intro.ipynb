{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c957545e-be63-4737-b7d3-a94b8bd1cf46",
   "metadata": {},
   "source": [
    "### Models (LLM and ChatModel)\n",
    "* How to use LLMs for real world problems, for which Langchain provide a framework to implement different usecases.\n",
    "* Langchain provides two types of models\n",
    "\n",
    "#### LLMs: \n",
    "Such models are similar to what general LLM models which can be used for any purpose. The prompt is a string/string-template as we interact with ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d1d551d-e369-41a6-a166-8b5e3b74e1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your API key : https://platform.openai.com/account/api-keys\n",
    "# store the API key in Environment variable : https://networkdirection.net/python/resources/env-variable/\n",
    "import os\n",
    "API_KEY = os.environ.get('OpenAI_API_Key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfd2fd14-a415-4f25-abfc-3826b1ee9364",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI(openai_api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "275dc859-b6f0-47fe-8ef8-662bc2f392ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nAI is projected to have a monumental impact on the world. It is likely to change the way we live, work, and interact with each other. AI is being used to automate mundane tasks, create personalized services, and create new ways to interact with our environment. AI is providing ways to make decisions more quickly and accurately, and to automate complex processes. AI is being used to automate medical diagnostics, improve agricultural yields, and even to develop new medicines. AI is also being used to improve customer service, automate financial transactions, and even to control self-driving cars. AI is also being used to analyze large amounts of data to identify patterns, predict outcomes, and make better decisions. As AI continues to develop, it will be used to create even more innovative solutions and services that will revolutionize our lives.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(\"Explain how AI wil change the world\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a82b69-d314-45f2-82b8-4c0cee6c3a3e",
   "metadata": {},
   "source": [
    "#### ChatModels: \n",
    "Using LLMs under the hood, these models are specific to chatbots and has three major components\n",
    "\n",
    "* HumanMessage : The prompt given by the user\n",
    "\n",
    "* AIMessage : The response given by the LLM\n",
    "\n",
    "* SystemMessage: Its a context that we can pass to the chatmodel about its role."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57db3c07-cf30-4bbd-b15c-e3b52c6e527f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage,SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba419bec-9ead-4792-b12c-2978de7af9bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Yes.', additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [SystemMessage(\n",
    "content=\"You are a Grammar Teacher who responds Yes for correct Grammar input\"),\n",
    "HumanMessage(content=\"I love, programming.\")]\n",
    "\n",
    "chat = ChatOpenAI(openai_api_key=API_KEY)\n",
    "chat(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77773e64-0a34-4206-a469-8da904da1b8b",
   "metadata": {},
   "source": [
    "#### Prompt Templates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19c01e7-f460-48c2-a5b3-3b663113f711",
   "metadata": {},
   "source": [
    "How to make this prompt more customizable ? There are predefined templates for prompts for an LLM so that we don’t need to write any prompt from scratch. But these prompts have different types\n",
    "\n",
    "* PromptTemplate : This is used to create a prompt from string input. This can be considered as the baseline version of templates where we can pass a variable or simply write a whole prompt as required. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "48179216-294e-47db-8a10-2417c9c5db7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Write 5 lines about Australia'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"Write {lines} lines about {topic}\"\n",
    ")\n",
    "prompt_template.format(lines=\"5\", topic=\"Australia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8af9f50f-4182-4880-8f33-5ee9877bbcf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Write 5 lines about Australia'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Or\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"Write 5 lines about Australia\"\n",
    ")\n",
    "prompt_template.format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffd19595-42d0-404c-8e7d-e61287664f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "# app : to check grammar for an English sentence\n",
    "template = \"\"\"You are a English Teacher. The user will provide a English sentence as input.\n",
    "Output Correct if it is grammatically right else output Wrong and rewrite the sentence in the next line\"\"\"\n",
    "\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(template) # what this app is all about\n",
    "human_template = \"{text}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d09aafc-3b3b-468f-aef9-7d1571fcbb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain object:\n",
    "chain = LLMChain(\n",
    "    llm=ChatOpenAI(openai_api_key=API_KEY, max_retries=3),\n",
    "    prompt=chat_prompt\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e7b73f2-ad54-4fb8-ad36-0fec76bb344e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 1 Wrong.\n",
      "You're saying \"Get out house my you!\" but the correct sentence should be \"Get out of my house!\"\n",
      "\n",
      "Prompt 2 Correct\n"
     ]
    }
   ],
   "source": [
    "print('Prompt 1',chain.run(\"Get out house my you !\"))\n",
    "print('\\nPrompt 2',chain.run(\"You're beautiful\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15575318-2cc7-4aa3-bdd4-7db1228bcc2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt 3 Correct\n",
      "\n",
      "Prompt 4 Wrong\n",
      "He has done this task.\n"
     ]
    }
   ],
   "source": [
    "# wait for 60s if you see RateLimitError\n",
    "print('\\nPrompt 3',chain.run(\"I love my parents\"))\n",
    "print('\\nPrompt 4',chain.run(\"He have done this task\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e63a52-241f-4b8f-83b2-a96b73106db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# App : Changing the tone of the input sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b998d3f8-de41-4747-b79e-b297fdb32681",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "#the imports remain the same\n",
    "template = \"You are a helpful assistant that rewrite the input text according to the {tone} passed.\"\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
    "human_template = \"{text}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=ChatOpenAI(openai_api_key=API_KEY, max_retries=3),\n",
    "    prompt=chat_prompt\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64d1e16b-79ae-4bd7-bb4c-aac8e303dbab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am a boy.\n",
      "He is adorable.\n"
     ]
    }
   ],
   "source": [
    "# two variables : text and tone\n",
    "print(chain.run({'text':'I am a boy','tone':'angry'}))\n",
    "print(chain.run({'text':'He is cute','tone':'sweet'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00c2fae7-f016-4457-9cde-7c32b971e2ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry to hear that his friend passed away.\n",
      "I deeply regret kicking his friend Adam.\n"
     ]
    }
   ],
   "source": [
    "# wait for 60s if you see RateLimitError\n",
    "print(chain.run({'text':'His friend died','tone':'regretful'}))\n",
    "print(chain.run({'text':'I kicked his friend Adam','tone':'regretful'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b017d3-0b59-4c8b-bf79-5edfaafe314e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# App : for language translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "94609c6d-c463-41d6-8809-1b348e674945",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "#imports remain the same\n",
    "from langchain.schema import BaseOutputParser\n",
    "class CommaSeparatedListOutputParser(BaseOutputParser):\n",
    "    \"\"\"Parse the output of an LLM call to a comma-separated list.\"\"\"\n",
    "    def parse(self, text: str):\n",
    "        \"\"\"Parse the output of an LLM call.\"\"\"\n",
    "        return text.strip().split(\", \")\n",
    "\n",
    "template = \"You are a helpful assistant that translates input text to {output_language}. Separate the outputs for each language by comma.\"\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
    "human_template = \"{text}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=ChatOpenAI(openai_api_key=API_KEY, max_retries=3), #request_timeout=200\n",
    "    prompt=chat_prompt,\n",
    "    output_parser=CommaSeparatedListOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bdd1b631-0320-4770-8de1-27c8222fee3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['मैं एक लड़का हूँ', 'Io sono un ragazzo.']\n",
      "['Je suis un garçon', 'Ich bin ein Junge']\n"
     ]
    }
   ],
   "source": [
    "print(chain.run({'text':'I am a boy','input_language':'english','output_language':'hindi,italian'}))\n",
    "print(chain.run({'text':'I am a boy','input_language':'english','output_language':'French,German'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc2d383c-81fa-4857-92ef-fdd3a342b110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['أنا صبي']\n",
      "['अहम् बालकः', 'हम छौरा बा']\n"
     ]
    }
   ],
   "source": [
    "print(chain.run({'text':'I am a boy','input_language':'english','output_language':'Arabic'}))\n",
    "print(chain.run({'text':'I am a boy','input_language':'english','output_language':'Sanskrit, bhojpuri'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780f78eb-425d-49cb-85cf-6412eae9e062",
   "metadata": {},
   "source": [
    "#### ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a12e0d-8082-42d1-bd8a-cdf429f26de6",
   "metadata": {},
   "source": [
    "ChatPromptTemplate are for ChatModels for customizing prompts for ChatModels, similar to what PromptTemplate are for LLM models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d18fbd66-2a3e-498f-a0f1-b93f1b3e8fe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Sure! I can help you with that. Here\\'s a Python function that checks whether a number is prime or not:\\n\\n```python\\ndef is_prime(n):\\n    if n <= 1:\\n        return False\\n\\n    for i in range(2, int(n**0.5) + 1):\\n        if n % i == 0:\\n            return False\\n\\n    return True\\n```\\n\\nYou can now call this function and pass in the number you want to check. It will return `True` if the number is prime, and `False` otherwise.\\n\\nFor example:\\n\\n```python\\nnum = 17\\nif is_prime(num):\\n    print(f\"{num} is prime\")\\nelse:\\n    print(f\"{num} is not prime\")\\n```\\n\\nOutput:\\n```\\n17 is prime\\n```\\n\\nLet me know if you need any further assistance!', additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.prompts.chat import SystemMessage, HumanMessagePromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content=(\"You are a python coder AI that helps user with bugs and writing programs\")),\n",
    "        HumanMessagePromptTemplate.from_template(\"{text}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(openai_api_key=API_KEY, max_retries=3)\n",
    "llm(template.format_messages(text='Check whether a number is prime or not'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcc3bbe-ad4a-4e78-ad32-00e4cec647c4",
   "metadata": {},
   "source": [
    "* As we had 3 roles in ChatModels, we have 3 roles in this ChatPromptTemplate also: system, ai & human."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90cddee3-2940-490a-8202-2789cde5dbb9",
   "metadata": {},
   "source": [
    "* Similar to PromptTemplate, we can pass variables in the template to customize the prompt according to different usecases. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d184f66-d9c4-4d61-921e-1edc471016f2",
   "metadata": {},
   "source": [
    "#### Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0884a6-8f87-40b0-ab2d-df363300c9e2",
   "metadata": {},
   "source": [
    "The above example were side features of Langchain. The most crucial feature is Chains. So what actually are chains?\n",
    "\n",
    "They can be taken as programs written around LLMs that can perform specific tasks. Internally in backend, Chains are nothing but chaining multiple LLMs together or with other elements like some 3rd Party tool integrations. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fa3156-7cd8-4988-8564-17dbf56a43b7",
   "metadata": {},
   "source": [
    "#### Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb1584e-8c2e-48eb-87be-ccd27d413a01",
   "metadata": {},
   "source": [
    "When we interacted with ChatGPT, we have noticed it has a memory and we can ask questions based on previous questions or answers in the conversation. How to add this memory to an LLM?\n",
    "* Add a memory to the agent using LangChain so that the bot rememebers the memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d555f14b-9945-48a5-a209-7efc2209f4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf6391f-4499-42eb-947e-4f7b64fe44df",
   "metadata": {},
   "source": [
    "* Memory is getting added similar to we pass a variable to templates (as we saw in above examples). The format/template is important here.\n",
    "* Create a ConversationalBufferMemory() object and passing this variable under 'Previous conversations' to this function\n",
    "* This buffer memory object is than assigned to LLMChain() object enabling storage of historic information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9c18e74f-50d2-4f41-a77e-bc87dc7c35d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"You are a chatbot having a conversation with a human.\n",
    "\n",
    "Previous conversation:\n",
    "{chat_history}\n",
    "\n",
    "New human question: {human_input}\n",
    "Chatbot:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfb152e-86cc-49cf-8ab8-87c8bf1aa78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chat_history : variable for memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aa423a1c-d2ab-4271-8c69-349f889f2208",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(input_variables=[\"chat_history\", \"human_input\"], template = template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4feea7ae-77ba-4a55-b5c4-ea4940c3038f",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc394098-c251-43c9-bef9-ee54368cbec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(openai_api_key=API_KEY, temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3629b1dd-3cc5-4026-9dd8-32a2a956e208",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    "    verbose=True,\n",
    "    memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4f2350fc-9e1e-493e-a3ad-1cadc249d6ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are a chatbot having a conversation with a human.\n",
      "\n",
      "Previous conversation:\n",
      "\n",
      "\n",
      "New human question: Hi there my friend\n",
      "Chatbot:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Hi there! How can I help you?'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.predict(human_input = \"Hi there my friend\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "713de163-fa81-4e10-9ab9-9c2df8046396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are a chatbot having a conversation with a human.\n",
      "\n",
      "Previous conversation:\n",
      "Human: Hi there my friend\n",
      "AI:  Hi there! How can I help you?\n",
      "\n",
      "New human question: Tell me what is Machine Learning\n",
      "Chatbot:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Machine Learning is a type of artificial intelligence that allows computers to learn from data without being explicitly programmed. It uses algorithms to identify patterns in data and make predictions or decisions based on those patterns.'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.predict(human_input = \"Tell me what is Machine Learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fe8706b4-5ec9-4aa0-9c6d-6f6bc6bc5bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are a chatbot having a conversation with a human.\n",
      "\n",
      "Previous conversation:\n",
      "Human: Hi there my friend\n",
      "AI:  Hi there! How can I help you?\n",
      "Human: Tell me what is Machine Learning\n",
      "AI:  Machine Learning is a type of artificial intelligence that allows computers to learn from data without being explicitly programmed. It uses algorithms to identify patterns in data and make predictions or decisions based on those patterns.\n",
      "\n",
      "New human question: How is it different from AI?\n",
      "Chatbot:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Machine Learning is a subset of Artificial Intelligence (AI). AI is a broader concept that includes Machine Learning, but also includes other techniques such as natural language processing, computer vision, and robotics. Machine Learning focuses on using data to train algorithms to make predictions or decisions, while AI focuses on creating intelligent systems that can think and act like humans.'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.predict(human_input = \"How is it different from AI?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "aed7ada1-0ca7-4af1-8b7f-14102d6be04b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are a chatbot having a conversation with a human.\n",
      "\n",
      "Previous conversation:\n",
      "Human: Hi there my friend\n",
      "AI:  Hi there! How can I help you?\n",
      "Human: Tell me what is Machine Learning\n",
      "AI:  Machine Learning is a type of artificial intelligence that allows computers to learn from data without being explicitly programmed. It uses algorithms to identify patterns in data and make predictions or decisions based on those patterns.\n",
      "Human: How is it different from AI?\n",
      "AI:  Machine Learning is a subset of Artificial Intelligence (AI). AI is a broader concept that includes Machine Learning, but also includes other techniques such as natural language processing, computer vision, and robotics. Machine Learning focuses on using data to train algorithms to make predictions or decisions, while AI focuses on creating intelligent systems that can think and act like humans.\n",
      "\n",
      "New human question: How are the two different from Data Science ?\n",
      "Chatbot:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Data Science is a field of study that uses scientific methods, processes, algorithms, and systems to extract knowledge and insights from structured and unstructured data. Machine Learning and Artificial Intelligence are two techniques used in Data Science to analyze data and make predictions or decisions. Machine Learning focuses on using data to train algorithms to make predictions or decisions, while AI focuses on creating intelligent systems that can think and act like humans.'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.predict(human_input = \"How are the two different from Data Science ?\")\n",
    "# it has to remember the previous two questions context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c31f96-6ca2-4356-a5d3-fb358b8e4695",
   "metadata": {},
   "source": [
    "#### Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24640115-af20-4283-9ea2-9bf292bbc662",
   "metadata": {},
   "source": [
    "Many a times, we would wish to provide context to the LLM which is open-source or private. For example, if working for some organization XYZ, we might wish to do a Q&A on some report. How to provide the context to LLM about this report? Obviously by uploading it to someplace where LLM can access it. Retrieval elements helps in usage of these external context while generation of a response by an LLM called as the Retrieval Augmented Generation (RAG). Now this external resource can be a Database, CSV, text file, PDF or Youtube video. This Retrieval system has the below major components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a399260-2b76-4053-82fd-53acf6e54ad1",
   "metadata": {},
   "source": [
    "* Document loader: This component helps in loading the external resource in memory\n",
    "\n",
    "* Document Transformer: This is majorly a preprocessing steps once the external document is loaded in the memory (like tokenizing the text, character splitting, etc)\n",
    "\n",
    "* Embedding model: To store these documents, we 1st need to generate embeddings for the text present.\n",
    "\n",
    "* Vector Databases/Store: Databases specialized in storing vector data.\n",
    "\n",
    "* Retrievers: Retrieve relevant entries from the vector DB once a prompt is run using LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a315bd6-a0ea-4ebf-9295-bd3d3659c589",
   "metadata": {},
   "source": [
    "#### Youtube video  analysis Question Asnwering with LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dbb8989b-96e5-40a4-b729-247d6c117837",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import TextLoader, YoutubeLoader, GoogleApiYoutubeLoader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfd56e6-adbf-4e29-aa89-66c943183101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.youtube.com/watch?v=3w0EhxiebUA : Named Entity Recognition detection Youtube video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "27e7de78-cd28-4595-8737-727d8fec042e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = YoutubeLoader.from_youtube_url(\"https://www.youtube.com/watch?v=3w0EhxiebUA\", add_video_info =True,\n",
    "language=[\"en\", \"id\"],\n",
    "translation=\"en\",\n",
    ")\n",
    "data = loader. load()\n",
    "# add video info : use Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "811a5182-47ea-4c41-bec3-262e51bdb4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(data)\n",
    "# Preprocessign the text from the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9cb72dff-6cba-47c8-b9df-0f2a41a1cbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(openai_api_key=API_KEY)\n",
    "llm = OpenAI(openai_api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "148bf9d3-7681-48e9-bf32-af004aa37b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "docsearch = Chroma.from_documents(texts, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e7c8f0-b49b-4556-b2f1-a1c1695d76bc",
   "metadata": {},
   "source": [
    "##### Question Answering on the text of the Youtube video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bc6a5b52-0a5a-41a8-95da-3b8a9e50d16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = RetrievalQA.from_chain_type(llm = llm, chain_type= \"stuff\", retriever= docsearch.as_retriever())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e62b44e5-5872-47f5-8a59-7d69fd4333ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -CRFs are used for named entity recognition \n",
      "-Information extraction refers to extracting important information from a given text \n",
      "-Named entity recognition is part of information extraction\n",
      "-Segmentation ambiguity and tag assignment ambiguity are two major problems that can be faced \n",
      "-Feature functions are used to generate word-level features \n",
      "-CRF equation is used to calculate the probability of a given tag sequence \n",
      "-Weights are assigned to different feature functions \n",
      "-CRFs are trained using training data and weight updation is done using gradient descent\n"
     ]
    }
   ],
   "source": [
    "print('\\n'.join(qa.run('Summarize the text in short points').split('\\n')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "11a81695-d026-4f56-a10a-f40607908a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. What is the equation used in CRF?\n",
      "2. What is a feature function?\n",
      "3. What does the letter \"O\" refer to in IOB tagging?\n",
      "4. What is the denominator of the CRF equation calculated from?\n",
      "5. How are weights updated in CRF?\n"
     ]
    }
   ],
   "source": [
    "print('\\n'.join(qa.run('Generate some quiz questions from this text').split('\\n')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6642604f-75df-4306-8f7b-a132bc23e521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try this with  another Youtube video : https://www.youtube.com/watch?v=Gn_PjruUtrc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c44acb5-a4cc-4e5f-be11-843d6ace5a99",
   "metadata": {},
   "source": [
    "#### CSV file analysis using Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "57c4850f-314c-4b4e-88bb-7f3d0e76bdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "from langchain.agents.agent_types import AgentType\n",
    "from langchain.agents import create_csv_agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "dbb6ecfc-2108-443e-933a-113720a4799d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a csv agent\n",
    "agent = create_csv_agent(\n",
    "OpenAI(temperature=0,openai_api_key=API_KEY),\"titanic.csv\",verbose=True,\n",
    "agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c6cba5b1-521c-4347-98e0-ed8aa25f3a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to find the cabins with the highest fare\n",
      "Action: python_repl_ast\n",
      "Action Input: df.sort_values(by='fare', ascending=False)['cabin'].head()\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m183           B101\n",
      "302            NaN\n",
      "49     B51 B53 B55\n",
      "50     B51 B53 B55\n",
      "113    C23 C25 C27\n",
      "Name: cabin, dtype: object\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the most expensive cabins\n",
      "Final Answer: B101, NaN, B51 B53 B55, C23 C25 C27\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'B101, NaN, B51 B53 B55, C23 C25 C27'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run('List down the most expensive cabins')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "929f902a-5af8-4628-be88-92fc9bed6078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I should look at the data and see what stands out\n",
      "Action: python_repl_ast\n",
      "Action Input: df.describe()\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m            pclass     survived          age        sibsp        parch  \\\n",
      "count  1309.000000  1309.000000  1046.000000  1309.000000  1309.000000   \n",
      "mean      2.294882     0.381971    29.881138     0.498854     0.385027   \n",
      "std       0.837836     0.486055    14.413493     1.041658     0.865560   \n",
      "min       1.000000     0.000000     0.170000     0.000000     0.000000   \n",
      "25%       2.000000     0.000000    21.000000     0.000000     0.000000   \n",
      "50%       3.000000     0.000000    28.000000     0.000000     0.000000   \n",
      "75%       3.000000     1.000000    39.000000     1.000000     0.000000   \n",
      "max       3.000000     1.000000    80.000000     8.000000     9.000000   \n",
      "\n",
      "              fare        body  \n",
      "count  1308.000000  121.000000  \n",
      "mean     33.295479  160.809917  \n",
      "std      51.758668   97.696922  \n",
      "min       0.000000    1.000000  \n",
      "25%       7.895800   72.000000  \n",
      "50%      14.454200  155.000000  \n",
      "75%      31.275000  256.000000  \n",
      "max     512.329200  328.000000  \u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I can see that the average age of passengers is 29.88, the average fare is 33.29, and the average body count is 160.81.\n",
      "Final Answer: The average age of passengers is 29.88, the average fare is 33.29, and the average body count is 160.81.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The average age of passengers is 29.88, the average fare is 33.29, and the average body count is 160.81.'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run('Give some interesting facts from the data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a1395a-4b69-4510-a51a-8e9bf0d42a45",
   "metadata": {},
   "source": [
    "#### PDF file analysis using Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f98d8f-8ab5-4810-8f2d-4ec8704f9716",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lpip install chromadb langchain openai tiktoken unstructured pypdfium2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "de25f343-a2a6-4a98-bd83-f7e07aef6978",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.document_loaders import PyPDFium2Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e4f0763b-afb3-4d05-bc7f-1c8f0e3afb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Attention is all you need research paper\n",
    "loader = PyPDFium2Loader(\"NIPS-2017-attention-is-all-you-need-Paper.pdf\")\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "dbcac56f-3bf8-4c04-bd87-babd04dbdaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "929e266e-5451-4d2e-b9f7-e7f63cecb181",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(openai_api_key=API_KEY)\n",
    "llm = OpenAI(openai_api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ddcb28d8-834c-46cb-afd6-0049c1896870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing the embeddings - vectordb\n",
    "docsearch = Chroma.from_documents(texts, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "eb06ba79-4025-4676-ac5f-4eee49347779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieval QA chain\n",
    "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever = docsearch.as_retriever())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ae009379-2d92-436d-a2b8-e05bea93d368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' This pdf is about the Transformer, a new simple network architecture based solely on attention mechanisms which can be used for sequence transduction tasks such as language modeling and machine translation.'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa.run('what is this pdf about?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b983c2be-ab29-4ebb-acd7-c222318eb730",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The authors of this paper are Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, and Illia Polosukhin.'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa.run('who is the author of this paper ?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce129bb-67a8-45be-a34e-b95e88797b9e",
   "metadata": {},
   "source": [
    "#### End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
