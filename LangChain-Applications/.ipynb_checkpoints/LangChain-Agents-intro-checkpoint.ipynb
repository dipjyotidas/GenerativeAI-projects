{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57ce086e-5bd2-42f2-8443-ce05d737338e",
   "metadata": {},
   "source": [
    "#### Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6a3e83-962d-45f4-ab75-245ecc1c5b02",
   "metadata": {},
   "source": [
    "Very closely related to the concept of Chains, Agents are also used to execute multiple steps using an LLM. A major difference being the way multiple actions are executed by Chains and Agents. In case of Agents, the backend uses an LLM to decide over what action to take (of all options/tools available), hence flexible while in case of Chains, a hardcoded sequence of steps are taken. Also, agents are more diverse and can integrate with multiple, different tools."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f4f782-1b6c-4db2-b42e-4ce91df3cafa",
   "metadata": {},
   "source": [
    "You have an agent that has access to\n",
    "* Google search\n",
    "* Maths-Calculator\n",
    "* A retriever for some external document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad816e06-76f3-4c96-a3c2-4cf7a8d99cb3",
   "metadata": {},
   "source": [
    "* When you run a query, the LLM will decide which tool to use depending on the query or maybe it won’t use any tool if the query doesn’t require it like ‘Hello LLM’. But in case of a chain,\n",
    "\n",
    "* You might not be able to provide multiple, diverse functionality with pre-defined chains in Langchain.\n",
    "\n",
    "* Even if you do, you need to hardcode the whole code and sequence of steps. So even if the query don’t require any tool, it will use it (& may throw an error as well due to lack of compatibility). Hence no flexibility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecb09a5-eda3-4e3e-92d5-94f08161fe74",
   "metadata": {},
   "source": [
    "* So, if you want a more flexible, dynamic app, Agents are a better option but if your use case is constant, chains can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b2fb71-ea2c-4047-b987-f4a309036fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent is like a Chatbot which can do specific tasks, they can interact with api, tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d9b74f-ca56-48e0-bc7c-1b8239f1b745",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain openai google-search-result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fea612d-4f32-45b4-b863-cd2bc2e9c008",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import Tool\n",
    "from langchain.agents import AgentType\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.utilities import SerpAPIWrapper\n",
    "from langchain.agents import initialize_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86423f4a-7ebc-4842-82c1-47e7cfefb076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your API key : https://platform.openai.com/account/api-keys\n",
    "# store the API key in Environment variable : https://networkdirection.net/python/resources/env-variable/\n",
    "import os\n",
    "api_key = os.environ.get('OpenAI_API_Key')\n",
    "serp_key = os.environ.get('serp_api')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "286ce403-b90d-48a5-941e-a4547ab9d91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#You need to get serp_api and openai_api for this.\n",
    "search = SerpAPIWrapper(serpapi_api_key=serp_key)\n",
    "llm=OpenAI(openai_api_key=api_key)\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name = \"Current Search\",\n",
    "        func=search.run,\n",
    "        description=\"useful for when you need to answer questions about current events or the current state of the world\"\n",
    "\n",
    "    ),]\n",
    "search_me = \"Explain what happend in G20 meeting, 2023 that happened in Delhi?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6312443-9f28-487c-b6d4-be4173e3580e",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_chain = initialize_agent(tools, llm, agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4fe2eef3-5ab9-4340-8781-8a8d3cc87b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': 'Explain what happend in G20 meeting, 2023 that happened in Delhi?', 'chat_history': [], 'output': 'The G20 meeting in 2023, which was held in Delhi, India, was focused on the global economic recovery and strengthening international cooperation. It was attended by the heads of states from the G20 countries, as well as representatives of international organizations. The meeting discussed issues related to climate change, global trade, and the digital economy, as well as other topics of global importance. The participants also agreed on a new framework for global financial regulation.'}\n"
     ]
    }
   ],
   "source": [
    "out = agent_chain({\"input\": search_me, \"chat_history\": []})\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c127c8-c678-4a91-8020-dcd25cf9334e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# refer : https://github.com/langchain-ai/langchain/issues/3106"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f52aba-985f-47bf-92fd-3bcd4384a93e",
   "metadata": {},
   "source": [
    "#### How to build Langchain agents?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1578f608-1532-4e6d-a4c7-244064f7b9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second example: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73dd124-df85-4f15-96ab-14460084ef87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install langchain openai arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd600adf-986d-4cd5-8113-d3f4ebcdc9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import Tool, ZeroShotAgent, AgentExecutor\n",
    "from langchain import OpenAI, LLMChain \n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.tools.arxiv.tool import ArxivQueryRun\n",
    "from langchain.tools.shell.tool import ShellTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27c1914c-a052-46f7-8c97-e2a10a4e2d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package langchain.tools in langchain:\n",
      "\n",
      "NAME\n",
      "    langchain.tools - Core toolkit implementations.\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    arxiv (package)\n",
      "    azure_cognitive_services (package)\n",
      "    base\n",
      "    bing_search (package)\n",
      "    brave_search (package)\n",
      "    convert_to_openai\n",
      "    ddg_search (package)\n",
      "    file_management (package)\n",
      "    gmail (package)\n",
      "    google_places (package)\n",
      "    google_search (package)\n",
      "    google_serper (package)\n",
      "    graphql (package)\n",
      "    human (package)\n",
      "    ifttt\n",
      "    interaction (package)\n",
      "    jira (package)\n",
      "    json (package)\n",
      "    metaphor_search (package)\n",
      "    openapi (package)\n",
      "    openweathermap (package)\n",
      "    playwright (package)\n",
      "    plugin\n",
      "    powerbi (package)\n",
      "    pubmed (package)\n",
      "    python (package)\n",
      "    requests (package)\n",
      "    scenexplain (package)\n",
      "    searx_search (package)\n",
      "    shell (package)\n",
      "    sleep (package)\n",
      "    spark_sql (package)\n",
      "    sql_database (package)\n",
      "    steamship_image_generation (package)\n",
      "    vectorstore (package)\n",
      "    wikipedia (package)\n",
      "    wolfram_alpha (package)\n",
      "    youtube (package)\n",
      "    zapier (package)\n",
      "\n",
      "CLASSES\n",
      "    abc.ABC(builtins.object)\n",
      "        langchain.tools.base.BaseTool(abc.ABC, pydantic.main.BaseModel)\n",
      "            langchain.tools.arxiv.tool.ArxivQueryRun\n",
      "            langchain.tools.azure_cognitive_services.form_recognizer.AzureCogsFormRecognizerTool\n",
      "            langchain.tools.azure_cognitive_services.image_analysis.AzureCogsImageAnalysisTool\n",
      "            langchain.tools.azure_cognitive_services.speech2text.AzureCogsSpeech2TextTool\n",
      "            langchain.tools.azure_cognitive_services.text2speech.AzureCogsText2SpeechTool\n",
      "            langchain.tools.base.StructuredTool\n",
      "            langchain.tools.base.Tool\n",
      "            langchain.tools.bing_search.tool.BingSearchResults\n",
      "            langchain.tools.bing_search.tool.BingSearchRun\n",
      "            langchain.tools.brave_search.tool.BraveSearch\n",
      "            langchain.tools.ddg_search.tool.DuckDuckGoSearchResults\n",
      "            langchain.tools.ddg_search.tool.DuckDuckGoSearchRun\n",
      "            langchain.tools.file_management.copy.CopyFileTool(langchain.tools.file_management.utils.BaseFileToolMixin, langchain.tools.base.BaseTool)\n",
      "            langchain.tools.file_management.delete.DeleteFileTool(langchain.tools.file_management.utils.BaseFileToolMixin, langchain.tools.base.BaseTool)\n",
      "            langchain.tools.file_management.file_search.FileSearchTool(langchain.tools.file_management.utils.BaseFileToolMixin, langchain.tools.base.BaseTool)\n",
      "            langchain.tools.file_management.list_dir.ListDirectoryTool(langchain.tools.file_management.utils.BaseFileToolMixin, langchain.tools.base.BaseTool)\n",
      "            langchain.tools.file_management.move.MoveFileTool(langchain.tools.file_management.utils.BaseFileToolMixin, langchain.tools.base.BaseTool)\n",
      "            langchain.tools.file_management.read.ReadFileTool(langchain.tools.file_management.utils.BaseFileToolMixin, langchain.tools.base.BaseTool)\n",
      "            langchain.tools.file_management.write.WriteFileTool(langchain.tools.file_management.utils.BaseFileToolMixin, langchain.tools.base.BaseTool)\n",
      "            langchain.tools.google_places.tool.GooglePlacesTool\n",
      "            langchain.tools.google_search.tool.GoogleSearchResults\n",
      "            langchain.tools.google_search.tool.GoogleSearchRun\n",
      "            langchain.tools.google_serper.tool.GoogleSerperResults\n",
      "            langchain.tools.google_serper.tool.GoogleSerperRun\n",
      "            langchain.tools.graphql.tool.BaseGraphQLTool\n",
      "            langchain.tools.human.tool.HumanInputRun\n",
      "            langchain.tools.ifttt.IFTTTWebhook\n",
      "            langchain.tools.jira.tool.JiraAction\n",
      "            langchain.tools.json.tool.JsonGetValueTool\n",
      "            langchain.tools.json.tool.JsonListKeysTool\n",
      "            langchain.tools.metaphor_search.tool.MetaphorSearchResults\n",
      "            langchain.tools.openweathermap.tool.OpenWeatherMapQueryRun\n",
      "            langchain.tools.plugin.AIPluginTool\n",
      "            langchain.tools.powerbi.tool.InfoPowerBITool\n",
      "            langchain.tools.powerbi.tool.ListPowerBITool\n",
      "            langchain.tools.powerbi.tool.QueryPowerBITool\n",
      "            langchain.tools.pubmed.tool.PubmedQueryRun\n",
      "            langchain.tools.python.tool.PythonAstREPLTool\n",
      "            langchain.tools.python.tool.PythonREPLTool\n",
      "            langchain.tools.scenexplain.tool.SceneXplainTool\n",
      "            langchain.tools.searx_search.tool.SearxSearchResults\n",
      "            langchain.tools.searx_search.tool.SearxSearchRun\n",
      "            langchain.tools.shell.tool.ShellTool\n",
      "            langchain.tools.sleep.tool.SleepTool\n",
      "            langchain.tools.steamship_image_generation.tool.SteamshipImageGenerationTool\n",
      "            langchain.tools.vectorstore.tool.VectorStoreQATool(langchain.tools.vectorstore.tool.BaseVectorStoreTool, langchain.tools.base.BaseTool)\n",
      "            langchain.tools.vectorstore.tool.VectorStoreQAWithSourcesTool(langchain.tools.vectorstore.tool.BaseVectorStoreTool, langchain.tools.base.BaseTool)\n",
      "            langchain.tools.wikipedia.tool.WikipediaQueryRun\n",
      "            langchain.tools.wolfram_alpha.tool.WolframAlphaQueryRun\n",
      "            langchain.tools.youtube.search.YouTubeSearchTool\n",
      "            langchain.tools.zapier.tool.ZapierNLAListActions\n",
      "            langchain.tools.zapier.tool.ZapierNLARunAction\n",
      "    langchain.tools.file_management.utils.BaseFileToolMixin(pydantic.main.BaseModel)\n",
      "        langchain.tools.file_management.copy.CopyFileTool(langchain.tools.file_management.utils.BaseFileToolMixin, langchain.tools.base.BaseTool)\n",
      "        langchain.tools.file_management.delete.DeleteFileTool(langchain.tools.file_management.utils.BaseFileToolMixin, langchain.tools.base.BaseTool)\n",
      "        langchain.tools.file_management.file_search.FileSearchTool(langchain.tools.file_management.utils.BaseFileToolMixin, langchain.tools.base.BaseTool)\n",
      "        langchain.tools.file_management.list_dir.ListDirectoryTool(langchain.tools.file_management.utils.BaseFileToolMixin, langchain.tools.base.BaseTool)\n",
      "        langchain.tools.file_management.move.MoveFileTool(langchain.tools.file_management.utils.BaseFileToolMixin, langchain.tools.base.BaseTool)\n",
      "        langchain.tools.file_management.read.ReadFileTool(langchain.tools.file_management.utils.BaseFileToolMixin, langchain.tools.base.BaseTool)\n",
      "        langchain.tools.file_management.write.WriteFileTool(langchain.tools.file_management.utils.BaseFileToolMixin, langchain.tools.base.BaseTool)\n",
      "    langchain.tools.gmail.base.GmailBaseTool(langchain.tools.base.BaseTool)\n",
      "        langchain.tools.gmail.create_draft.GmailCreateDraft\n",
      "        langchain.tools.gmail.get_message.GmailGetMessage\n",
      "        langchain.tools.gmail.get_thread.GmailGetThread\n",
      "        langchain.tools.gmail.search.GmailSearch\n",
      "        langchain.tools.gmail.send_message.GmailSendMessage\n",
      "    langchain.tools.playwright.base.BaseBrowserTool(langchain.tools.base.BaseTool)\n",
      "        langchain.tools.playwright.click.ClickTool\n",
      "        langchain.tools.playwright.current_page.CurrentWebPageTool\n",
      "        langchain.tools.playwright.extract_hyperlinks.ExtractHyperlinksTool\n",
      "        langchain.tools.playwright.extract_text.ExtractTextTool\n",
      "        langchain.tools.playwright.get_elements.GetElementsTool\n",
      "        langchain.tools.playwright.navigate.NavigateTool\n",
      "        langchain.tools.playwright.navigate_back.NavigateBackTool\n",
      "    langchain.tools.vectorstore.tool.BaseVectorStoreTool(pydantic.main.BaseModel)\n",
      "        langchain.tools.vectorstore.tool.VectorStoreQATool(langchain.tools.vectorstore.tool.BaseVectorStoreTool, langchain.tools.base.BaseTool)\n",
      "        langchain.tools.vectorstore.tool.VectorStoreQAWithSourcesTool(langchain.tools.vectorstore.tool.BaseVectorStoreTool, langchain.tools.base.BaseTool)\n",
      "    openapi_schema_pydantic.v3.v3_1_0.open_api.OpenAPI(pydantic.main.BaseModel)\n",
      "        langchain.tools.openapi.utils.openapi_utils.OpenAPISpec\n",
      "    pydantic.main.BaseModel(pydantic.utils.Representation)\n",
      "        langchain.tools.base.BaseTool(abc.ABC, pydantic.main.BaseModel)\n",
      "            langchain.tools.arxiv.tool.ArxivQueryRun\n",
      "            langchain.tools.azure_cognitive_services.form_recognizer.AzureCogsFormRecognizerTool\n",
      "            langchain.tools.azure_cognitive_services.image_analysis.AzureCogsImageAnalysisTool\n",
      "            langchain.tools.azure_cognitive_services.speech2text.AzureCogsSpeech2TextTool\n",
      "            langchain.tools.azure_cognitive_services.text2speech.AzureCogsText2SpeechTool\n",
      "            langchain.tools.base.StructuredTool\n",
      "            langchain.tools.base.Tool\n",
      "            langchain.tools.bing_search.tool.BingSearchResults\n",
      "            langchain.tools.bing_search.tool.BingSearchRun\n",
      "            langchain.tools.brave_search.tool.BraveSearch\n",
      "            langchain.tools.ddg_search.tool.DuckDuckGoSearchResults\n",
      "            langchain.tools.ddg_search.tool.DuckDuckGoSearchRun\n",
      "            langchain.tools.file_management.copy.CopyFileTool(langchain.tools.file_management.utils.BaseFileToolMixin, langchain.tools.base.BaseTool)\n",
      "            langchain.tools.file_management.delete.DeleteFileTool(langchain.tools.file_management.utils.BaseFileToolMixin, langchain.tools.base.BaseTool)\n",
      "            langchain.tools.file_management.file_search.FileSearchTool(langchain.tools.file_management.utils.BaseFileToolMixin, langchain.tools.base.BaseTool)\n",
      "            langchain.tools.file_management.list_dir.ListDirectoryTool(langchain.tools.file_management.utils.BaseFileToolMixin, langchain.tools.base.BaseTool)\n",
      "            langchain.tools.file_management.move.MoveFileTool(langchain.tools.file_management.utils.BaseFileToolMixin, langchain.tools.base.BaseTool)\n",
      "            langchain.tools.file_management.read.ReadFileTool(langchain.tools.file_management.utils.BaseFileToolMixin, langchain.tools.base.BaseTool)\n",
      "            langchain.tools.file_management.write.WriteFileTool(langchain.tools.file_management.utils.BaseFileToolMixin, langchain.tools.base.BaseTool)\n",
      "            langchain.tools.google_places.tool.GooglePlacesTool\n",
      "            langchain.tools.google_search.tool.GoogleSearchResults\n",
      "            langchain.tools.google_search.tool.GoogleSearchRun\n",
      "            langchain.tools.google_serper.tool.GoogleSerperResults\n",
      "            langchain.tools.google_serper.tool.GoogleSerperRun\n",
      "            langchain.tools.graphql.tool.BaseGraphQLTool\n",
      "            langchain.tools.human.tool.HumanInputRun\n",
      "            langchain.tools.ifttt.IFTTTWebhook\n",
      "            langchain.tools.jira.tool.JiraAction\n",
      "            langchain.tools.json.tool.JsonGetValueTool\n",
      "            langchain.tools.json.tool.JsonListKeysTool\n",
      "            langchain.tools.metaphor_search.tool.MetaphorSearchResults\n",
      "            langchain.tools.openweathermap.tool.OpenWeatherMapQueryRun\n",
      "            langchain.tools.plugin.AIPluginTool\n",
      "            langchain.tools.powerbi.tool.InfoPowerBITool\n",
      "            langchain.tools.powerbi.tool.ListPowerBITool\n",
      "            langchain.tools.powerbi.tool.QueryPowerBITool\n",
      "            langchain.tools.pubmed.tool.PubmedQueryRun\n",
      "            langchain.tools.python.tool.PythonAstREPLTool\n",
      "            langchain.tools.python.tool.PythonREPLTool\n",
      "            langchain.tools.scenexplain.tool.SceneXplainTool\n",
      "            langchain.tools.searx_search.tool.SearxSearchResults\n",
      "            langchain.tools.searx_search.tool.SearxSearchRun\n",
      "            langchain.tools.shell.tool.ShellTool\n",
      "            langchain.tools.sleep.tool.SleepTool\n",
      "            langchain.tools.steamship_image_generation.tool.SteamshipImageGenerationTool\n",
      "            langchain.tools.vectorstore.tool.VectorStoreQATool(langchain.tools.vectorstore.tool.BaseVectorStoreTool, langchain.tools.base.BaseTool)\n",
      "            langchain.tools.vectorstore.tool.VectorStoreQAWithSourcesTool(langchain.tools.vectorstore.tool.BaseVectorStoreTool, langchain.tools.base.BaseTool)\n",
      "            langchain.tools.wikipedia.tool.WikipediaQueryRun\n",
      "            langchain.tools.wolfram_alpha.tool.WolframAlphaQueryRun\n",
      "            langchain.tools.youtube.search.YouTubeSearchTool\n",
      "            langchain.tools.zapier.tool.ZapierNLAListActions\n",
      "            langchain.tools.zapier.tool.ZapierNLARunAction\n",
      "        langchain.tools.openapi.utils.api_models.APIOperation\n",
      "        langchain.tools.requests.tool.BaseRequestsTool\n",
      "            langchain.tools.requests.tool.RequestsDeleteTool(langchain.tools.requests.tool.BaseRequestsTool, langchain.tools.base.BaseTool)\n",
      "            langchain.tools.requests.tool.RequestsGetTool(langchain.tools.requests.tool.BaseRequestsTool, langchain.tools.base.BaseTool)\n",
      "            langchain.tools.requests.tool.RequestsPatchTool(langchain.tools.requests.tool.BaseRequestsTool, langchain.tools.base.BaseTool)\n",
      "            langchain.tools.requests.tool.RequestsPostTool(langchain.tools.requests.tool.BaseRequestsTool, langchain.tools.base.BaseTool)\n",
      "            langchain.tools.requests.tool.RequestsPutTool(langchain.tools.requests.tool.BaseRequestsTool, langchain.tools.base.BaseTool)\n",
      "        langchain.tools.spark_sql.tool.BaseSparkSQLTool\n",
      "            langchain.tools.spark_sql.tool.InfoSparkSQLTool(langchain.tools.spark_sql.tool.BaseSparkSQLTool, langchain.tools.base.BaseTool)\n",
      "            langchain.tools.spark_sql.tool.ListSparkSQLTool(langchain.tools.spark_sql.tool.BaseSparkSQLTool, langchain.tools.base.BaseTool)\n",
      "            langchain.tools.spark_sql.tool.QueryCheckerTool(langchain.tools.spark_sql.tool.BaseSparkSQLTool, langchain.tools.base.BaseTool)\n",
      "            langchain.tools.spark_sql.tool.QuerySparkSQLTool(langchain.tools.spark_sql.tool.BaseSparkSQLTool, langchain.tools.base.BaseTool)\n",
      "        langchain.tools.sql_database.tool.BaseSQLDatabaseTool\n",
      "            langchain.tools.sql_database.tool.InfoSQLDatabaseTool(langchain.tools.sql_database.tool.BaseSQLDatabaseTool, langchain.tools.base.BaseTool)\n",
      "            langchain.tools.sql_database.tool.ListSQLDatabaseTool(langchain.tools.sql_database.tool.BaseSQLDatabaseTool, langchain.tools.base.BaseTool)\n",
      "            langchain.tools.sql_database.tool.QuerySQLCheckerTool(langchain.tools.sql_database.tool.BaseSQLDatabaseTool, langchain.tools.base.BaseTool)\n",
      "            langchain.tools.sql_database.tool.QuerySQLDataBaseTool(langchain.tools.sql_database.tool.BaseSQLDatabaseTool, langchain.tools.base.BaseTool)\n",
      "    \n",
      "    class AIPluginTool(langchain.tools.base.BaseTool)\n",
      "     |  AIPluginTool(*, name: str, description: str, args_schema: Type[langchain.tools.plugin.AIPluginToolSchema] = <class 'langchain.tools.plugin.AIPluginToolSchema'>, return_direct: bool = False, verbose: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, handle_tool_error: Union[bool, str, Callable[[langchain.tools.base.ToolException], str], NoneType] = False, plugin: langchain.tools.plugin.AIPlugin, api_spec: str) -> None\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      AIPluginTool\n",
      "     |      langchain.tools.base.BaseTool\n",
      "     |      abc.ABC\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  from_plugin_url(url: 'str') -> 'AIPluginTool' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'api_spec': 'str', 'args_schema': 'Type[AIPluginToo...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.tools.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'api_spec': ModelField(name='api_spec', type=str, requir...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function BaseTool.raise_deprecati...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {}\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, name: str, description: str, args...in....\n",
      "     |  \n",
      "     |  __validators__ = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  __call__(self, tool_input: 'str', callbacks: 'Callbacks' = None) -> 'str'\n",
      "     |      Make tool callable.\n",
      "     |  \n",
      "     |  async arun(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool asynchronously.\n",
      "     |  \n",
      "     |  run(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  raise_deprecation(values: 'Dict') -> 'Dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  args\n",
      "     |  \n",
      "     |  is_single_input\n",
      "     |      Whether the tool only accepts a single input.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.tools.base.BaseTool.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __init__(__pydantic_self__, **data: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  dict(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> 'DictStrAny'\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class APIOperation(pydantic.main.BaseModel)\n",
      "     |  APIOperation(*, operation_id: str, description: Optional[str] = None, base_url: str, path: str, method: langchain.tools.openapi.utils.openapi_utils.HTTPVerb, properties: Sequence[langchain.tools.openapi.utils.api_models.APIProperty], request_body: Optional[langchain.tools.openapi.utils.api_models.APIRequestBody] = None) -> None\n",
      "     |  \n",
      "     |  A model for a single API operation.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      APIOperation\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  to_typescript(self) -> str\n",
      "     |      Get typescript string representation of the operation.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  from_openapi_spec(spec: langchain.tools.openapi.utils.openapi_utils.OpenAPISpec, path: str, method: str) -> 'APIOperation' from pydantic.main.ModelMetaclass\n",
      "     |      Create an APIOperation from an OpenAPI spec.\n",
      "     |  \n",
      "     |  from_openapi_url(spec_url: str, path: str, method: str) -> 'APIOperation' from pydantic.main.ModelMetaclass\n",
      "     |      Create an APIOperation from an OpenAPI URL.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ts_type_from_python(type_: Union[str, Type, tuple, NoneType, enum.Enum]) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  body_params\n",
      "     |  \n",
      "     |  path_params\n",
      "     |  \n",
      "     |  query_params\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'base_url': <class 'str'>, 'description': typing.Op...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.tools.openapi.utils.api_models.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = None\n",
      "     |  \n",
      "     |  __fields__ = {'base_url': ModelField(name='base_url', type=str, requir...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = []\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {}\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, operation_id: str, description: O...uti...\n",
      "     |  \n",
      "     |  __validators__ = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __init__(__pydantic_self__, **data: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  dict(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> 'DictStrAny'\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  Config = <class 'pydantic.config.BaseConfig'>\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class ArxivQueryRun(langchain.tools.base.BaseTool)\n",
      "     |  ArxivQueryRun(*, name: str = 'arxiv', description: str = 'A wrapper around Arxiv.org Useful for when you need to answer questions about Physics, Mathematics, Computer Science, Quantitative Biology, Quantitative Finance, Statistics, Electrical Engineering, and Economics from scientific articles on arxiv.org. Input should be a search query.', args_schema: Optional[Type[pydantic.main.BaseModel]] = None, return_direct: bool = False, verbose: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, handle_tool_error: Union[bool, str, Callable[[langchain.tools.base.ToolException], str], NoneType] = False, api_wrapper: langchain.utilities.arxiv.ArxivAPIWrapper = None) -> None\n",
      "     |  \n",
      "     |  Tool that adds the capability to search using the Arxiv API.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ArxivQueryRun\n",
      "     |      langchain.tools.base.BaseTool\n",
      "     |      abc.ABC\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'api_wrapper': <class 'langchain.utilities.arxiv.Ar...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.tools.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'api_wrapper': ModelField(name='api_wrapper', type=Arxiv...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function BaseTool.raise_deprecati...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {}\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, name: str = 'arxiv', description:....ut...\n",
      "     |  \n",
      "     |  __validators__ = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  __call__(self, tool_input: 'str', callbacks: 'Callbacks' = None) -> 'str'\n",
      "     |      Make tool callable.\n",
      "     |  \n",
      "     |  async arun(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool asynchronously.\n",
      "     |  \n",
      "     |  run(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  raise_deprecation(values: 'Dict') -> 'Dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  args\n",
      "     |  \n",
      "     |  is_single_input\n",
      "     |      Whether the tool only accepts a single input.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.tools.base.BaseTool.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __init__(__pydantic_self__, **data: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  dict(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> 'DictStrAny'\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class AzureCogsFormRecognizerTool(langchain.tools.base.BaseTool)\n",
      "     |  AzureCogsFormRecognizerTool(*, name: str = 'azure_cognitive_services_form_recognizer', description: str = 'A wrapper around Azure Cognitive Services Form Recognizer. Useful for when you need to extract text, tables, and key-value pairs from documents. Input should be a url to a document.', args_schema: Optional[Type[pydantic.main.BaseModel]] = None, return_direct: bool = False, verbose: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, handle_tool_error: Union[bool, str, Callable[[langchain.tools.base.ToolException], str], NoneType] = False, azure_cogs_key: str = '', azure_cogs_endpoint: str = '', doc_analysis_client: Any = None) -> None\n",
      "     |  \n",
      "     |  Tool that queries the Azure Cognitive Services Form Recognizer API.\n",
      "     |  \n",
      "     |  In order to set this up, follow instructions at:\n",
      "     |  https://learn.microsoft.com/en-us/azure/applied-ai-services/form-recognizer/quickstarts/get-started-sdks-rest-api?view=form-recog-3.0.0&pivots=programming-language-python\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      AzureCogsFormRecognizerTool\n",
      "     |      langchain.tools.base.BaseTool\n",
      "     |      abc.ABC\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  validate_environment(values: 'Dict') -> 'Dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Validate that api key and endpoint exists in environment.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'azure_cogs_endpoint': 'str', 'azure_cogs_key': 'st...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.tools.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'args_schema': ModelField(name='args_schema', type=Optio...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function BaseTool.raise_deprecati...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = [<function AzureCogsFormRecognizerTool.valid...\n",
      "     |  \n",
      "     |  __private_attributes__ = {}\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, name: str = 'azure_cognitive_serv...r =...\n",
      "     |  \n",
      "     |  __validators__ = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  __call__(self, tool_input: 'str', callbacks: 'Callbacks' = None) -> 'str'\n",
      "     |      Make tool callable.\n",
      "     |  \n",
      "     |  async arun(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool asynchronously.\n",
      "     |  \n",
      "     |  run(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  raise_deprecation(values: 'Dict') -> 'Dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  args\n",
      "     |  \n",
      "     |  is_single_input\n",
      "     |      Whether the tool only accepts a single input.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.tools.base.BaseTool.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __init__(__pydantic_self__, **data: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  dict(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> 'DictStrAny'\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class AzureCogsImageAnalysisTool(langchain.tools.base.BaseTool)\n",
      "     |  AzureCogsImageAnalysisTool(*, name: str = 'azure_cognitive_services_image_analysis', description: str = 'A wrapper around Azure Cognitive Services Image Analysis. Useful for when you need to analyze images. Input should be a url to an image.', args_schema: Optional[Type[pydantic.main.BaseModel]] = None, return_direct: bool = False, verbose: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, handle_tool_error: Union[bool, str, Callable[[langchain.tools.base.ToolException], str], NoneType] = False, azure_cogs_key: str = '', azure_cogs_endpoint: str = '', vision_service: Any = None, analysis_options: Any = None) -> None\n",
      "     |  \n",
      "     |  Tool that queries the Azure Cognitive Services Image Analysis API.\n",
      "     |  \n",
      "     |  In order to set this up, follow instructions at:\n",
      "     |  https://learn.microsoft.com/en-us/azure/cognitive-services/computer-vision/quickstarts-sdk/image-analysis-client-library-40\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      AzureCogsImageAnalysisTool\n",
      "     |      langchain.tools.base.BaseTool\n",
      "     |      abc.ABC\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  validate_environment(values: 'Dict') -> 'Dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Validate that api key and endpoint exists in environment.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'analysis_options': 'Any', 'azure_cogs_endpoint': '...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.tools.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'analysis_options': ModelField(name='analysis_options', ...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function BaseTool.raise_deprecati...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = [<function AzureCogsImageAnalysisTool.valida...\n",
      "     |  \n",
      "     |  __private_attributes__ = {}\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, name: str = 'azure_cognitive_serv...ny ...\n",
      "     |  \n",
      "     |  __validators__ = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  __call__(self, tool_input: 'str', callbacks: 'Callbacks' = None) -> 'str'\n",
      "     |      Make tool callable.\n",
      "     |  \n",
      "     |  async arun(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool asynchronously.\n",
      "     |  \n",
      "     |  run(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  raise_deprecation(values: 'Dict') -> 'Dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  args\n",
      "     |  \n",
      "     |  is_single_input\n",
      "     |      Whether the tool only accepts a single input.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.tools.base.BaseTool.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __init__(__pydantic_self__, **data: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  dict(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> 'DictStrAny'\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class AzureCogsSpeech2TextTool(langchain.tools.base.BaseTool)\n",
      "     |  AzureCogsSpeech2TextTool(*, name: str = 'azure_cognitive_services_speech2text', description: str = 'A wrapper around Azure Cognitive Services Speech2Text. Useful for when you need to transcribe audio to text. Input should be a url to an audio file.', args_schema: Optional[Type[pydantic.main.BaseModel]] = None, return_direct: bool = False, verbose: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, handle_tool_error: Union[bool, str, Callable[[langchain.tools.base.ToolException], str], NoneType] = False, azure_cogs_key: str = '', azure_cogs_region: str = '', speech_language: str = 'en-US', speech_config: Any = None) -> None\n",
      "     |  \n",
      "     |  Tool that queries the Azure Cognitive Services Speech2Text API.\n",
      "     |  \n",
      "     |  In order to set this up, follow instructions at:\n",
      "     |  https://learn.microsoft.com/en-us/azure/cognitive-services/speech-service/get-started-speech-to-text?pivots=programming-language-python\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      AzureCogsSpeech2TextTool\n",
      "     |      langchain.tools.base.BaseTool\n",
      "     |      abc.ABC\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  validate_environment(values: 'Dict') -> 'Dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Validate that api key and endpoint exists in environment.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'azure_cogs_key': 'str', 'azure_cogs_region': 'str'...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.tools.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'args_schema': ModelField(name='args_schema', type=Optio...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function BaseTool.raise_deprecati...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = [<function AzureCogsSpeech2TextTool.validate...\n",
      "     |  \n",
      "     |  __private_attributes__ = {}\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, name: str = 'azure_cognitive_serv...tr ...\n",
      "     |  \n",
      "     |  __validators__ = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  __call__(self, tool_input: 'str', callbacks: 'Callbacks' = None) -> 'str'\n",
      "     |      Make tool callable.\n",
      "     |  \n",
      "     |  async arun(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool asynchronously.\n",
      "     |  \n",
      "     |  run(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  raise_deprecation(values: 'Dict') -> 'Dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  args\n",
      "     |  \n",
      "     |  is_single_input\n",
      "     |      Whether the tool only accepts a single input.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.tools.base.BaseTool.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __init__(__pydantic_self__, **data: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  dict(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> 'DictStrAny'\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class AzureCogsText2SpeechTool(langchain.tools.base.BaseTool)\n",
      "     |  AzureCogsText2SpeechTool(*, name: str = 'azure_cognitive_services_text2speech', description: str = 'A wrapper around Azure Cognitive Services Text2Speech. Useful for when you need to convert text to speech. ', args_schema: Optional[Type[pydantic.main.BaseModel]] = None, return_direct: bool = False, verbose: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, handle_tool_error: Union[bool, str, Callable[[langchain.tools.base.ToolException], str], NoneType] = False, azure_cogs_key: str = '', azure_cogs_region: str = '', speech_language: str = 'en-US', speech_config: Any = None) -> None\n",
      "     |  \n",
      "     |  Tool that queries the Azure Cognitive Services Text2Speech API.\n",
      "     |  \n",
      "     |  In order to set this up, follow instructions at:\n",
      "     |  https://learn.microsoft.com/en-us/azure/cognitive-services/speech-service/get-started-text-to-speech?pivots=programming-language-python\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      AzureCogsText2SpeechTool\n",
      "     |      langchain.tools.base.BaseTool\n",
      "     |      abc.ABC\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  validate_environment(values: 'Dict') -> 'Dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Validate that api key and endpoint exists in environment.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'azure_cogs_key': 'str', 'azure_cogs_region': 'str'...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.tools.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'args_schema': ModelField(name='args_schema', type=Optio...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function BaseTool.raise_deprecati...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = [<function AzureCogsText2SpeechTool.validate...\n",
      "     |  \n",
      "     |  __private_attributes__ = {}\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, name: str = 'azure_cognitive_serv...tr ...\n",
      "     |  \n",
      "     |  __validators__ = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  __call__(self, tool_input: 'str', callbacks: 'Callbacks' = None) -> 'str'\n",
      "     |      Make tool callable.\n",
      "     |  \n",
      "     |  async arun(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool asynchronously.\n",
      "     |  \n",
      "     |  run(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  raise_deprecation(values: 'Dict') -> 'Dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  args\n",
      "     |  \n",
      "     |  is_single_input\n",
      "     |      Whether the tool only accepts a single input.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.tools.base.BaseTool.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __init__(__pydantic_self__, **data: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  dict(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> 'DictStrAny'\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class BaseGraphQLTool(langchain.tools.base.BaseTool)\n",
      "     |  BaseGraphQLTool(*, name: str = 'query_graphql', description: str = \"    Input to this tool is a detailed and correct GraphQL query, output is a result from the API.\\n    If the query is not correct, an error message will be returned.\\n    If an error is returned with 'Bad request' in it, rewrite the query and try again.\\n    If an error is returned with 'Unauthorized' in it, do not try again, but tell the user to change their authentication.\\n\\n    Example Input: query {{ allUsers {{ id, name, email }} }}    \", args_schema: Optional[Type[pydantic.main.BaseModel]] = None, return_direct: bool = False, verbose: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, handle_tool_error: Union[bool, str, Callable[[langchain.tools.base.ToolException], str], NoneType] = False, graphql_wrapper: langchain.utilities.graphql.GraphQLAPIWrapper) -> None\n",
      "     |  \n",
      "     |  Base tool for querying a GraphQL API.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      BaseGraphQLTool\n",
      "     |      langchain.tools.base.BaseTool\n",
      "     |      abc.ABC\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.tools.graphql.tool.BaseGraphQLTool.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'graphql_wrapper': <class 'langchain.utilities.grap...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.tools.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'args_schema': ModelField(name='args_schema', type=Optio...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function BaseTool.raise_deprecati...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {}\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, name: str = 'query_graphql', desc...ain...\n",
      "     |  \n",
      "     |  __validators__ = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  __call__(self, tool_input: 'str', callbacks: 'Callbacks' = None) -> 'str'\n",
      "     |      Make tool callable.\n",
      "     |  \n",
      "     |  async arun(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool asynchronously.\n",
      "     |  \n",
      "     |  run(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  raise_deprecation(values: 'Dict') -> 'Dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  args\n",
      "     |  \n",
      "     |  is_single_input\n",
      "     |      Whether the tool only accepts a single input.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __init__(__pydantic_self__, **data: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  dict(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> 'DictStrAny'\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class BaseRequestsTool(pydantic.main.BaseModel)\n",
      "     |  BaseRequestsTool(*, requests_wrapper: langchain.requests.TextRequestsWrapper) -> None\n",
      "     |  \n",
      "     |  Base class for requests tools.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      BaseRequestsTool\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'requests_wrapper': <class 'langchain.requests.Text...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.tools.requests.tool.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = None\n",
      "     |  \n",
      "     |  __fields__ = {'requests_wrapper': ModelField(name='requests_wrapper', ...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = []\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {}\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, requests_wrapper: langchain.requests.Te...\n",
      "     |  \n",
      "     |  __validators__ = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __init__(__pydantic_self__, **data: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  dict(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> 'DictStrAny'\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  Config = <class 'pydantic.config.BaseConfig'>\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class BaseSQLDatabaseTool(pydantic.main.BaseModel)\n",
      "     |  BaseSQLDatabaseTool(*, db: langchain.sql_database.SQLDatabase) -> None\n",
      "     |  \n",
      "     |  Base tool for interacting with a SQL database.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      BaseSQLDatabaseTool\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.tools.sql_database.tool.BaseSQLDatabaseTool...\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'db': <class 'langchain.sql_database.SQLDatabase'>}\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.tools.sql_database.tool.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'db': True}\n",
      "     |  \n",
      "     |  __fields__ = {'db': ModelField(name='db', type=SQLDatabase, required=T...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = []\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {}\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, db: langchain.sql_database.SQLDatabase)...\n",
      "     |  \n",
      "     |  __validators__ = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __init__(__pydantic_self__, **data: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  dict(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> 'DictStrAny'\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class BaseSparkSQLTool(pydantic.main.BaseModel)\n",
      "     |  BaseSparkSQLTool(*, db: langchain.utilities.spark_sql.SparkSQL) -> None\n",
      "     |  \n",
      "     |  Base tool for interacting with Spark SQL.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      BaseSparkSQLTool\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.tools.spark_sql.tool.BaseSparkSQLTool.Confi...\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'db': <class 'langchain.utilities.spark_sql.SparkSQ...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.tools.spark_sql.tool.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'db': True}\n",
      "     |  \n",
      "     |  __fields__ = {'db': ModelField(name='db', type=SparkSQL, required=True...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = []\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {}\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, db: langchain.utilities.spark_sql.Spark...\n",
      "     |  \n",
      "     |  __validators__ = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __init__(__pydantic_self__, **data: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  dict(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> 'DictStrAny'\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class BaseTool(abc.ABC, pydantic.main.BaseModel)\n",
      "     |  BaseTool(*, name: str, description: str, args_schema: Optional[Type[pydantic.main.BaseModel]] = None, return_direct: bool = False, verbose: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, handle_tool_error: Union[bool, str, Callable[[langchain.tools.base.ToolException], str], NoneType] = False) -> None\n",
      "     |  \n",
      "     |  Interface LangChain tools must implement.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      BaseTool\n",
      "     |      abc.ABC\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __call__(self, tool_input: 'str', callbacks: 'Callbacks' = None) -> 'str'\n",
      "     |      Make tool callable.\n",
      "     |  \n",
      "     |  async arun(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool asynchronously.\n",
      "     |  \n",
      "     |  run(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  raise_deprecation(values: 'Dict') -> 'Dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  args\n",
      "     |  \n",
      "     |  is_single_input\n",
      "     |      Whether the tool only accepts a single input.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.tools.base.BaseTool.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset({'_arun', '_run'})\n",
      "     |  \n",
      "     |  __annotations__ = {'args_schema': 'Optional[Type[BaseModel]]', 'callba...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.tools.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'args_schema': ModelField(name='args_schema', type=Optio...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function BaseTool.raise_deprecati...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {}\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, name: str, description: str, args...Too...\n",
      "     |  \n",
      "     |  __validators__ = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __init__(__pydantic_self__, **data: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  dict(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> 'DictStrAny'\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class BingSearchResults(langchain.tools.base.BaseTool)\n",
      "     |  BingSearchResults(*, name: str = 'Bing Search Results JSON', description: str = 'A wrapper around Bing Search. Useful for when you need to answer questions about current events. Input should be a search query. Output is a JSON array of the query results', args_schema: Optional[Type[pydantic.main.BaseModel]] = None, return_direct: bool = False, verbose: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, handle_tool_error: Union[bool, str, Callable[[langchain.tools.base.ToolException], str], NoneType] = False, num_results: int = 4, api_wrapper: langchain.utilities.bing_search.BingSearchAPIWrapper) -> None\n",
      "     |  \n",
      "     |  Tool that has capability to query the Bing Search API and get back json.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      BingSearchResults\n",
      "     |      langchain.tools.base.BaseTool\n",
      "     |      abc.ABC\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'api_wrapper': <class 'langchain.utilities.bing_sea...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.tools.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'api_wrapper': ModelField(name='api_wrapper', type=BingS...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function BaseTool.raise_deprecati...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {}\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, name: str = 'Bing Search Results ...lit...\n",
      "     |  \n",
      "     |  __validators__ = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  __call__(self, tool_input: 'str', callbacks: 'Callbacks' = None) -> 'str'\n",
      "     |      Make tool callable.\n",
      "     |  \n",
      "     |  async arun(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool asynchronously.\n",
      "     |  \n",
      "     |  run(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  raise_deprecation(values: 'Dict') -> 'Dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  args\n",
      "     |  \n",
      "     |  is_single_input\n",
      "     |      Whether the tool only accepts a single input.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.tools.base.BaseTool.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __init__(__pydantic_self__, **data: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  dict(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> 'DictStrAny'\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class BingSearchRun(langchain.tools.base.BaseTool)\n",
      "     |  BingSearchRun(*, name: str = 'bing_search', description: str = 'A wrapper around Bing Search. Useful for when you need to answer questions about current events. Input should be a search query.', args_schema: Optional[Type[pydantic.main.BaseModel]] = None, return_direct: bool = False, verbose: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, handle_tool_error: Union[bool, str, Callable[[langchain.tools.base.ToolException], str], NoneType] = False, api_wrapper: langchain.utilities.bing_search.BingSearchAPIWrapper) -> None\n",
      "     |  \n",
      "     |  Tool that adds the capability to query the Bing search API.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      BingSearchRun\n",
      "     |      langchain.tools.base.BaseTool\n",
      "     |      abc.ABC\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'api_wrapper': <class 'langchain.utilities.bing_sea...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.tools.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'api_wrapper': ModelField(name='api_wrapper', type=BingS...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function BaseTool.raise_deprecati...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {}\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, name: str = 'bing_search', descri...lit...\n",
      "     |  \n",
      "     |  __validators__ = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  __call__(self, tool_input: 'str', callbacks: 'Callbacks' = None) -> 'str'\n",
      "     |      Make tool callable.\n",
      "     |  \n",
      "     |  async arun(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool asynchronously.\n",
      "     |  \n",
      "     |  run(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  raise_deprecation(values: 'Dict') -> 'Dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  args\n",
      "     |  \n",
      "     |  is_single_input\n",
      "     |      Whether the tool only accepts a single input.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.tools.base.BaseTool.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __init__(__pydantic_self__, **data: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  dict(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> 'DictStrAny'\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class BraveSearch(langchain.tools.base.BaseTool)\n",
      "     |  BraveSearch(*, name: str = 'brave_search', description: str = 'a search engine. useful for when you need to answer questions about current events. input should be a search query.', args_schema: Optional[Type[pydantic.main.BaseModel]] = None, return_direct: bool = False, verbose: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, handle_tool_error: Union[bool, str, Callable[[langchain.tools.base.ToolException], str], NoneType] = False, search_wrapper: langchain.utilities.brave_search.BraveSearchWrapper) -> None\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      BraveSearch\n",
      "     |      langchain.tools.base.BaseTool\n",
      "     |      abc.ABC\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  from_api_key(api_key: 'str', search_kwargs: 'Optional[dict]' = None, **kwargs: 'Any') -> 'BraveSearch' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'search_wrapper': 'BraveSearchWrapper'}\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.tools.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'args_schema': ModelField(name='args_schema', type=Optio...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function BaseTool.raise_deprecati...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {}\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, name: str = 'brave_search', descr...ili...\n",
      "     |  \n",
      "     |  __validators__ = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  __call__(self, tool_input: 'str', callbacks: 'Callbacks' = None) -> 'str'\n",
      "     |      Make tool callable.\n",
      "     |  \n",
      "     |  async arun(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool asynchronously.\n",
      "     |  \n",
      "     |  run(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  raise_deprecation(values: 'Dict') -> 'Dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  args\n",
      "     |  \n",
      "     |  is_single_input\n",
      "     |      Whether the tool only accepts a single input.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.tools.base.BaseTool.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __init__(__pydantic_self__, **data: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  dict(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> 'DictStrAny'\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class ClickTool(langchain.tools.playwright.base.BaseBrowserTool)\n",
      "     |  ClickTool(*, name: str = 'click_element', description: str = 'Click on an element with the given CSS selector', args_schema: Type[pydantic.main.BaseModel] = <class 'langchain.tools.playwright.click.ClickToolInput'>, return_direct: bool = False, verbose: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, handle_tool_error: Union[bool, str, Callable[[langchain.tools.base.ToolException], str], NoneType] = False, sync_browser: ForwardRef(\"Optional['SyncBrowser']\") = None, async_browser: ForwardRef(\"Optional['AsyncBrowser']\") = None, visible_only: bool = True, playwright_strict: bool = False, playwright_timeout: float = 1000) -> None\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ClickTool\n",
      "     |      langchain.tools.playwright.base.BaseBrowserTool\n",
      "     |      langchain.tools.base.BaseTool\n",
      "     |      abc.ABC\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'args_schema': 'Type[BaseModel]', 'description': 's...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.tools.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'args_schema': ModelField(name='args_schema', type=Type[...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function BaseTool.raise_deprecati...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {}\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, name: str = 'click_element', desc...Fal...\n",
      "     |  \n",
      "     |  __validators__ = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.tools.playwright.base.BaseBrowserTool:\n",
      "     |  \n",
      "     |  from_browser(sync_browser: 'Optional[SyncBrowser]' = None, async_browser: 'Optional[AsyncBrowser]' = None) -> 'BaseBrowserTool' from langchain.tools.base.ToolMetaclass\n",
      "     |      Instantiate the tool.\n",
      "     |  \n",
      "     |  validate_browser_provided(values: 'dict') -> 'dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Check that the arguments are valid.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  __call__(self, tool_input: 'str', callbacks: 'Callbacks' = None) -> 'str'\n",
      "     |      Make tool callable.\n",
      "     |  \n",
      "     |  async arun(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool asynchronously.\n",
      "     |  \n",
      "     |  run(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  raise_deprecation(values: 'Dict') -> 'Dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  args\n",
      "     |  \n",
      "     |  is_single_input\n",
      "     |      Whether the tool only accepts a single input.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.tools.base.BaseTool.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __init__(__pydantic_self__, **data: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  dict(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> 'DictStrAny'\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class CopyFileTool(langchain.tools.file_management.utils.BaseFileToolMixin, langchain.tools.base.BaseTool)\n",
      "     |  CopyFileTool(*, name: str = 'copy_file', description: str = 'Create a copy of a file in a specified location', args_schema: Type[pydantic.main.BaseModel] = <class 'langchain.tools.file_management.copy.FileCopyInput'>, return_direct: bool = False, verbose: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, handle_tool_error: Union[bool, str, Callable[[langchain.tools.base.ToolException], str], NoneType] = False, root_dir: Optional[str] = None) -> None\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      CopyFileTool\n",
      "     |      langchain.tools.file_management.utils.BaseFileToolMixin\n",
      "     |      langchain.tools.base.BaseTool\n",
      "     |      abc.ABC\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'args_schema': typing.Type[pydantic.main.BaseModel]...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.tools.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'args_schema': ModelField(name='args_schema', type=Type[...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function BaseTool.raise_deprecati...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {}\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, name: str = 'copy_file', descript...= F...\n",
      "     |  \n",
      "     |  __validators__ = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.tools.file_management.utils.BaseFileToolMixin:\n",
      "     |  \n",
      "     |  get_relative_path(self, file_path: str) -> pathlib.Path\n",
      "     |      Get the relative path, returning an error if unsupported.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  __call__(self, tool_input: 'str', callbacks: 'Callbacks' = None) -> 'str'\n",
      "     |      Make tool callable.\n",
      "     |  \n",
      "     |  async arun(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool asynchronously.\n",
      "     |  \n",
      "     |  run(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  raise_deprecation(values: 'Dict') -> 'Dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  args\n",
      "     |  \n",
      "     |  is_single_input\n",
      "     |      Whether the tool only accepts a single input.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.tools.base.BaseTool.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __init__(__pydantic_self__, **data: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  dict(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> 'DictStrAny'\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class CurrentWebPageTool(langchain.tools.playwright.base.BaseBrowserTool)\n",
      "     |  CurrentWebPageTool(*, name: str = 'current_webpage', description: str = 'Returns the URL of the current page', args_schema: Type[pydantic.main.BaseModel] = <class 'pydantic.main.BaseModel'>, return_direct: bool = False, verbose: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, handle_tool_error: Union[bool, str, Callable[[langchain.tools.base.ToolException], str], NoneType] = False, sync_browser: ForwardRef(\"Optional['SyncBrowser']\") = None, async_browser: ForwardRef(\"Optional['AsyncBrowser']\") = None) -> None\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      CurrentWebPageTool\n",
      "     |      langchain.tools.playwright.base.BaseBrowserTool\n",
      "     |      langchain.tools.base.BaseTool\n",
      "     |      abc.ABC\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'args_schema': 'Type[BaseModel]', 'description': 's...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.tools.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'args_schema': ModelField(name='args_schema', type=Type[...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function BaseTool.raise_deprecati...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {}\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, name: str = 'current_webpage', de...dRe...\n",
      "     |  \n",
      "     |  __validators__ = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.tools.playwright.base.BaseBrowserTool:\n",
      "     |  \n",
      "     |  from_browser(sync_browser: 'Optional[SyncBrowser]' = None, async_browser: 'Optional[AsyncBrowser]' = None) -> 'BaseBrowserTool' from langchain.tools.base.ToolMetaclass\n",
      "     |      Instantiate the tool.\n",
      "     |  \n",
      "     |  validate_browser_provided(values: 'dict') -> 'dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Check that the arguments are valid.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  __call__(self, tool_input: 'str', callbacks: 'Callbacks' = None) -> 'str'\n",
      "     |      Make tool callable.\n",
      "     |  \n",
      "     |  async arun(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool asynchronously.\n",
      "     |  \n",
      "     |  run(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  raise_deprecation(values: 'Dict') -> 'Dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  args\n",
      "     |  \n",
      "     |  is_single_input\n",
      "     |      Whether the tool only accepts a single input.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.tools.base.BaseTool.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __init__(__pydantic_self__, **data: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  dict(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> 'DictStrAny'\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class DeleteFileTool(langchain.tools.file_management.utils.BaseFileToolMixin, langchain.tools.base.BaseTool)\n",
      "     |  DeleteFileTool(*, name: str = 'file_delete', description: str = 'Delete a file', args_schema: Type[pydantic.main.BaseModel] = <class 'langchain.tools.file_management.delete.FileDeleteInput'>, return_direct: bool = False, verbose: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, handle_tool_error: Union[bool, str, Callable[[langchain.tools.base.ToolException], str], NoneType] = False, root_dir: Optional[str] = None) -> None\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      DeleteFileTool\n",
      "     |      langchain.tools.file_management.utils.BaseFileToolMixin\n",
      "     |      langchain.tools.base.BaseTool\n",
      "     |      abc.ABC\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'args_schema': typing.Type[pydantic.main.BaseModel]...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.tools.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'args_schema': ModelField(name='args_schema', type=Type[...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function BaseTool.raise_deprecati...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {}\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, name: str = 'file_delete', descri...= F...\n",
      "     |  \n",
      "     |  __validators__ = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.tools.file_management.utils.BaseFileToolMixin:\n",
      "     |  \n",
      "     |  get_relative_path(self, file_path: str) -> pathlib.Path\n",
      "     |      Get the relative path, returning an error if unsupported.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  __call__(self, tool_input: 'str', callbacks: 'Callbacks' = None) -> 'str'\n",
      "     |      Make tool callable.\n",
      "     |  \n",
      "     |  async arun(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool asynchronously.\n",
      "     |  \n",
      "     |  run(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  raise_deprecation(values: 'Dict') -> 'Dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  args\n",
      "     |  \n",
      "     |  is_single_input\n",
      "     |      Whether the tool only accepts a single input.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.tools.base.BaseTool.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __init__(__pydantic_self__, **data: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  dict(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> 'DictStrAny'\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class DuckDuckGoSearchResults(langchain.tools.base.BaseTool)\n",
      "     |  DuckDuckGoSearchResults(*, name: str = 'DuckDuckGo Results JSON', description: str = 'A wrapper around Duck Duck Go Search. Useful for when you need to answer questions about current events. Input should be a search query. Output is a JSON array of the query results', args_schema: Optional[Type[pydantic.main.BaseModel]] = None, return_direct: bool = False, verbose: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, handle_tool_error: Union[bool, str, Callable[[langchain.tools.base.ToolException], str], NoneType] = False, num_results: int = 4, api_wrapper: langchain.utilities.duckduckgo_search.DuckDuckGoSearchAPIWrapper = None) -> None\n",
      "     |  \n",
      "     |  Tool that queries the Duck Duck Go Search API and get back json.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      DuckDuckGoSearchResults\n",
      "     |      langchain.tools.base.BaseTool\n",
      "     |      abc.ABC\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'api_wrapper': <class 'langchain.utilities.duckduck...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.tools.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'api_wrapper': ModelField(name='api_wrapper', type=DuckD...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function BaseTool.raise_deprecati...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {}\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, name: str = 'DuckDuckGo Results J...ear...\n",
      "     |  \n",
      "     |  __validators__ = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  __call__(self, tool_input: 'str', callbacks: 'Callbacks' = None) -> 'str'\n",
      "     |      Make tool callable.\n",
      "     |  \n",
      "     |  async arun(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool asynchronously.\n",
      "     |  \n",
      "     |  run(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  raise_deprecation(values: 'Dict') -> 'Dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  args\n",
      "     |  \n",
      "     |  is_single_input\n",
      "     |      Whether the tool only accepts a single input.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.tools.base.BaseTool.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __init__(__pydantic_self__, **data: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  dict(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> 'DictStrAny'\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class DuckDuckGoSearchRun(langchain.tools.base.BaseTool)\n",
      "     |  DuckDuckGoSearchRun(*, name: str = 'duckduckgo_search', description: str = 'A wrapper around DuckDuckGo Search. Useful for when you need to answer questions about current events. Input should be a search query.', args_schema: Optional[Type[pydantic.main.BaseModel]] = None, return_direct: bool = False, verbose: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, handle_tool_error: Union[bool, str, Callable[[langchain.tools.base.ToolException], str], NoneType] = False, api_wrapper: langchain.utilities.duckduckgo_search.DuckDuckGoSearchAPIWrapper = None) -> None\n",
      "     |  \n",
      "     |  Tool that adds the capability to query the DuckDuckGo search API.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      DuckDuckGoSearchRun\n",
      "     |      langchain.tools.base.BaseTool\n",
      "     |      abc.ABC\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'api_wrapper': <class 'langchain.utilities.duckduck...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.tools.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'api_wrapper': ModelField(name='api_wrapper', type=DuckD...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function BaseTool.raise_deprecati...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {}\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, name: str = 'duckduckgo_search', ...ear...\n",
      "     |  \n",
      "     |  __validators__ = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  __call__(self, tool_input: 'str', callbacks: 'Callbacks' = None) -> 'str'\n",
      "     |      Make tool callable.\n",
      "     |  \n",
      "     |  async arun(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool asynchronously.\n",
      "     |  \n",
      "     |  run(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  raise_deprecation(values: 'Dict') -> 'Dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  args\n",
      "     |  \n",
      "     |  is_single_input\n",
      "     |      Whether the tool only accepts a single input.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.tools.base.BaseTool.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __init__(__pydantic_self__, **data: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  dict(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> 'DictStrAny'\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class ExtractHyperlinksTool(langchain.tools.playwright.base.BaseBrowserTool)\n",
      "     |  ExtractHyperlinksTool(*, name: str = 'extract_hyperlinks', description: str = 'Extract all hyperlinks on the current webpage', args_schema: Type[pydantic.main.BaseModel] = <class 'langchain.tools.playwright.extract_hyperlinks.ExtractHyperlinksToolInput'>, return_direct: bool = False, verbose: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, handle_tool_error: Union[bool, str, Callable[[langchain.tools.base.ToolException], str], NoneType] = False, sync_browser: ForwardRef(\"Optional['SyncBrowser']\") = None, async_browser: ForwardRef(\"Optional['AsyncBrowser']\") = None) -> None\n",
      "     |  \n",
      "     |  Extract all hyperlinks on the page.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ExtractHyperlinksTool\n",
      "     |      langchain.tools.playwright.base.BaseBrowserTool\n",
      "     |      langchain.tools.base.BaseTool\n",
      "     |      abc.ABC\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  check_bs_import(values: 'dict') -> 'dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Check that the arguments are valid.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  scrape_page(page: 'Any', html_content: 'str', absolute_urls: 'bool') -> 'str'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'args_schema': 'Type[BaseModel]', 'description': 's...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.tools.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'args_schema': ModelField(name='args_schema', type=Type[...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function BaseTool.raise_deprecati...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {}\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, name: str = 'extract_hyperlinks',...dRe...\n",
      "     |  \n",
      "     |  __validators__ = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.tools.playwright.base.BaseBrowserTool:\n",
      "     |  \n",
      "     |  from_browser(sync_browser: 'Optional[SyncBrowser]' = None, async_browser: 'Optional[AsyncBrowser]' = None) -> 'BaseBrowserTool' from langchain.tools.base.ToolMetaclass\n",
      "     |      Instantiate the tool.\n",
      "     |  \n",
      "     |  validate_browser_provided(values: 'dict') -> 'dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Check that the arguments are valid.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  __call__(self, tool_input: 'str', callbacks: 'Callbacks' = None) -> 'str'\n",
      "     |      Make tool callable.\n",
      "     |  \n",
      "     |  async arun(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool asynchronously.\n",
      "     |  \n",
      "     |  run(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  raise_deprecation(values: 'Dict') -> 'Dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  args\n",
      "     |  \n",
      "     |  is_single_input\n",
      "     |      Whether the tool only accepts a single input.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.tools.base.BaseTool.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __init__(__pydantic_self__, **data: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  dict(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> 'DictStrAny'\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class ExtractTextTool(langchain.tools.playwright.base.BaseBrowserTool)\n",
      "     |  ExtractTextTool(*, name: str = 'extract_text', description: str = 'Extract all the text on the current webpage', args_schema: Type[pydantic.main.BaseModel] = <class 'pydantic.main.BaseModel'>, return_direct: bool = False, verbose: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, handle_tool_error: Union[bool, str, Callable[[langchain.tools.base.ToolException], str], NoneType] = False, sync_browser: ForwardRef(\"Optional['SyncBrowser']\") = None, async_browser: ForwardRef(\"Optional['AsyncBrowser']\") = None) -> None\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ExtractTextTool\n",
      "     |      langchain.tools.playwright.base.BaseBrowserTool\n",
      "     |      langchain.tools.base.BaseTool\n",
      "     |      abc.ABC\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  check_acheck_bs_importrgs(values: 'dict') -> 'dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Check that the arguments are valid.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'args_schema': 'Type[BaseModel]', 'description': 's...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.tools.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'args_schema': ModelField(name='args_schema', type=Type[...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function BaseTool.raise_deprecati...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {}\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, name: str = 'extract_text', descr...dRe...\n",
      "     |  \n",
      "     |  __validators__ = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.tools.playwright.base.BaseBrowserTool:\n",
      "     |  \n",
      "     |  from_browser(sync_browser: 'Optional[SyncBrowser]' = None, async_browser: 'Optional[AsyncBrowser]' = None) -> 'BaseBrowserTool' from langchain.tools.base.ToolMetaclass\n",
      "     |      Instantiate the tool.\n",
      "     |  \n",
      "     |  validate_browser_provided(values: 'dict') -> 'dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Check that the arguments are valid.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  __call__(self, tool_input: 'str', callbacks: 'Callbacks' = None) -> 'str'\n",
      "     |      Make tool callable.\n",
      "     |  \n",
      "     |  async arun(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool asynchronously.\n",
      "     |  \n",
      "     |  run(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  raise_deprecation(values: 'Dict') -> 'Dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  args\n",
      "     |  \n",
      "     |  is_single_input\n",
      "     |      Whether the tool only accepts a single input.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.tools.base.BaseTool.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __init__(__pydantic_self__, **data: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  dict(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> 'DictStrAny'\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class FileSearchTool(langchain.tools.file_management.utils.BaseFileToolMixin, langchain.tools.base.BaseTool)\n",
      "     |  FileSearchTool(*, name: str = 'file_search', description: str = 'Recursively search for files in a subdirectory that match the regex pattern', args_schema: Type[pydantic.main.BaseModel] = <class 'langchain.tools.file_management.file_search.FileSearchInput'>, return_direct: bool = False, verbose: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, handle_tool_error: Union[bool, str, Callable[[langchain.tools.base.ToolException], str], NoneType] = False, root_dir: Optional[str] = None) -> None\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      FileSearchTool\n",
      "     |      langchain.tools.file_management.utils.BaseFileToolMixin\n",
      "     |      langchain.tools.base.BaseTool\n",
      "     |      abc.ABC\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'args_schema': typing.Type[pydantic.main.BaseModel]...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.tools.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'args_schema': ModelField(name='args_schema', type=Type[...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function BaseTool.raise_deprecati...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {}\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, name: str = 'file_search', descri...= F...\n",
      "     |  \n",
      "     |  __validators__ = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.tools.file_management.utils.BaseFileToolMixin:\n",
      "     |  \n",
      "     |  get_relative_path(self, file_path: str) -> pathlib.Path\n",
      "     |      Get the relative path, returning an error if unsupported.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  __call__(self, tool_input: 'str', callbacks: 'Callbacks' = None) -> 'str'\n",
      "     |      Make tool callable.\n",
      "     |  \n",
      "     |  async arun(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool asynchronously.\n",
      "     |  \n",
      "     |  run(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  raise_deprecation(values: 'Dict') -> 'Dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  args\n",
      "     |  \n",
      "     |  is_single_input\n",
      "     |      Whether the tool only accepts a single input.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.tools.base.BaseTool.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __init__(__pydantic_self__, **data: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  dict(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> 'DictStrAny'\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class GetElementsTool(langchain.tools.playwright.base.BaseBrowserTool)\n",
      "     |  GetElementsTool(*, name: str = 'get_elements', description: str = 'Retrieve elements in the current web page matching the given CSS selector', args_schema: Type[pydantic.main.BaseModel] = <class 'langchain.tools.playwright.get_elements.GetElementsToolInput'>, return_direct: bool = False, verbose: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, handle_tool_error: Union[bool, str, Callable[[langchain.tools.base.ToolException], str], NoneType] = False, sync_browser: ForwardRef(\"Optional['SyncBrowser']\") = None, async_browser: ForwardRef(\"Optional['AsyncBrowser']\") = None) -> None\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      GetElementsTool\n",
      "     |      langchain.tools.playwright.base.BaseBrowserTool\n",
      "     |      langchain.tools.base.BaseTool\n",
      "     |      abc.ABC\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'args_schema': 'Type[BaseModel]', 'description': 's...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.tools.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'args_schema': ModelField(name='args_schema', type=Type[...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function BaseTool.raise_deprecati...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {}\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, name: str = 'get_elements', descr...dRe...\n",
      "     |  \n",
      "     |  __validators__ = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.tools.playwright.base.BaseBrowserTool:\n",
      "     |  \n",
      "     |  from_browser(sync_browser: 'Optional[SyncBrowser]' = None, async_browser: 'Optional[AsyncBrowser]' = None) -> 'BaseBrowserTool' from langchain.tools.base.ToolMetaclass\n",
      "     |      Instantiate the tool.\n",
      "     |  \n",
      "     |  validate_browser_provided(values: 'dict') -> 'dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Check that the arguments are valid.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  __call__(self, tool_input: 'str', callbacks: 'Callbacks' = None) -> 'str'\n",
      "     |      Make tool callable.\n",
      "     |  \n",
      "     |  async arun(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool asynchronously.\n",
      "     |  \n",
      "     |  run(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  raise_deprecation(values: 'Dict') -> 'Dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  args\n",
      "     |  \n",
      "     |  is_single_input\n",
      "     |      Whether the tool only accepts a single input.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.tools.base.BaseTool.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __init__(__pydantic_self__, **data: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  dict(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> 'DictStrAny'\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class GmailCreateDraft(langchain.tools.gmail.base.GmailBaseTool)\n",
      "     |  GmailCreateDraft(*, name: str = 'create_gmail_draft', description: str = 'Use this tool to create a draft email with the provided message fields.', args_schema: Type[langchain.tools.gmail.create_draft.CreateDraftSchema] = <class 'langchain.tools.gmail.create_draft.CreateDraftSchema'>, return_direct: bool = False, verbose: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, handle_tool_error: Union[bool, str, Callable[[langchain.tools.base.ToolException], str], NoneType] = False, api_resource: ForwardRef('Resource') = None) -> None\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      GmailCreateDraft\n",
      "     |      langchain.tools.gmail.base.GmailBaseTool\n",
      "     |      langchain.tools.base.BaseTool\n",
      "     |      abc.ABC\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'args_schema': typing.Type[langchain.tools.gmail.cr...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.tools.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'api_resource': ModelField(name='api_resource', type=For...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function BaseTool.raise_deprecati...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {}\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, name: str = 'create_gmail_draft',...res...\n",
      "     |  \n",
      "     |  __validators__ = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.tools.gmail.base.GmailBaseTool:\n",
      "     |  \n",
      "     |  from_api_resource(api_resource: 'Resource') -> \"'GmailBaseTool'\" from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  __call__(self, tool_input: 'str', callbacks: 'Callbacks' = None) -> 'str'\n",
      "     |      Make tool callable.\n",
      "     |  \n",
      "     |  async arun(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool asynchronously.\n",
      "     |  \n",
      "     |  run(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  raise_deprecation(values: 'Dict') -> 'Dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  args\n",
      "     |  \n",
      "     |  is_single_input\n",
      "     |      Whether the tool only accepts a single input.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.tools.base.BaseTool.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __init__(__pydantic_self__, **data: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  dict(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> 'DictStrAny'\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class GmailGetMessage(langchain.tools.gmail.base.GmailBaseTool)\n",
      "     |  GmailGetMessage(*, name: str = 'get_gmail_message', description: str = 'Use this tool to fetch an email by message ID. Returns the thread ID, snipet, body, subject, and sender.', args_schema: Type[langchain.tools.gmail.get_message.SearchArgsSchema] = <class 'langchain.tools.gmail.get_message.SearchArgsSchema'>, return_direct: bool = False, verbose: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, handle_tool_error: Union[bool, str, Callable[[langchain.tools.base.ToolException], str], NoneType] = False, api_resource: ForwardRef('Resource') = None) -> None\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      GmailGetMessage\n",
      "     |      langchain.tools.gmail.base.GmailBaseTool\n",
      "     |      langchain.tools.base.BaseTool\n",
      "     |      abc.ABC\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'args_schema': typing.Type[langchain.tools.gmail.ge...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.tools.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'api_resource': ModelField(name='api_resource', type=For...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function BaseTool.raise_deprecati...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {}\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, name: str = 'get_gmail_message', ...res...\n",
      "     |  \n",
      "     |  __validators__ = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.tools.gmail.base.GmailBaseTool:\n",
      "     |  \n",
      "     |  from_api_resource(api_resource: 'Resource') -> \"'GmailBaseTool'\" from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  __call__(self, tool_input: 'str', callbacks: 'Callbacks' = None) -> 'str'\n",
      "     |      Make tool callable.\n",
      "     |  \n",
      "     |  async arun(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool asynchronously.\n",
      "     |  \n",
      "     |  run(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  raise_deprecation(values: 'Dict') -> 'Dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  args\n",
      "     |  \n",
      "     |  is_single_input\n",
      "     |      Whether the tool only accepts a single input.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.tools.base.BaseTool.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __init__(__pydantic_self__, **data: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  dict(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> 'DictStrAny'\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class GmailGetThread(langchain.tools.gmail.base.GmailBaseTool)\n",
      "     |  GmailGetThread(*, name: str = 'get_gmail_thread', description: str = 'Use this tool to search for email messages. The input must be a valid Gmail query. The output is a JSON list of messages.', args_schema: Type[langchain.tools.gmail.get_thread.GetThreadSchema] = <class 'langchain.tools.gmail.get_thread.GetThreadSchema'>, return_direct: bool = False, verbose: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, handle_tool_error: Union[bool, str, Callable[[langchain.tools.base.ToolException], str], NoneType] = False, api_resource: ForwardRef('Resource') = None) -> None\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      GmailGetThread\n",
      "     |      langchain.tools.gmail.base.GmailBaseTool\n",
      "     |      langchain.tools.base.BaseTool\n",
      "     |      abc.ABC\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'args_schema': typing.Type[langchain.tools.gmail.ge...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.tools.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'api_resource': ModelField(name='api_resource', type=For...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function BaseTool.raise_deprecati...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {}\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, name: str = 'get_gmail_thread', d...res...\n",
      "     |  \n",
      "     |  __validators__ = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.tools.gmail.base.GmailBaseTool:\n",
      "     |  \n",
      "     |  from_api_resource(api_resource: 'Resource') -> \"'GmailBaseTool'\" from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  __call__(self, tool_input: 'str', callbacks: 'Callbacks' = None) -> 'str'\n",
      "     |      Make tool callable.\n",
      "     |  \n",
      "     |  async arun(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool asynchronously.\n",
      "     |  \n",
      "     |  run(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  raise_deprecation(values: 'Dict') -> 'Dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  args\n",
      "     |  \n",
      "     |  is_single_input\n",
      "     |      Whether the tool only accepts a single input.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.tools.base.BaseTool.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __init__(__pydantic_self__, **data: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  dict(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> 'DictStrAny'\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class GmailSearch(langchain.tools.gmail.base.GmailBaseTool)\n",
      "     |  GmailSearch(*, name: str = 'search_gmail', description: str = 'Use this tool to search for email messages or threads. The input must be a valid Gmail query. The output is a JSON list of the requested resource.', args_schema: Type[langchain.tools.gmail.search.SearchArgsSchema] = <class 'langchain.tools.gmail.search.SearchArgsSchema'>, return_direct: bool = False, verbose: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, handle_tool_error: Union[bool, str, Callable[[langchain.tools.base.ToolException], str], NoneType] = False, api_resource: ForwardRef('Resource') = None) -> None\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      GmailSearch\n",
      "     |      langchain.tools.gmail.base.GmailBaseTool\n",
      "     |      langchain.tools.base.BaseTool\n",
      "     |      abc.ABC\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'args_schema': typing.Type[langchain.tools.gmail.se...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.tools.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'api_resource': ModelField(name='api_resource', type=Res...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function BaseTool.raise_deprecati...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {}\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, name: str = 'search_gmail', descr...res...\n",
      "     |  \n",
      "     |  __validators__ = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.tools.gmail.base.GmailBaseTool:\n",
      "     |  \n",
      "     |  from_api_resource(api_resource: 'Resource') -> \"'GmailBaseTool'\" from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  __call__(self, tool_input: 'str', callbacks: 'Callbacks' = None) -> 'str'\n",
      "     |      Make tool callable.\n",
      "     |  \n",
      "     |  async arun(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool asynchronously.\n",
      "     |  \n",
      "     |  run(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  raise_deprecation(values: 'Dict') -> 'Dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  args\n",
      "     |  \n",
      "     |  is_single_input\n",
      "     |      Whether the tool only accepts a single input.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.tools.base.BaseTool.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __init__(__pydantic_self__, **data: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  dict(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> 'DictStrAny'\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class GmailSendMessage(langchain.tools.gmail.base.GmailBaseTool)\n",
      "     |  GmailSendMessage(*, name: str = 'send_gmail_message', description: str = 'Use this tool to send email messages. The input is the message, recipents', args_schema: Optional[Type[pydantic.main.BaseModel]] = None, return_direct: bool = False, verbose: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, handle_tool_error: Union[bool, str, Callable[[langchain.tools.base.ToolException], str], NoneType] = False, api_resource: ForwardRef('Resource') = None) -> None\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      GmailSendMessage\n",
      "     |      langchain.tools.gmail.base.GmailBaseTool\n",
      "     |      langchain.tools.base.BaseTool\n",
      "     |      abc.ABC\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'description': <class 'str'>, 'name': <class 'str'>...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.tools.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'api_resource': ModelField(name='api_resource', type=For...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function BaseTool.raise_deprecati...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {}\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, name: str = 'send_gmail_message',...res...\n",
      "     |  \n",
      "     |  __validators__ = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.tools.gmail.base.GmailBaseTool:\n",
      "     |  \n",
      "     |  from_api_resource(api_resource: 'Resource') -> \"'GmailBaseTool'\" from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  __call__(self, tool_input: 'str', callbacks: 'Callbacks' = None) -> 'str'\n",
      "     |      Make tool callable.\n",
      "     |  \n",
      "     |  async arun(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool asynchronously.\n",
      "     |  \n",
      "     |  run(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  raise_deprecation(values: 'Dict') -> 'Dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  args\n",
      "     |  \n",
      "     |  is_single_input\n",
      "     |      Whether the tool only accepts a single input.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.tools.base.BaseTool.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __init__(__pydantic_self__, **data: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  dict(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> 'DictStrAny'\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class GooglePlacesTool(langchain.tools.base.BaseTool)\n",
      "     |  GooglePlacesTool(*, name: str = 'google_places', description: str = 'A wrapper around Google Places. Useful for when you need to validate or discover addressed from ambiguous text. Input should be a search query.', args_schema: Type[pydantic.main.BaseModel] = <class 'langchain.tools.google_places.tool.GooglePlacesSchema'>, return_direct: bool = False, verbose: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, handle_tool_error: Union[bool, str, Callable[[langchain.tools.base.ToolException], str], NoneType] = False, api_wrapper: langchain.utilities.google_places_api.GooglePlacesAPIWrapper = None) -> None\n",
      "     |  \n",
      "     |  Tool that adds the capability to query the Google places API.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      GooglePlacesTool\n",
      "     |      langchain.tools.base.BaseTool\n",
      "     |      abc.ABC\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'api_wrapper': <class 'langchain.utilities.google_p...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.tools.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'api_wrapper': ModelField(name='api_wrapper', type=Googl...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function BaseTool.raise_deprecati...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {}\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, name: str = 'google_places', desc...lac...\n",
      "     |  \n",
      "     |  __validators__ = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  __call__(self, tool_input: 'str', callbacks: 'Callbacks' = None) -> 'str'\n",
      "     |      Make tool callable.\n",
      "     |  \n",
      "     |  async arun(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool asynchronously.\n",
      "     |  \n",
      "     |  run(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  raise_deprecation(values: 'Dict') -> 'Dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  args\n",
      "     |  \n",
      "     |  is_single_input\n",
      "     |      Whether the tool only accepts a single input.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.tools.base.BaseTool.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __init__(__pydantic_self__, **data: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  dict(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> 'DictStrAny'\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class GoogleSearchResults(langchain.tools.base.BaseTool)\n",
      "     |  GoogleSearchResults(*, name: str = 'Google Search Results JSON', description: str = 'A wrapper around Google Search. Useful for when you need to answer questions about current events. Input should be a search query. Output is a JSON array of the query results', args_schema: Optional[Type[pydantic.main.BaseModel]] = None, return_direct: bool = False, verbose: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, handle_tool_error: Union[bool, str, Callable[[langchain.tools.base.ToolException], str], NoneType] = False, num_results: int = 4, api_wrapper: langchain.utilities.google_search.GoogleSearchAPIWrapper) -> None\n",
      "     |  \n",
      "     |  Tool that has capability to query the Google Search API and get back json.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      GoogleSearchResults\n",
      "     |      langchain.tools.base.BaseTool\n",
      "     |      abc.ABC\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'api_wrapper': <class 'langchain.utilities.google_s...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.tools.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'api_wrapper': ModelField(name='api_wrapper', type=Googl...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function BaseTool.raise_deprecati...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {}\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, name: str = 'Google Search Result...es....\n",
      "     |  \n",
      "     |  __validators__ = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  __call__(self, tool_input: 'str', callbacks: 'Callbacks' = None) -> 'str'\n",
      "     |      Make tool callable.\n",
      "     |  \n",
      "     |  async arun(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool asynchronously.\n",
      "     |  \n",
      "     |  run(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  raise_deprecation(values: 'Dict') -> 'Dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  args\n",
      "     |  \n",
      "     |  is_single_input\n",
      "     |      Whether the tool only accepts a single input.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.tools.base.BaseTool.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __init__(__pydantic_self__, **data: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  dict(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> 'DictStrAny'\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class GoogleSearchRun(langchain.tools.base.BaseTool)\n",
      "     |  GoogleSearchRun(*, name: str = 'google_search', description: str = 'A wrapper around Google Search. Useful for when you need to answer questions about current events. Input should be a search query.', args_schema: Optional[Type[pydantic.main.BaseModel]] = None, return_direct: bool = False, verbose: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, handle_tool_error: Union[bool, str, Callable[[langchain.tools.base.ToolException], str], NoneType] = False, api_wrapper: langchain.utilities.google_search.GoogleSearchAPIWrapper) -> None\n",
      "     |  \n",
      "     |  Tool that adds the capability to query the Google search API.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      GoogleSearchRun\n",
      "     |      langchain.tools.base.BaseTool\n",
      "     |      abc.ABC\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'api_wrapper': <class 'langchain.utilities.google_s...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.tools.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'api_wrapper': ModelField(name='api_wrapper', type=Googl...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function BaseTool.raise_deprecati...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {}\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, name: str = 'google_search', desc...es....\n",
      "     |  \n",
      "     |  __validators__ = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  __call__(self, tool_input: 'str', callbacks: 'Callbacks' = None) -> 'str'\n",
      "     |      Make tool callable.\n",
      "     |  \n",
      "     |  async arun(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool asynchronously.\n",
      "     |  \n",
      "     |  run(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  raise_deprecation(values: 'Dict') -> 'Dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  args\n",
      "     |  \n",
      "     |  is_single_input\n",
      "     |      Whether the tool only accepts a single input.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.tools.base.BaseTool.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __init__(__pydantic_self__, **data: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  dict(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> 'DictStrAny'\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class GoogleSerperResults(langchain.tools.base.BaseTool)\n",
      "     |  GoogleSerperResults(*, name: str = 'Google Serrper Results JSON', description: str = 'A low-cost Google Search API.Useful for when you need to answer questions about current events.Input should be a search query. Output is a JSON object of the query results', args_schema: Optional[Type[pydantic.main.BaseModel]] = None, return_direct: bool = False, verbose: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, handle_tool_error: Union[bool, str, Callable[[langchain.tools.base.ToolException], str], NoneType] = False, api_wrapper: langchain.utilities.google_serper.GoogleSerperAPIWrapper = None) -> None\n",
      "     |  \n",
      "     |  Tool that has capability to query the Serper.dev Google Search API\n",
      "     |  and get back json.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      GoogleSerperResults\n",
      "     |      langchain.tools.base.BaseTool\n",
      "     |      abc.ABC\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'api_wrapper': <class 'langchain.utilities.google_s...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.tools.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'api_wrapper': ModelField(name='api_wrapper', type=Googl...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function BaseTool.raise_deprecati...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {}\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, name: str = 'Google Serrper Resul...le_...\n",
      "     |  \n",
      "     |  __validators__ = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  __call__(self, tool_input: 'str', callbacks: 'Callbacks' = None) -> 'str'\n",
      "     |      Make tool callable.\n",
      "     |  \n",
      "     |  async arun(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool asynchronously.\n",
      "     |  \n",
      "     |  run(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  raise_deprecation(values: 'Dict') -> 'Dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  args\n",
      "     |  \n",
      "     |  is_single_input\n",
      "     |      Whether the tool only accepts a single input.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.tools.base.BaseTool.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __init__(__pydantic_self__, **data: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  dict(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> 'DictStrAny'\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class GoogleSerperRun(langchain.tools.base.BaseTool)\n",
      "     |  GoogleSerperRun(*, name: str = 'google_serper', description: str = 'A low-cost Google Search API.Useful for when you need to answer questions about current events.Input should be a search query.', args_schema: Optional[Type[pydantic.main.BaseModel]] = None, return_direct: bool = False, verbose: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, handle_tool_error: Union[bool, str, Callable[[langchain.tools.base.ToolException], str], NoneType] = False, api_wrapper: langchain.utilities.google_serper.GoogleSerperAPIWrapper) -> None\n",
      "     |  \n",
      "     |  Tool that adds the capability to query the Serper.dev Google search API.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      GoogleSerperRun\n",
      "     |      langchain.tools.base.BaseTool\n",
      "     |      abc.ABC\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'api_wrapper': <class 'langchain.utilities.google_s...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.tools.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'api_wrapper': ModelField(name='api_wrapper', type=Googl...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function BaseTool.raise_deprecati...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {}\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, name: str = 'google_serper', desc...es....\n",
      "     |  \n",
      "     |  __validators__ = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  __call__(self, tool_input: 'str', callbacks: 'Callbacks' = None) -> 'str'\n",
      "     |      Make tool callable.\n",
      "     |  \n",
      "     |  async arun(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool asynchronously.\n",
      "     |  \n",
      "     |  run(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  raise_deprecation(values: 'Dict') -> 'Dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  args\n",
      "     |  \n",
      "     |  is_single_input\n",
      "     |      Whether the tool only accepts a single input.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.tools.base.BaseTool.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __init__(__pydantic_self__, **data: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  dict(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> 'DictStrAny'\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class HumanInputRun(langchain.tools.base.BaseTool)\n",
      "     |  HumanInputRun(*, name: str = 'human', description: str = 'You can ask a human for guidance when you think you got stuck or you are not sure what to do next. The input should be a question for the human.', args_schema: Optional[Type[pydantic.main.BaseModel]] = None, return_direct: bool = False, verbose: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, handle_tool_error: Union[bool, str, Callable[[langchain.tools.base.ToolException], str], NoneType] = False, prompt_func: Callable[[str], NoneType] = None, input_func: Callable = None) -> None\n",
      "     |  \n",
      "     |  Tool that adds the capability to ask user for input.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      HumanInputRun\n",
      "     |      langchain.tools.base.BaseTool\n",
      "     |      abc.ABC\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'input_func': typing.Callable, 'prompt_func': typin...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.tools.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'args_schema': ModelField(name='args_schema', type=Optio...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function BaseTool.raise_deprecati...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {}\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, name: str = 'human', description:...pe]...\n",
      "     |  \n",
      "     |  __validators__ = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  __call__(self, tool_input: 'str', callbacks: 'Callbacks' = None) -> 'str'\n",
      "     |      Make tool callable.\n",
      "     |  \n",
      "     |  async arun(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool asynchronously.\n",
      "     |  \n",
      "     |  run(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  raise_deprecation(values: 'Dict') -> 'Dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  args\n",
      "     |  \n",
      "     |  is_single_input\n",
      "     |      Whether the tool only accepts a single input.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.tools.base.BaseTool.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __init__(__pydantic_self__, **data: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  dict(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> 'DictStrAny'\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class IFTTTWebhook(langchain.tools.base.BaseTool)\n",
      "     |  IFTTTWebhook(*, name: str, description: str, args_schema: Optional[Type[pydantic.main.BaseModel]] = None, return_direct: bool = False, verbose: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, handle_tool_error: Union[bool, str, Callable[[langchain.tools.base.ToolException], str], NoneType] = False, url: str) -> None\n",
      "     |  \n",
      "     |  IFTTT Webhook.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      name: name of the tool\n",
      "     |      description: description of the tool\n",
      "     |      url: url to hit with the json event.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      IFTTTWebhook\n",
      "     |      langchain.tools.base.BaseTool\n",
      "     |      abc.ABC\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'url': <class 'str'>}\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.tools.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'args_schema': ModelField(name='args_schema', type=Optio...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function BaseTool.raise_deprecati...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {}\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, name: str, description: str, args...ion...\n",
      "     |  \n",
      "     |  __validators__ = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  __call__(self, tool_input: 'str', callbacks: 'Callbacks' = None) -> 'str'\n",
      "     |      Make tool callable.\n",
      "     |  \n",
      "     |  async arun(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool asynchronously.\n",
      "     |  \n",
      "     |  run(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  raise_deprecation(values: 'Dict') -> 'Dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  args\n",
      "     |  \n",
      "     |  is_single_input\n",
      "     |      Whether the tool only accepts a single input.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.tools.base.BaseTool.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __init__(__pydantic_self__, **data: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  dict(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> 'DictStrAny'\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class InfoPowerBITool(langchain.tools.base.BaseTool)\n",
      "     |  InfoPowerBITool(*, name: str = 'schema_powerbi', description: str = '\\n    Input to this tool is a comma-separated list of tables, output is the schema and sample rows for those tables.\\n    Be sure that the tables actually exist by calling list_tables_powerbi first!\\n\\n    Example Input: \"table1, table2, table3\"\\n    ', args_schema: Optional[Type[pydantic.main.BaseModel]] = None, return_direct: bool = False, verbose: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, handle_tool_error: Union[bool, str, Callable[[langchain.tools.base.ToolException], str], NoneType] = False, powerbi: langchain.utilities.powerbi.PowerBIDataset) -> None\n",
      "     |  \n",
      "     |  Tool for getting metadata about a PowerBI Dataset.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      InfoPowerBITool\n",
      "     |      langchain.tools.base.BaseTool\n",
      "     |      abc.ABC\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.tools.powerbi.tool.InfoPowerBITool.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'powerbi': <class 'langchain.utilities.powerbi.Powe...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.tools.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True, 'po...\n",
      "     |  \n",
      "     |  __fields__ = {'args_schema': ModelField(name='args_schema', type=Optio...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function BaseTool.raise_deprecati...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {}\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, name: str = 'schema_powerbi', des...gch...\n",
      "     |  \n",
      "     |  __validators__ = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  __call__(self, tool_input: 'str', callbacks: 'Callbacks' = None) -> 'str'\n",
      "     |      Make tool callable.\n",
      "     |  \n",
      "     |  async arun(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool asynchronously.\n",
      "     |  \n",
      "     |  run(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  raise_deprecation(values: 'Dict') -> 'Dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  args\n",
      "     |  \n",
      "     |  is_single_input\n",
      "     |      Whether the tool only accepts a single input.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __init__(__pydantic_self__, **data: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  dict(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> 'DictStrAny'\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class InfoSQLDatabaseTool(BaseSQLDatabaseTool, langchain.tools.base.BaseTool)\n",
      "     |  InfoSQLDatabaseTool(*, name: str = 'sql_db_schema', description: str = '\\n    Input to this tool is a comma-separated list of tables, output is the schema and sample rows for those tables.    \\n\\n    Example Input: \"table1, table2, table3\"\\n    ', args_schema: Optional[Type[pydantic.main.BaseModel]] = None, return_direct: bool = False, verbose: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, handle_tool_error: Union[bool, str, Callable[[langchain.tools.base.ToolException], str], NoneType] = False, db: langchain.sql_database.SQLDatabase) -> None\n",
      "     |  \n",
      "     |  Tool for getting metadata about a SQL database.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      InfoSQLDatabaseTool\n",
      "     |      BaseSQLDatabaseTool\n",
      "     |      langchain.tools.base.BaseTool\n",
      "     |      abc.ABC\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.tools.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True, 'db...\n",
      "     |  \n",
      "     |  __fields__ = {'args_schema': ModelField(name='args_schema', type=Optio...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function BaseTool.raise_deprecati...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {}\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, name: str = 'sql_db_schema', desc... db...\n",
      "     |  \n",
      "     |  __validators__ = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from BaseSQLDatabaseTool:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.tools.sql_database.tool.BaseSQLDatabaseTool...\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  __call__(self, tool_input: 'str', callbacks: 'Callbacks' = None) -> 'str'\n",
      "     |      Make tool callable.\n",
      "     |  \n",
      "     |  async arun(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool asynchronously.\n",
      "     |  \n",
      "     |  run(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  raise_deprecation(values: 'Dict') -> 'Dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  args\n",
      "     |  \n",
      "     |  is_single_input\n",
      "     |      Whether the tool only accepts a single input.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __init__(__pydantic_self__, **data: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  dict(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> 'DictStrAny'\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class InfoSparkSQLTool(BaseSparkSQLTool, langchain.tools.base.BaseTool)\n",
      "     |  InfoSparkSQLTool(*, name: str = 'schema_sql_db', description: str = '\\n    Input to this tool is a comma-separated list of tables, output is the schema and sample rows for those tables.\\n    Be sure that the tables actually exist by calling list_tables_sql_db first!\\n\\n    Example Input: \"table1, table2, table3\"\\n    ', args_schema: Optional[Type[pydantic.main.BaseModel]] = None, return_direct: bool = False, verbose: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, handle_tool_error: Union[bool, str, Callable[[langchain.tools.base.ToolException], str], NoneType] = False, db: langchain.utilities.spark_sql.SparkSQL) -> None\n",
      "     |  \n",
      "     |  Tool for getting metadata about a Spark SQL.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      InfoSparkSQLTool\n",
      "     |      BaseSparkSQLTool\n",
      "     |      langchain.tools.base.BaseTool\n",
      "     |      abc.ABC\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.tools.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True, 'db...\n",
      "     |  \n",
      "     |  __fields__ = {'args_schema': ModelField(name='args_schema', type=Optio...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function BaseTool.raise_deprecati...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {}\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, name: str = 'schema_sql_db', desc... la...\n",
      "     |  \n",
      "     |  __validators__ = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from BaseSparkSQLTool:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.tools.spark_sql.tool.BaseSparkSQLTool.Confi...\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  __call__(self, tool_input: 'str', callbacks: 'Callbacks' = None) -> 'str'\n",
      "     |      Make tool callable.\n",
      "     |  \n",
      "     |  async arun(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool asynchronously.\n",
      "     |  \n",
      "     |  run(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  raise_deprecation(values: 'Dict') -> 'Dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  args\n",
      "     |  \n",
      "     |  is_single_input\n",
      "     |      Whether the tool only accepts a single input.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __init__(__pydantic_self__, **data: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  dict(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> 'DictStrAny'\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class JiraAction(langchain.tools.base.BaseTool)\n",
      "     |  JiraAction(*, name: str = '', description: str = '', args_schema: Optional[Type[pydantic.main.BaseModel]] = None, return_direct: bool = False, verbose: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, handle_tool_error: Union[bool, str, Callable[[langchain.tools.base.ToolException], str], NoneType] = False, api_wrapper: langchain.utilities.jira.JiraAPIWrapper = None, mode: str) -> None\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      JiraAction\n",
      "     |      langchain.tools.base.BaseTool\n",
      "     |      abc.ABC\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'api_wrapper': <class 'langchain.utilities.jira.Jir...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.tools.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'api_wrapper': ModelField(name='api_wrapper', type=JiraA...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function BaseTool.raise_deprecati...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {}\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, name: str = '', description: str ...s.j...\n",
      "     |  \n",
      "     |  __validators__ = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  __call__(self, tool_input: 'str', callbacks: 'Callbacks' = None) -> 'str'\n",
      "     |      Make tool callable.\n",
      "     |  \n",
      "     |  async arun(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool asynchronously.\n",
      "     |  \n",
      "     |  run(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  raise_deprecation(values: 'Dict') -> 'Dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  args\n",
      "     |  \n",
      "     |  is_single_input\n",
      "     |      Whether the tool only accepts a single input.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.tools.base.BaseTool.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __init__(__pydantic_self__, **data: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  dict(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> 'DictStrAny'\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class JsonGetValueTool(langchain.tools.base.BaseTool)\n",
      "     |  JsonGetValueTool(*, name: str = 'json_spec_get_value', description: str = '\\n    Can be used to see value in string format at a given path.\\n    Before calling this you should be SURE that the path to this exists.\\n    The input is a text representation of the path to the dict in Python syntax (e.g. data[\"key1\"][0][\"key2\"]).\\n    ', args_schema: Optional[Type[pydantic.main.BaseModel]] = None, return_direct: bool = False, verbose: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, handle_tool_error: Union[bool, str, Callable[[langchain.tools.base.ToolException], str], NoneType] = False, spec: langchain.tools.json.tool.JsonSpec) -> None\n",
      "     |  \n",
      "     |  Tool for getting a value in a JSON spec.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      JsonGetValueTool\n",
      "     |      langchain.tools.base.BaseTool\n",
      "     |      abc.ABC\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'spec': 'JsonSpec'}\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.tools.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'args_schema': ModelField(name='args_schema', type=Optio...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function BaseTool.raise_deprecati...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {}\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, name: str = 'json_spec_get_value'...pec...\n",
      "     |  \n",
      "     |  __validators__ = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  __call__(self, tool_input: 'str', callbacks: 'Callbacks' = None) -> 'str'\n",
      "     |      Make tool callable.\n",
      "     |  \n",
      "     |  async arun(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool asynchronously.\n",
      "     |  \n",
      "     |  run(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  raise_deprecation(values: 'Dict') -> 'Dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  args\n",
      "     |  \n",
      "     |  is_single_input\n",
      "     |      Whether the tool only accepts a single input.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.tools.base.BaseTool.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __init__(__pydantic_self__, **data: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  dict(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> 'DictStrAny'\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class JsonListKeysTool(langchain.tools.base.BaseTool)\n",
      "     |  JsonListKeysTool(*, name: str = 'json_spec_list_keys', description: str = '\\n    Can be used to list all keys at a given path. \\n    Before calling this you should be SURE that the path to this exists.\\n    The input is a text representation of the path to the dict in Python syntax (e.g. data[\"key1\"][0][\"key2\"]).\\n    ', args_schema: Optional[Type[pydantic.main.BaseModel]] = None, return_direct: bool = False, verbose: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, handle_tool_error: Union[bool, str, Callable[[langchain.tools.base.ToolException], str], NoneType] = False, spec: langchain.tools.json.tool.JsonSpec) -> None\n",
      "     |  \n",
      "     |  Tool for listing keys in a JSON spec.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      JsonListKeysTool\n",
      "     |      langchain.tools.base.BaseTool\n",
      "     |      abc.ABC\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'spec': 'JsonSpec'}\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.tools.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'args_schema': ModelField(name='args_schema', type=Optio...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function BaseTool.raise_deprecati...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {}\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, name: str = 'json_spec_list_keys'...pec...\n",
      "     |  \n",
      "     |  __validators__ = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  __call__(self, tool_input: 'str', callbacks: 'Callbacks' = None) -> 'str'\n",
      "     |      Make tool callable.\n",
      "     |  \n",
      "     |  async arun(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool asynchronously.\n",
      "     |  \n",
      "     |  run(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  raise_deprecation(values: 'Dict') -> 'Dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  args\n",
      "     |  \n",
      "     |  is_single_input\n",
      "     |      Whether the tool only accepts a single input.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.tools.base.BaseTool.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __init__(__pydantic_self__, **data: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  dict(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> 'DictStrAny'\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class ListDirectoryTool(langchain.tools.file_management.utils.BaseFileToolMixin, langchain.tools.base.BaseTool)\n",
      "     |  ListDirectoryTool(*, name: str = 'list_directory', description: str = 'List files and directories in a specified folder', args_schema: Type[pydantic.main.BaseModel] = <class 'langchain.tools.file_management.list_dir.DirectoryListingInput'>, return_direct: bool = False, verbose: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, handle_tool_error: Union[bool, str, Callable[[langchain.tools.base.ToolException], str], NoneType] = False, root_dir: Optional[str] = None) -> None\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ListDirectoryTool\n",
      "     |      langchain.tools.file_management.utils.BaseFileToolMixin\n",
      "     |      langchain.tools.base.BaseTool\n",
      "     |      abc.ABC\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'args_schema': typing.Type[pydantic.main.BaseModel]...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.tools.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'args_schema': ModelField(name='args_schema', type=Type[...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function BaseTool.raise_deprecati...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {}\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, name: str = 'list_directory', des...= F...\n",
      "     |  \n",
      "     |  __validators__ = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.tools.file_management.utils.BaseFileToolMixin:\n",
      "     |  \n",
      "     |  get_relative_path(self, file_path: str) -> pathlib.Path\n",
      "     |      Get the relative path, returning an error if unsupported.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  __call__(self, tool_input: 'str', callbacks: 'Callbacks' = None) -> 'str'\n",
      "     |      Make tool callable.\n",
      "     |  \n",
      "     |  async arun(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool asynchronously.\n",
      "     |  \n",
      "     |  run(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  raise_deprecation(values: 'Dict') -> 'Dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  args\n",
      "     |  \n",
      "     |  is_single_input\n",
      "     |      Whether the tool only accepts a single input.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.tools.base.BaseTool.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __init__(__pydantic_self__, **data: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  dict(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> 'DictStrAny'\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class ListPowerBITool(langchain.tools.base.BaseTool)\n",
      "     |  ListPowerBITool(*, name: str = 'list_tables_powerbi', description: str = 'Input is an empty string, output is a comma separated list of tables in the database.', args_schema: Optional[Type[pydantic.main.BaseModel]] = None, return_direct: bool = False, verbose: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, handle_tool_error: Union[bool, str, Callable[[langchain.tools.base.ToolException], str], NoneType] = False, powerbi: langchain.utilities.powerbi.PowerBIDataset) -> None\n",
      "     |  \n",
      "     |  Tool for getting tables names.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ListPowerBITool\n",
      "     |      langchain.tools.base.BaseTool\n",
      "     |      abc.ABC\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.tools.powerbi.tool.ListPowerBITool.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'powerbi': <class 'langchain.utilities.powerbi.Powe...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.tools.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True, 'po...\n",
      "     |  \n",
      "     |  __fields__ = {'args_schema': ModelField(name='args_schema', type=Optio...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function BaseTool.raise_deprecati...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {}\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, name: str = 'list_tables_powerbi'...gch...\n",
      "     |  \n",
      "     |  __validators__ = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  __call__(self, tool_input: 'str', callbacks: 'Callbacks' = None) -> 'str'\n",
      "     |      Make tool callable.\n",
      "     |  \n",
      "     |  async arun(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool asynchronously.\n",
      "     |  \n",
      "     |  run(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  raise_deprecation(values: 'Dict') -> 'Dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  args\n",
      "     |  \n",
      "     |  is_single_input\n",
      "     |      Whether the tool only accepts a single input.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __init__(__pydantic_self__, **data: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  dict(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> 'DictStrAny'\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class ListSQLDatabaseTool(BaseSQLDatabaseTool, langchain.tools.base.BaseTool)\n",
      "     |  ListSQLDatabaseTool(*, name: str = 'sql_db_list_tables', description: str = 'Input is an empty string, output is a comma separated list of tables in the database.', args_schema: Optional[Type[pydantic.main.BaseModel]] = None, return_direct: bool = False, verbose: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, handle_tool_error: Union[bool, str, Callable[[langchain.tools.base.ToolException], str], NoneType] = False, db: langchain.sql_database.SQLDatabase) -> None\n",
      "     |  \n",
      "     |  Tool for getting tables names.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ListSQLDatabaseTool\n",
      "     |      BaseSQLDatabaseTool\n",
      "     |      langchain.tools.base.BaseTool\n",
      "     |      abc.ABC\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.tools.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True, 'db...\n",
      "     |  \n",
      "     |  __fields__ = {'args_schema': ModelField(name='args_schema', type=Optio...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function BaseTool.raise_deprecati...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {}\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, name: str = 'sql_db_list_tables',... db...\n",
      "     |  \n",
      "     |  __validators__ = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from BaseSQLDatabaseTool:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.tools.sql_database.tool.BaseSQLDatabaseTool...\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  __call__(self, tool_input: 'str', callbacks: 'Callbacks' = None) -> 'str'\n",
      "     |      Make tool callable.\n",
      "     |  \n",
      "     |  async arun(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool asynchronously.\n",
      "     |  \n",
      "     |  run(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  raise_deprecation(values: 'Dict') -> 'Dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  args\n",
      "     |  \n",
      "     |  is_single_input\n",
      "     |      Whether the tool only accepts a single input.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __init__(__pydantic_self__, **data: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  dict(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> 'DictStrAny'\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class ListSparkSQLTool(BaseSparkSQLTool, langchain.tools.base.BaseTool)\n",
      "     |  ListSparkSQLTool(*, name: str = 'list_tables_sql_db', description: str = 'Input is an empty string, output is a comma separated list of tables in the Spark SQL.', args_schema: Optional[Type[pydantic.main.BaseModel]] = None, return_direct: bool = False, verbose: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, handle_tool_error: Union[bool, str, Callable[[langchain.tools.base.ToolException], str], NoneType] = False, db: langchain.utilities.spark_sql.SparkSQL) -> None\n",
      "     |  \n",
      "     |  Tool for getting tables names.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ListSparkSQLTool\n",
      "     |      BaseSparkSQLTool\n",
      "     |      langchain.tools.base.BaseTool\n",
      "     |      abc.ABC\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.tools.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True, 'db...\n",
      "     |  \n",
      "     |  __fields__ = {'args_schema': ModelField(name='args_schema', type=Optio...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function BaseTool.raise_deprecati...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {}\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, name: str = 'list_tables_sql_db',... la...\n",
      "     |  \n",
      "     |  __validators__ = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from BaseSparkSQLTool:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.tools.spark_sql.tool.BaseSparkSQLTool.Confi...\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  __call__(self, tool_input: 'str', callbacks: 'Callbacks' = None) -> 'str'\n",
      "     |      Make tool callable.\n",
      "     |  \n",
      "     |  async arun(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool asynchronously.\n",
      "     |  \n",
      "     |  run(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  raise_deprecation(values: 'Dict') -> 'Dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  args\n",
      "     |  \n",
      "     |  is_single_input\n",
      "     |      Whether the tool only accepts a single input.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __init__(__pydantic_self__, **data: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  dict(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> 'DictStrAny'\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class MetaphorSearchResults(langchain.tools.base.BaseTool)\n",
      "     |  MetaphorSearchResults(*, name: str = 'metaphor_search_results_json', description: str = 'A wrapper around Metaphor Search. Input should be a Metaphor-optimized query. Output is a JSON array of the query results', args_schema: Optional[Type[pydantic.main.BaseModel]] = None, return_direct: bool = False, verbose: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, handle_tool_error: Union[bool, str, Callable[[langchain.tools.base.ToolException], str], NoneType] = False, api_wrapper: langchain.utilities.metaphor_search.MetaphorSearchAPIWrapper) -> None\n",
      "     |  \n",
      "     |  Tool that has capability to query the Metaphor Search API and get back json.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      MetaphorSearchResults\n",
      "     |      langchain.tools.base.BaseTool\n",
      "     |      abc.ABC\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'api_wrapper': <class 'langchain.utilities.metaphor...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.tools.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'api_wrapper': ModelField(name='api_wrapper', type=Metap...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function BaseTool.raise_deprecati...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {}\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, name: str = 'metaphor_search_resu...eta...\n",
      "     |  \n",
      "     |  __validators__ = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  __call__(self, tool_input: 'str', callbacks: 'Callbacks' = None) -> 'str'\n",
      "     |      Make tool callable.\n",
      "     |  \n",
      "     |  async arun(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool asynchronously.\n",
      "     |  \n",
      "     |  run(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  raise_deprecation(values: 'Dict') -> 'Dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  args\n",
      "     |  \n",
      "     |  is_single_input\n",
      "     |      Whether the tool only accepts a single input.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.tools.base.BaseTool.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __init__(__pydantic_self__, **data: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  dict(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> 'DictStrAny'\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class MoveFileTool(langchain.tools.file_management.utils.BaseFileToolMixin, langchain.tools.base.BaseTool)\n",
      "     |  MoveFileTool(*, name: str = 'move_file', description: str = 'Move or rename a file from one location to another', args_schema: Type[pydantic.main.BaseModel] = <class 'langchain.tools.file_management.move.FileMoveInput'>, return_direct: bool = False, verbose: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, handle_tool_error: Union[bool, str, Callable[[langchain.tools.base.ToolException], str], NoneType] = False, root_dir: Optional[str] = None) -> None\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      MoveFileTool\n",
      "     |      langchain.tools.file_management.utils.BaseFileToolMixin\n",
      "     |      langchain.tools.base.BaseTool\n",
      "     |      abc.ABC\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'args_schema': typing.Type[pydantic.main.BaseModel]...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.tools.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'args_schema': ModelField(name='args_schema', type=Type[...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function BaseTool.raise_deprecati...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {}\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, name: str = 'move_file', descript...= F...\n",
      "     |  \n",
      "     |  __validators__ = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.tools.file_management.utils.BaseFileToolMixin:\n",
      "     |  \n",
      "     |  get_relative_path(self, file_path: str) -> pathlib.Path\n",
      "     |      Get the relative path, returning an error if unsupported.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  __call__(self, tool_input: 'str', callbacks: 'Callbacks' = None) -> 'str'\n",
      "     |      Make tool callable.\n",
      "     |  \n",
      "     |  async arun(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool asynchronously.\n",
      "     |  \n",
      "     |  run(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  raise_deprecation(values: 'Dict') -> 'Dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  args\n",
      "     |  \n",
      "     |  is_single_input\n",
      "     |      Whether the tool only accepts a single input.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.tools.base.BaseTool.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __init__(__pydantic_self__, **data: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  dict(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> 'DictStrAny'\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class NavigateBackTool(langchain.tools.playwright.base.BaseBrowserTool)\n",
      "     |  NavigateBackTool(*, name: str = 'previous_webpage', description: str = 'Navigate back to the previous page in the browser history', args_schema: Type[pydantic.main.BaseModel] = <class 'pydantic.main.BaseModel'>, return_direct: bool = False, verbose: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, handle_tool_error: Union[bool, str, Callable[[langchain.tools.base.ToolException], str], NoneType] = False, sync_browser: ForwardRef(\"Optional['SyncBrowser']\") = None, async_browser: ForwardRef(\"Optional['AsyncBrowser']\") = None) -> None\n",
      "     |  \n",
      "     |  Navigate back to the previous page in the browser history.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      NavigateBackTool\n",
      "     |      langchain.tools.playwright.base.BaseBrowserTool\n",
      "     |      langchain.tools.base.BaseTool\n",
      "     |      abc.ABC\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'args_schema': 'Type[BaseModel]', 'description': 's...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.tools.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'args_schema': ModelField(name='args_schema', type=Type[...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function BaseTool.raise_deprecati...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {}\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, name: str = 'previous_webpage', d...dRe...\n",
      "     |  \n",
      "     |  __validators__ = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.tools.playwright.base.BaseBrowserTool:\n",
      "     |  \n",
      "     |  from_browser(sync_browser: 'Optional[SyncBrowser]' = None, async_browser: 'Optional[AsyncBrowser]' = None) -> 'BaseBrowserTool' from langchain.tools.base.ToolMetaclass\n",
      "     |      Instantiate the tool.\n",
      "     |  \n",
      "     |  validate_browser_provided(values: 'dict') -> 'dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Check that the arguments are valid.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  __call__(self, tool_input: 'str', callbacks: 'Callbacks' = None) -> 'str'\n",
      "     |      Make tool callable.\n",
      "     |  \n",
      "     |  async arun(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool asynchronously.\n",
      "     |  \n",
      "     |  run(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  raise_deprecation(values: 'Dict') -> 'Dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  args\n",
      "     |  \n",
      "     |  is_single_input\n",
      "     |      Whether the tool only accepts a single input.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.tools.base.BaseTool.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __init__(__pydantic_self__, **data: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  dict(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> 'DictStrAny'\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class NavigateTool(langchain.tools.playwright.base.BaseBrowserTool)\n",
      "     |  NavigateTool(*, name: str = 'navigate_browser', description: str = 'Navigate a browser to the specified URL', args_schema: Type[pydantic.main.BaseModel] = <class 'langchain.tools.playwright.navigate.NavigateToolInput'>, return_direct: bool = False, verbose: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, handle_tool_error: Union[bool, str, Callable[[langchain.tools.base.ToolException], str], NoneType] = False, sync_browser: ForwardRef(\"Optional['SyncBrowser']\") = None, async_browser: ForwardRef(\"Optional['AsyncBrowser']\") = None) -> None\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      NavigateTool\n",
      "     |      langchain.tools.playwright.base.BaseBrowserTool\n",
      "     |      langchain.tools.base.BaseTool\n",
      "     |      abc.ABC\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'args_schema': 'Type[BaseModel]', 'description': 's...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.tools.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'args_schema': ModelField(name='args_schema', type=Type[...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function BaseTool.raise_deprecati...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {}\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, name: str = 'navigate_browser', d...dRe...\n",
      "     |  \n",
      "     |  __validators__ = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.tools.playwright.base.BaseBrowserTool:\n",
      "     |  \n",
      "     |  from_browser(sync_browser: 'Optional[SyncBrowser]' = None, async_browser: 'Optional[AsyncBrowser]' = None) -> 'BaseBrowserTool' from langchain.tools.base.ToolMetaclass\n",
      "     |      Instantiate the tool.\n",
      "     |  \n",
      "     |  validate_browser_provided(values: 'dict') -> 'dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Check that the arguments are valid.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  __call__(self, tool_input: 'str', callbacks: 'Callbacks' = None) -> 'str'\n",
      "     |      Make tool callable.\n",
      "     |  \n",
      "     |  async arun(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool asynchronously.\n",
      "     |  \n",
      "     |  run(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  raise_deprecation(values: 'Dict') -> 'Dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  args\n",
      "     |  \n",
      "     |  is_single_input\n",
      "     |      Whether the tool only accepts a single input.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.tools.base.BaseTool.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __init__(__pydantic_self__, **data: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  dict(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> 'DictStrAny'\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class OpenAPISpec(openapi_schema_pydantic.v3.v3_1_0.open_api.OpenAPI)\n",
      "     |  OpenAPISpec(*, openapi: str = '3.1.0', info: openapi_schema_pydantic.v3.v3_1_0.info.Info, jsonSchemaDialect: Optional[str] = None, servers: List[openapi_schema_pydantic.v3.v3_1_0.server.Server] = [Server(url='/', description=None, variables=None)], paths: Optional[Dict[str, openapi_schema_pydantic.v3.v3_1_0.path_item.PathItem]] = None, webhooks: Optional[Dict[str, Union[openapi_schema_pydantic.v3.v3_1_0.path_item.PathItem, openapi_schema_pydantic.v3.v3_1_0.reference.Reference]]] = None, components: Optional[openapi_schema_pydantic.v3.v3_1_0.components.Components] = None, security: Optional[List[Dict[str, List[str]]]] = None, tags: Optional[List[openapi_schema_pydantic.v3.v3_1_0.tag.Tag]] = None, externalDocs: Optional[openapi_schema_pydantic.v3.v3_1_0.external_documentation.ExternalDocumentation] = None) -> None\n",
      "     |  \n",
      "     |  OpenAPI Model that removes misformatted parts of the spec.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      OpenAPISpec\n",
      "     |      openapi_schema_pydantic.v3.v3_1_0.open_api.OpenAPI\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  get_methods_for_path(self, path: str) -> List[str]\n",
      "     |      Return a list of valid methods for the specified path.\n",
      "     |  \n",
      "     |  get_operation(self, path: str, method: str) -> openapi_schema_pydantic.v3.v3_1_0.operation.Operation\n",
      "     |      Get the operation object for a given path and HTTP method.\n",
      "     |  \n",
      "     |  get_parameters_for_operation(self, operation: openapi_schema_pydantic.v3.v3_1_0.operation.Operation) -> List[openapi_schema_pydantic.v3.v3_1_0.parameter.Parameter]\n",
      "     |      Get the components for a given operation.\n",
      "     |  \n",
      "     |  get_referenced_schema(self, ref: openapi_schema_pydantic.v3.v3_1_0.reference.Reference) -> openapi_schema_pydantic.v3.v3_1_0.schema.Schema\n",
      "     |      Get a schema (or nested reference) or err.\n",
      "     |  \n",
      "     |  get_request_body_for_operation(self, operation: openapi_schema_pydantic.v3.v3_1_0.operation.Operation) -> Optional[openapi_schema_pydantic.v3.v3_1_0.request_body.RequestBody]\n",
      "     |      Get the request body for a given operation.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  from_file(path: Union[str, pathlib.Path]) -> 'OpenAPISpec' from pydantic.main.ModelMetaclass\n",
      "     |      Get an OpenAPI spec from a file path.\n",
      "     |  \n",
      "     |  from_spec_dict(spec_dict: dict) -> 'OpenAPISpec' from pydantic.main.ModelMetaclass\n",
      "     |      Get an OpenAPI spec from a dict.\n",
      "     |  \n",
      "     |  from_text(text: str) -> 'OpenAPISpec' from pydantic.main.ModelMetaclass\n",
      "     |      Get an OpenAPI spec from a text.\n",
      "     |  \n",
      "     |  from_url(url: str) -> 'OpenAPISpec' from pydantic.main.ModelMetaclass\n",
      "     |      Get an OpenAPI spec from a URL.\n",
      "     |  \n",
      "     |  parse_obj(obj: dict) -> 'OpenAPISpec' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  get_cleaned_operation_id(operation: openapi_schema_pydantic.v3.v3_1_0.operation.Operation, path: str, method: str) -> str\n",
      "     |      Get a cleaned operation id from an operation id.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  base_url\n",
      "     |      Get the base url.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.tools.openapi.utils.openapi_utils.Confi...\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = None\n",
      "     |  \n",
      "     |  __fields__ = {'components': ModelField(name='components', type=Optiona...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = []\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {}\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, openapi: str = '3.1.0', info: ope...men...\n",
      "     |  \n",
      "     |  __validators__ = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from openapi_schema_pydantic.v3.v3_1_0.open_api.OpenAPI:\n",
      "     |  \n",
      "     |  Config = <class 'openapi_schema_pydantic.v3.v3_1_0.open_api.OpenAPI.Co...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __init__(__pydantic_self__, **data: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  dict(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> 'DictStrAny'\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class OpenWeatherMapQueryRun(langchain.tools.base.BaseTool)\n",
      "     |  OpenWeatherMapQueryRun(*, name: str = 'OpenWeatherMap', description: str = 'A wrapper around OpenWeatherMap API. Useful for fetching current weather information for a specified location. Input should be a location string (e.g. London,GB).', args_schema: Optional[Type[pydantic.main.BaseModel]] = None, return_direct: bool = False, verbose: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, handle_tool_error: Union[bool, str, Callable[[langchain.tools.base.ToolException], str], NoneType] = False, api_wrapper: langchain.utilities.openweathermap.OpenWeatherMapAPIWrapper = None) -> None\n",
      "     |  \n",
      "     |  Tool that adds the capability to query using the OpenWeatherMap API.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      OpenWeatherMapQueryRun\n",
      "     |      langchain.tools.base.BaseTool\n",
      "     |      abc.ABC\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'api_wrapper': <class 'langchain.utilities.openweat...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.tools.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'api_wrapper': ModelField(name='api_wrapper', type=OpenW...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function BaseTool.raise_deprecati...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {}\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, name: str = 'OpenWeatherMap', des...the...\n",
      "     |  \n",
      "     |  __validators__ = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  __call__(self, tool_input: 'str', callbacks: 'Callbacks' = None) -> 'str'\n",
      "     |      Make tool callable.\n",
      "     |  \n",
      "     |  async arun(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool asynchronously.\n",
      "     |  \n",
      "     |  run(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  raise_deprecation(values: 'Dict') -> 'Dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  args\n",
      "     |  \n",
      "     |  is_single_input\n",
      "     |      Whether the tool only accepts a single input.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.tools.base.BaseTool.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __init__(__pydantic_self__, **data: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  dict(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> 'DictStrAny'\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class PubmedQueryRun(langchain.tools.base.BaseTool)\n",
      "     |  PubmedQueryRun(*, name: str = 'PubMed', description: str = 'A wrapper around PubMed.org Useful for when you need to answer questions about Physics, Mathematics, Computer Science, Quantitative Biology, Quantitative Finance, Statistics, Electrical Engineering, and Economics from scientific articles on PubMed.org. Input should be a search query.', args_schema: Optional[Type[pydantic.main.BaseModel]] = None, return_direct: bool = False, verbose: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, handle_tool_error: Union[bool, str, Callable[[langchain.tools.base.ToolException], str], NoneType] = False, api_wrapper: langchain.utilities.pupmed.PubMedAPIWrapper = None) -> None\n",
      "     |  \n",
      "     |  Tool that adds the capability to search using the PubMed API.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      PubmedQueryRun\n",
      "     |      langchain.tools.base.BaseTool\n",
      "     |      abc.ABC\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'api_wrapper': <class 'langchain.utilities.pupmed.P...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.tools.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'api_wrapper': ModelField(name='api_wrapper', type=PubMe...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function BaseTool.raise_deprecati...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {}\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, name: str = 'PubMed', description...til...\n",
      "     |  \n",
      "     |  __validators__ = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  __call__(self, tool_input: 'str', callbacks: 'Callbacks' = None) -> 'str'\n",
      "     |      Make tool callable.\n",
      "     |  \n",
      "     |  async arun(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool asynchronously.\n",
      "     |  \n",
      "     |  run(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  raise_deprecation(values: 'Dict') -> 'Dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  args\n",
      "     |  \n",
      "     |  is_single_input\n",
      "     |      Whether the tool only accepts a single input.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.tools.base.BaseTool.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __init__(__pydantic_self__, **data: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  dict(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> 'DictStrAny'\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class PythonAstREPLTool(langchain.tools.base.BaseTool)\n",
      "     |  PythonAstREPLTool(*, name: str = 'python_repl_ast', description: str = 'A Python shell. Use this to execute python commands. Input should be a valid python command. When using this tool, sometimes output is abbreviated - make sure it does not look abbreviated before using it in your answer.', args_schema: Optional[Type[pydantic.main.BaseModel]] = None, return_direct: bool = False, verbose: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, handle_tool_error: Union[bool, str, Callable[[langchain.tools.base.ToolException], str], NoneType] = False, globals: Optional[Dict] = None, locals: Optional[Dict] = None, sanitize_input: bool = True) -> None\n",
      "     |  \n",
      "     |  A tool for running python code in a REPL.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      PythonAstREPLTool\n",
      "     |      langchain.tools.base.BaseTool\n",
      "     |      abc.ABC\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  validate_python_version(values: Dict) -> Dict from langchain.tools.base.ToolMetaclass\n",
      "     |      Validate valid python version.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'globals': typing.Optional[typing.Dict], 'locals': ...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.tools.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'args_schema': ModelField(name='args_schema', type=Optio...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function BaseTool.raise_deprecati...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = [<function PythonAstREPLTool.validate_python...\n",
      "     |  \n",
      "     |  __private_attributes__ = {}\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, name: str = 'python_repl_ast', de...ct]...\n",
      "     |  \n",
      "     |  __validators__ = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  __call__(self, tool_input: 'str', callbacks: 'Callbacks' = None) -> 'str'\n",
      "     |      Make tool callable.\n",
      "     |  \n",
      "     |  async arun(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool asynchronously.\n",
      "     |  \n",
      "     |  run(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  raise_deprecation(values: 'Dict') -> 'Dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  args\n",
      "     |  \n",
      "     |  is_single_input\n",
      "     |      Whether the tool only accepts a single input.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.tools.base.BaseTool.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __init__(__pydantic_self__, **data: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  dict(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> 'DictStrAny'\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class PythonREPLTool(langchain.tools.base.BaseTool)\n",
      "     |  PythonREPLTool(*, name: str = 'Python_REPL', description: str = 'A Python shell. Use this to execute python commands. Input should be a valid python command. If you want to see the output of a value, you should print it out with `print(...)`.', args_schema: Optional[Type[pydantic.main.BaseModel]] = None, return_direct: bool = False, verbose: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, handle_tool_error: Union[bool, str, Callable[[langchain.tools.base.ToolException], str], NoneType] = False, python_repl: langchain.utilities.python.PythonREPL = None, sanitize_input: bool = True) -> None\n",
      "     |  \n",
      "     |  A tool for running python code in a REPL.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      PythonREPLTool\n",
      "     |      langchain.tools.base.BaseTool\n",
      "     |      abc.ABC\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'python_repl': <class 'langchain.utilities.python.P...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.tools.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'args_schema': ModelField(name='args_schema', type=Optio...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function BaseTool.raise_deprecati...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {}\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, name: str = 'Python_REPL', descri...EPL...\n",
      "     |  \n",
      "     |  __validators__ = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  __call__(self, tool_input: 'str', callbacks: 'Callbacks' = None) -> 'str'\n",
      "     |      Make tool callable.\n",
      "     |  \n",
      "     |  async arun(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool asynchronously.\n",
      "     |  \n",
      "     |  run(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  raise_deprecation(values: 'Dict') -> 'Dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  args\n",
      "     |  \n",
      "     |  is_single_input\n",
      "     |      Whether the tool only accepts a single input.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.tools.base.BaseTool.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __init__(__pydantic_self__, **data: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  dict(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> 'DictStrAny'\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class QueryCheckerTool(BaseSparkSQLTool, langchain.tools.base.BaseTool)\n",
      "     |  QueryCheckerTool(*, name: str = 'query_checker_sql_db', description: str = '\\n    Use this tool to double check if your query is correct before executing it.\\n    Always use this tool before executing a query with query_sql_db!\\n    ', args_schema: Optional[Type[pydantic.main.BaseModel]] = None, return_direct: bool = False, verbose: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, handle_tool_error: Union[bool, str, Callable[[langchain.tools.base.ToolException], str], NoneType] = False, db: langchain.utilities.spark_sql.SparkSQL, template: str = '\\n{query}\\nDouble check the Spark SQL query above for common mistakes, including:\\n- Using NOT IN with NULL values\\n- Using UNION when UNION ALL should have been used\\n- Using BETWEEN for exclusive ranges\\n- Data type mismatch in predicates\\n- Properly quoting identifiers\\n- Using the correct number of arguments for functions\\n- Casting to the correct data type\\n- Using the proper columns for joins\\n\\nIf there are any of the above mistakes, rewrite the query. If there are no mistakes, just reproduce the original query.', llm: langchain.base_language.BaseLanguageModel, llm_chain: langchain.chains.llm.LLMChain) -> None\n",
      "     |  \n",
      "     |  Use an LLM to check if a query is correct.\n",
      "     |  Adapted from https://www.patterns.app/blog/2023/01/18/crunchbot-sql-analyst-gpt/\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      QueryCheckerTool\n",
      "     |      BaseSparkSQLTool\n",
      "     |      langchain.tools.base.BaseTool\n",
      "     |      abc.ABC\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  initialize_llm_chain(values: Dict[str, Any]) -> Dict[str, Any] from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'llm': <class 'langchain.base_language.BaseLanguage...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.tools.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True, 'db...\n",
      "     |  \n",
      "     |  __fields__ = {'args_schema': ModelField(name='args_schema', type=Optio...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function BaseTool.raise_deprecati...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = [<function QueryCheckerTool.initialize_llm_c...\n",
      "     |  \n",
      "     |  __private_attributes__ = {}\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, name: str = 'query_checker_sql_db...lm_...\n",
      "     |  \n",
      "     |  __validators__ = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from BaseSparkSQLTool:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.tools.spark_sql.tool.BaseSparkSQLTool.Confi...\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  __call__(self, tool_input: 'str', callbacks: 'Callbacks' = None) -> 'str'\n",
      "     |      Make tool callable.\n",
      "     |  \n",
      "     |  async arun(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool asynchronously.\n",
      "     |  \n",
      "     |  run(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  raise_deprecation(values: 'Dict') -> 'Dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  args\n",
      "     |  \n",
      "     |  is_single_input\n",
      "     |      Whether the tool only accepts a single input.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __init__(__pydantic_self__, **data: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  dict(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> 'DictStrAny'\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class QueryPowerBITool(langchain.tools.base.BaseTool)\n",
      "     |  QueryPowerBITool(*, name: str = 'query_powerbi', description: str = '\\n    Input to this tool is a detailed question about the dataset, output is a result from the dataset. It will try to answer the question using the dataset, and if it cannot, it will ask for clarification.\\n\\n    Example Input: \"How many rows are in table1?\"\\n    ', args_schema: Optional[Type[pydantic.main.BaseModel]] = None, return_direct: bool = False, verbose: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, handle_tool_error: Union[bool, str, Callable[[langchain.tools.base.ToolException], str], NoneType] = False, llm_chain: langchain.chains.llm.LLMChain, powerbi: langchain.utilities.powerbi.PowerBIDataset, template: Optional[str] = '\\nAnswer the question below with a DAX query that can be sent to Power BI. DAX queries have a simple syntax comprised of just one required keyword, EVALUATE, and several optional keywords: ORDER BY, START AT, DEFINE, MEASURE, VAR, TABLE, and COLUMN. Each keyword defines a statement used for the duration of the query. Any time < or > are used in the text below it means that those values need to be replaced by table, columns or other things. If the question is not something you can answer with a DAX query, reply with \"I cannot answer this\" and the question will be escalated to a human.\\n\\nSome DAX functions return a table instead of a scalar, and must be wrapped in a function that evaluates the table and returns a scalar; unless the table is a single column, single row table, then it is treated as a scalar value. Most DAX functions require one or more arguments, which can include tables, columns, expressions, and values. However, some functions, such as PI, do not require any arguments, but always require parentheses to indicate the null argument. For example, you must always type PI(), not PI. You can also nest functions within other functions. \\n\\nSome commonly used functions are:\\nEVALUATE <table> - At the most basic level, a DAX query is an EVALUATE statement containing a table expression. At least one EVALUATE statement is required, however, a query can contain any number of EVALUATE statements.\\nEVALUATE <table> ORDER BY <expression> ASC or DESC - The optional ORDER BY keyword defines one or more expressions used to sort query results. Any expression that can be evaluated for each row of the result is valid.\\nEVALUATE <table> ORDER BY <expression> ASC or DESC START AT <value> or <parameter> - The optional START AT keyword is used inside an ORDER BY clause. It defines the value at which the query results begin.\\nDEFINE MEASURE | VAR; EVALUATE <table> - The optional DEFINE keyword introduces one or more calculated entity definitions that exist only for the duration of the query. Definitions precede the EVALUATE statement and are valid for all EVALUATE statements in the query. Definitions can be variables, measures, tables1, and columns1. Definitions can reference other definitions that appear before or after the current definition. At least one definition is required if the DEFINE keyword is included in a query.\\nMEASURE <table name>[<measure name>] = <scalar expression> - Introduces a measure definition in a DEFINE statement of a DAX query.\\nVAR <name> = <expression> - Stores the result of an expression as a named variable, which can then be passed as an argument to other measure expressions. Once resultant values have been calculated for a variable expression, those values do not change, even if the variable is referenced in another expression.\\n\\nFILTER(<table>,<filter>) - Returns a table that represents a subset of another table or expression, where <filter> is a Boolean expression that is to be evaluated for each row of the table. For example, [Amount] > 0 or [Region] = \"France\"\\nROW(<name>, <expression>) - Returns a table with a single row containing values that result from the expressions given to each column.\\nDISTINCT(<column>) - Returns a one-column table that contains the distinct values from the specified column. In other words, duplicate values are removed and only unique values are returned. This function cannot be used to Return values into a cell or column on a worksheet; rather, you nest the DISTINCT function within a formula, to get a list of distinct values that can be passed to another function and then counted, summed, or used for other operations.\\nDISTINCT(<table>) - Returns a table by removing duplicate rows from another table or expression.\\n\\nAggregation functions, names with a A in it, handle booleans and empty strings in appropriate ways, while the same function without A only uses the numeric values in a column. Functions names with an X in it can include a expression as an argument, this will be evaluated for each row in the table and the result will be used in the regular function calculation, these are the functions:\\nCOUNT(<column>), COUNTA(<column>), COUNTX(<table>,<expression>), COUNTAX(<table>,<expression>), COUNTROWS([<table>]), COUNTBLANK(<column>), DISTINCTCOUNT(<column>), DISTINCTCOUNTNOBLANK (<column>) - these are all variantions of count functions.\\nAVERAGE(<column>), AVERAGEA(<column>), AVERAGEX(<table>,<expression>) - these are all variantions of average functions.\\nMAX(<column>), MAXA(<column>), MAXX(<table>,<expression>) - these are all variantions of max functions.\\nMIN(<column>), MINA(<column>), MINX(<table>,<expression>) - these are all variantions of min functions.\\nPRODUCT(<column>), PRODUCTX(<table>,<expression>) - these are all variantions of product functions.\\nSUM(<column>), SUMX(<table>,<expression>) - these are all variantions of sum functions.\\n\\nDate and time functions:\\nDATE(year, month, day) - Returns a date value that represents the specified year, month, and day.\\nDATEDIFF(date1, date2, <interval>) - Returns the difference between two date values, in the specified interval, that can be SECOND, MINUTE, HOUR, DAY, WEEK, MONTH, QUARTER, YEAR.\\nDATEVALUE(<date_text>) - Returns a date value that represents the specified date.\\nYEAR(<date>), QUARTER(<date>), MONTH(<date>), DAY(<date>), HOUR(<date>), MINUTE(<date>), SECOND(<date>) - Returns the part of the date for the specified date.\\n\\nFinally, make sure to escape double quotes with a single backslash, and make sure that only table names have single quotes around them, while names of measures or the values of columns that you want to compare against are in escaped double quotes. Newlines are not necessary and can be skipped. The queries are serialized as json and so will have to fit be compliant with json syntax. Sometimes you will get a question, a DAX query and a error, in that case you need to rewrite the DAX query to get the correct answer.\\n\\nThe following tables exist: {tables}\\n\\nand the schema\\'s for some are given here:\\n{schemas}\\n\\nExamples:\\n{examples}\\n\\nQuestion: {tool_input}\\nDAX: \\n', examples: Optional[str] = '\\nQuestion: How many rows are in the table <table>?\\nDAX: EVALUATE ROW(\"Number of rows\", COUNTROWS(<table>))\\n----\\nQuestion: How many rows are in the table <table> where <column> is not empty?\\nDAX: EVALUATE ROW(\"Number of rows\", COUNTROWS(FILTER(<table>, <table>[<column>] <> \"\")))\\n----\\nQuestion: What was the average of <column> in <table>?\\nDAX: EVALUATE ROW(\"Average\", AVERAGE(<table>[<column>]))\\n----\\n', session_cache: Dict[str, Any] = None, max_iterations: int = 5) -> None\n",
      "     |  \n",
      "     |  Tool for querying a Power BI Dataset.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      QueryPowerBITool\n",
      "     |      langchain.tools.base.BaseTool\n",
      "     |      abc.ABC\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  validate_llm_chain_input_variables(llm_chain: langchain.chains.llm.LLMChain) -> langchain.chains.llm.LLMChain from langchain.tools.base.ToolMetaclass\n",
      "     |      Make sure the LLM chain has the correct input variables.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.tools.powerbi.tool.QueryPowerBITool.Config'...\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'examples': typing.Optional[str], 'llm_chain': <cla...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.tools.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True, 'po...\n",
      "     |  \n",
      "     |  __fields__ = {'args_schema': ModelField(name='args_schema', type=Optio...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function BaseTool.raise_deprecati...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {}\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, name: str = 'query_powerbi', desc...r, ...\n",
      "     |  \n",
      "     |  __validators__ = {'llm_chain': [<pydantic.class_validators.Validator o...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  __call__(self, tool_input: 'str', callbacks: 'Callbacks' = None) -> 'str'\n",
      "     |      Make tool callable.\n",
      "     |  \n",
      "     |  async arun(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool asynchronously.\n",
      "     |  \n",
      "     |  run(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  raise_deprecation(values: 'Dict') -> 'Dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  args\n",
      "     |  \n",
      "     |  is_single_input\n",
      "     |      Whether the tool only accepts a single input.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __init__(__pydantic_self__, **data: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  dict(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> 'DictStrAny'\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class QuerySQLCheckerTool(BaseSQLDatabaseTool, langchain.tools.base.BaseTool)\n",
      "     |  QuerySQLCheckerTool(*, name: str = 'sql_db_query_checker', description: str = '\\n    Use this tool to double check if your query is correct before executing it.\\n    Always use this tool before executing a query with query_sql_db!\\n    ', args_schema: Optional[Type[pydantic.main.BaseModel]] = None, return_direct: bool = False, verbose: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, handle_tool_error: Union[bool, str, Callable[[langchain.tools.base.ToolException], str], NoneType] = False, db: langchain.sql_database.SQLDatabase, template: str = '\\n{query}\\nDouble check the {dialect} query above for common mistakes, including:\\n- Using NOT IN with NULL values\\n- Using UNION when UNION ALL should have been used\\n- Using BETWEEN for exclusive ranges\\n- Data type mismatch in predicates\\n- Properly quoting identifiers\\n- Using the correct number of arguments for functions\\n- Casting to the correct data type\\n- Using the proper columns for joins\\n\\nIf there are any of the above mistakes, rewrite the query. If there are no mistakes, just reproduce the original query.', llm: langchain.base_language.BaseLanguageModel, llm_chain: langchain.chains.llm.LLMChain) -> None\n",
      "     |  \n",
      "     |  Use an LLM to check if a query is correct.\n",
      "     |  Adapted from https://www.patterns.app/blog/2023/01/18/crunchbot-sql-analyst-gpt/\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      QuerySQLCheckerTool\n",
      "     |      BaseSQLDatabaseTool\n",
      "     |      langchain.tools.base.BaseTool\n",
      "     |      abc.ABC\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  initialize_llm_chain(values: Dict[str, Any]) -> Dict[str, Any] from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'llm': <class 'langchain.base_language.BaseLanguage...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.tools.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True, 'db...\n",
      "     |  \n",
      "     |  __fields__ = {'args_schema': ModelField(name='args_schema', type=Optio...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function BaseTool.raise_deprecati...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = [<function QuerySQLCheckerTool.initialize_ll...\n",
      "     |  \n",
      "     |  __private_attributes__ = {}\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, name: str = 'sql_db_query_checker...lm_...\n",
      "     |  \n",
      "     |  __validators__ = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from BaseSQLDatabaseTool:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.tools.sql_database.tool.BaseSQLDatabaseTool...\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  __call__(self, tool_input: 'str', callbacks: 'Callbacks' = None) -> 'str'\n",
      "     |      Make tool callable.\n",
      "     |  \n",
      "     |  async arun(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool asynchronously.\n",
      "     |  \n",
      "     |  run(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  raise_deprecation(values: 'Dict') -> 'Dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  args\n",
      "     |  \n",
      "     |  is_single_input\n",
      "     |      Whether the tool only accepts a single input.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __init__(__pydantic_self__, **data: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  dict(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> 'DictStrAny'\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class QuerySQLDataBaseTool(BaseSQLDatabaseTool, langchain.tools.base.BaseTool)\n",
      "     |  QuerySQLDataBaseTool(*, name: str = 'sql_db_query', description: str = '\\n    Input to this tool is a detailed and correct SQL query, output is a result from the database.\\n    If the query is not correct, an error message will be returned.\\n    If an error is returned, rewrite the query, check the query, and try again.\\n    ', args_schema: Optional[Type[pydantic.main.BaseModel]] = None, return_direct: bool = False, verbose: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, handle_tool_error: Union[bool, str, Callable[[langchain.tools.base.ToolException], str], NoneType] = False, db: langchain.sql_database.SQLDatabase) -> None\n",
      "     |  \n",
      "     |  Tool for querying a SQL database.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      QuerySQLDataBaseTool\n",
      "     |      BaseSQLDatabaseTool\n",
      "     |      langchain.tools.base.BaseTool\n",
      "     |      abc.ABC\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.tools.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True, 'db...\n",
      "     |  \n",
      "     |  __fields__ = {'args_schema': ModelField(name='args_schema', type=Optio...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function BaseTool.raise_deprecati...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {}\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, name: str = 'sql_db_query', descr... db...\n",
      "     |  \n",
      "     |  __validators__ = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from BaseSQLDatabaseTool:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.tools.sql_database.tool.BaseSQLDatabaseTool...\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  __call__(self, tool_input: 'str', callbacks: 'Callbacks' = None) -> 'str'\n",
      "     |      Make tool callable.\n",
      "     |  \n",
      "     |  async arun(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool asynchronously.\n",
      "     |  \n",
      "     |  run(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  raise_deprecation(values: 'Dict') -> 'Dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  args\n",
      "     |  \n",
      "     |  is_single_input\n",
      "     |      Whether the tool only accepts a single input.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __init__(__pydantic_self__, **data: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  dict(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> 'DictStrAny'\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class QuerySparkSQLTool(BaseSparkSQLTool, langchain.tools.base.BaseTool)\n",
      "     |  QuerySparkSQLTool(*, name: str = 'query_sql_db', description: str = '\\n    Input to this tool is a detailed and correct SQL query, output is a result from the Spark SQL.\\n    If the query is not correct, an error message will be returned.\\n    If an error is returned, rewrite the query, check the query, and try again.\\n    ', args_schema: Optional[Type[pydantic.main.BaseModel]] = None, return_direct: bool = False, verbose: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, handle_tool_error: Union[bool, str, Callable[[langchain.tools.base.ToolException], str], NoneType] = False, db: langchain.utilities.spark_sql.SparkSQL) -> None\n",
      "     |  \n",
      "     |  Tool for querying a Spark SQL.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      QuerySparkSQLTool\n",
      "     |      BaseSparkSQLTool\n",
      "     |      langchain.tools.base.BaseTool\n",
      "     |      abc.ABC\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.tools.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True, 'db...\n",
      "     |  \n",
      "     |  __fields__ = {'args_schema': ModelField(name='args_schema', type=Optio...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function BaseTool.raise_deprecati...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {}\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, name: str = 'query_sql_db', descr... la...\n",
      "     |  \n",
      "     |  __validators__ = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from BaseSparkSQLTool:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.tools.spark_sql.tool.BaseSparkSQLTool.Confi...\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  __call__(self, tool_input: 'str', callbacks: 'Callbacks' = None) -> 'str'\n",
      "     |      Make tool callable.\n",
      "     |  \n",
      "     |  async arun(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool asynchronously.\n",
      "     |  \n",
      "     |  run(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  raise_deprecation(values: 'Dict') -> 'Dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  args\n",
      "     |  \n",
      "     |  is_single_input\n",
      "     |      Whether the tool only accepts a single input.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __init__(__pydantic_self__, **data: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  dict(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> 'DictStrAny'\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class ReadFileTool(langchain.tools.file_management.utils.BaseFileToolMixin, langchain.tools.base.BaseTool)\n",
      "     |  ReadFileTool(*, name: str = 'read_file', description: str = 'Read file from disk', args_schema: Type[pydantic.main.BaseModel] = <class 'langchain.tools.file_management.read.ReadFileInput'>, return_direct: bool = False, verbose: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, handle_tool_error: Union[bool, str, Callable[[langchain.tools.base.ToolException], str], NoneType] = False, root_dir: Optional[str] = None) -> None\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ReadFileTool\n",
      "     |      langchain.tools.file_management.utils.BaseFileToolMixin\n",
      "     |      langchain.tools.base.BaseTool\n",
      "     |      abc.ABC\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'args_schema': typing.Type[pydantic.main.BaseModel]...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.tools.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'args_schema': ModelField(name='args_schema', type=Type[...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function BaseTool.raise_deprecati...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {}\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, name: str = 'read_file', descript...= F...\n",
      "     |  \n",
      "     |  __validators__ = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.tools.file_management.utils.BaseFileToolMixin:\n",
      "     |  \n",
      "     |  get_relative_path(self, file_path: str) -> pathlib.Path\n",
      "     |      Get the relative path, returning an error if unsupported.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  __call__(self, tool_input: 'str', callbacks: 'Callbacks' = None) -> 'str'\n",
      "     |      Make tool callable.\n",
      "     |  \n",
      "     |  async arun(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool asynchronously.\n",
      "     |  \n",
      "     |  run(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  raise_deprecation(values: 'Dict') -> 'Dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  args\n",
      "     |  \n",
      "     |  is_single_input\n",
      "     |      Whether the tool only accepts a single input.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.tools.base.BaseTool.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __init__(__pydantic_self__, **data: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  dict(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> 'DictStrAny'\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class RequestsDeleteTool(BaseRequestsTool, langchain.tools.base.BaseTool)\n",
      "     |  RequestsDeleteTool(*, name: str = 'requests_delete', description: str = 'A portal to the internet. Use this when you need to make a DELETE request to a URL. Input should be a specific url, and the output will be the text response of the DELETE request.', args_schema: Optional[Type[pydantic.main.BaseModel]] = None, return_direct: bool = False, verbose: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, handle_tool_error: Union[bool, str, Callable[[langchain.tools.base.ToolException], str], NoneType] = False, requests_wrapper: langchain.requests.TextRequestsWrapper) -> None\n",
      "     |  \n",
      "     |  Tool for making a DELETE request to an API endpoint.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      RequestsDeleteTool\n",
      "     |      BaseRequestsTool\n",
      "     |      langchain.tools.base.BaseTool\n",
      "     |      abc.ABC\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.tools.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'args_schema': ModelField(name='args_schema', type=Optio...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function BaseTool.raise_deprecati...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {}\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, name: str = 'requests_delete', de... la...\n",
      "     |  \n",
      "     |  __validators__ = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  __call__(self, tool_input: 'str', callbacks: 'Callbacks' = None) -> 'str'\n",
      "     |      Make tool callable.\n",
      "     |  \n",
      "     |  async arun(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool asynchronously.\n",
      "     |  \n",
      "     |  run(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  raise_deprecation(values: 'Dict') -> 'Dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  args\n",
      "     |  \n",
      "     |  is_single_input\n",
      "     |      Whether the tool only accepts a single input.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.tools.base.BaseTool.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __init__(__pydantic_self__, **data: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  dict(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> 'DictStrAny'\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class RequestsGetTool(BaseRequestsTool, langchain.tools.base.BaseTool)\n",
      "     |  RequestsGetTool(*, name: str = 'requests_get', description: str = 'A portal to the internet. Use this when you need to get specific content from a website. Input should be a  url (i.e. https://www.google.com). The output will be the text response of the GET request.', args_schema: Optional[Type[pydantic.main.BaseModel]] = None, return_direct: bool = False, verbose: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, handle_tool_error: Union[bool, str, Callable[[langchain.tools.base.ToolException], str], NoneType] = False, requests_wrapper: langchain.requests.TextRequestsWrapper) -> None\n",
      "     |  \n",
      "     |  Tool for making a GET request to an API endpoint.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      RequestsGetTool\n",
      "     |      BaseRequestsTool\n",
      "     |      langchain.tools.base.BaseTool\n",
      "     |      abc.ABC\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.tools.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'args_schema': ModelField(name='args_schema', type=Optio...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function BaseTool.raise_deprecati...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {}\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, name: str = 'requests_get', descr... la...\n",
      "     |  \n",
      "     |  __validators__ = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  __call__(self, tool_input: 'str', callbacks: 'Callbacks' = None) -> 'str'\n",
      "     |      Make tool callable.\n",
      "     |  \n",
      "     |  async arun(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool asynchronously.\n",
      "     |  \n",
      "     |  run(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  raise_deprecation(values: 'Dict') -> 'Dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  args\n",
      "     |  \n",
      "     |  is_single_input\n",
      "     |      Whether the tool only accepts a single input.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.tools.base.BaseTool.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __init__(__pydantic_self__, **data: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  dict(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> 'DictStrAny'\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class RequestsPatchTool(BaseRequestsTool, langchain.tools.base.BaseTool)\n",
      "     |  RequestsPatchTool(*, name: str = 'requests_patch', description: str = 'Use this when you want to PATCH to a website.\\n    Input should be a json string with two keys: \"url\" and \"data\".\\n    The value of \"url\" should be a string, and the value of \"data\" should be a dictionary of \\n    key-value pairs you want to PATCH to the url.\\n    Be careful to always use double quotes for strings in the json string\\n    The output will be the text response of the PATCH request.\\n    ', args_schema: Optional[Type[pydantic.main.BaseModel]] = None, return_direct: bool = False, verbose: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, handle_tool_error: Union[bool, str, Callable[[langchain.tools.base.ToolException], str], NoneType] = False, requests_wrapper: langchain.requests.TextRequestsWrapper) -> None\n",
      "     |  \n",
      "     |  Tool for making a PATCH request to an API endpoint.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      RequestsPatchTool\n",
      "     |      BaseRequestsTool\n",
      "     |      langchain.tools.base.BaseTool\n",
      "     |      abc.ABC\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.tools.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'args_schema': ModelField(name='args_schema', type=Optio...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function BaseTool.raise_deprecati...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {}\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, name: str = 'requests_patch', des... la...\n",
      "     |  \n",
      "     |  __validators__ = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  __call__(self, tool_input: 'str', callbacks: 'Callbacks' = None) -> 'str'\n",
      "     |      Make tool callable.\n",
      "     |  \n",
      "     |  async arun(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool asynchronously.\n",
      "     |  \n",
      "     |  run(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  raise_deprecation(values: 'Dict') -> 'Dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  args\n",
      "     |  \n",
      "     |  is_single_input\n",
      "     |      Whether the tool only accepts a single input.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.tools.base.BaseTool.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __init__(__pydantic_self__, **data: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  dict(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> 'DictStrAny'\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class RequestsPostTool(BaseRequestsTool, langchain.tools.base.BaseTool)\n",
      "     |  RequestsPostTool(*, name: str = 'requests_post', description: str = 'Use this when you want to POST to a website.\\n    Input should be a json string with two keys: \"url\" and \"data\".\\n    The value of \"url\" should be a string, and the value of \"data\" should be a dictionary of \\n    key-value pairs you want to POST to the url.\\n    Be careful to always use double quotes for strings in the json string\\n    The output will be the text response of the POST request.\\n    ', args_schema: Optional[Type[pydantic.main.BaseModel]] = None, return_direct: bool = False, verbose: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, handle_tool_error: Union[bool, str, Callable[[langchain.tools.base.ToolException], str], NoneType] = False, requests_wrapper: langchain.requests.TextRequestsWrapper) -> None\n",
      "     |  \n",
      "     |  Tool for making a POST request to an API endpoint.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      RequestsPostTool\n",
      "     |      BaseRequestsTool\n",
      "     |      langchain.tools.base.BaseTool\n",
      "     |      abc.ABC\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.tools.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'args_schema': ModelField(name='args_schema', type=Optio...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function BaseTool.raise_deprecati...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {}\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, name: str = 'requests_post', desc... la...\n",
      "     |  \n",
      "     |  __validators__ = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  __call__(self, tool_input: 'str', callbacks: 'Callbacks' = None) -> 'str'\n",
      "     |      Make tool callable.\n",
      "     |  \n",
      "     |  async arun(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool asynchronously.\n",
      "     |  \n",
      "     |  run(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  raise_deprecation(values: 'Dict') -> 'Dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  args\n",
      "     |  \n",
      "     |  is_single_input\n",
      "     |      Whether the tool only accepts a single input.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.tools.base.BaseTool.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __init__(__pydantic_self__, **data: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  dict(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> 'DictStrAny'\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class RequestsPutTool(BaseRequestsTool, langchain.tools.base.BaseTool)\n",
      "     |  RequestsPutTool(*, name: str = 'requests_put', description: str = 'Use this when you want to PUT to a website.\\n    Input should be a json string with two keys: \"url\" and \"data\".\\n    The value of \"url\" should be a string, and the value of \"data\" should be a dictionary of \\n    key-value pairs you want to PUT to the url.\\n    Be careful to always use double quotes for strings in the json string.\\n    The output will be the text response of the PUT request.\\n    ', args_schema: Optional[Type[pydantic.main.BaseModel]] = None, return_direct: bool = False, verbose: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, handle_tool_error: Union[bool, str, Callable[[langchain.tools.base.ToolException], str], NoneType] = False, requests_wrapper: langchain.requests.TextRequestsWrapper) -> None\n",
      "     |  \n",
      "     |  Tool for making a PUT request to an API endpoint.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      RequestsPutTool\n",
      "     |      BaseRequestsTool\n",
      "     |      langchain.tools.base.BaseTool\n",
      "     |      abc.ABC\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.tools.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'args_schema': ModelField(name='args_schema', type=Optio...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function BaseTool.raise_deprecati...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {}\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, name: str = 'requests_put', descr... la...\n",
      "     |  \n",
      "     |  __validators__ = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  __call__(self, tool_input: 'str', callbacks: 'Callbacks' = None) -> 'str'\n",
      "     |      Make tool callable.\n",
      "     |  \n",
      "     |  async arun(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool asynchronously.\n",
      "     |  \n",
      "     |  run(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  raise_deprecation(values: 'Dict') -> 'Dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  args\n",
      "     |  \n",
      "     |  is_single_input\n",
      "     |      Whether the tool only accepts a single input.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.tools.base.BaseTool.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __init__(__pydantic_self__, **data: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  dict(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> 'DictStrAny'\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class SceneXplainTool(langchain.tools.base.BaseTool)\n",
      "     |  SceneXplainTool(*, name: str = 'image_explainer', description: str = 'An Image Captioning Tool: Use this tool to generate a detailed caption for an image. The input can be an image file of any format, and the output will be a text description that covers every detail of the image.', args_schema: Optional[Type[pydantic.main.BaseModel]] = None, return_direct: bool = False, verbose: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, handle_tool_error: Union[bool, str, Callable[[langchain.tools.base.ToolException], str], NoneType] = False, api_wrapper: langchain.utilities.scenexplain.SceneXplainAPIWrapper = None) -> None\n",
      "     |  \n",
      "     |  Tool that adds the capability to explain images.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SceneXplainTool\n",
      "     |      langchain.tools.base.BaseTool\n",
      "     |      abc.ABC\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'api_wrapper': <class 'langchain.utilities.scenexpl...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.tools.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'api_wrapper': ModelField(name='api_wrapper', type=Scene...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function BaseTool.raise_deprecati...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {}\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, name: str = 'image_explainer', de...cen...\n",
      "     |  \n",
      "     |  __validators__ = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  __call__(self, tool_input: 'str', callbacks: 'Callbacks' = None) -> 'str'\n",
      "     |      Make tool callable.\n",
      "     |  \n",
      "     |  async arun(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool asynchronously.\n",
      "     |  \n",
      "     |  run(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  raise_deprecation(values: 'Dict') -> 'Dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  args\n",
      "     |  \n",
      "     |  is_single_input\n",
      "     |      Whether the tool only accepts a single input.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.tools.base.BaseTool.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __init__(__pydantic_self__, **data: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  dict(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> 'DictStrAny'\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class SearxSearchResults(langchain.tools.base.BaseTool)\n",
      "     |  SearxSearchResults(*, name: str = 'Searx Search Results', description: str = 'A meta search engine.Useful for when you need to answer questions about current events.Input should be a search query. Output is a JSON array of the query results', args_schema: Optional[Type[pydantic.main.BaseModel]] = None, return_direct: bool = False, verbose: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, handle_tool_error: Union[bool, str, Callable[[langchain.tools.base.ToolException], str], NoneType] = False, wrapper: langchain.utilities.searx_search.SearxSearchWrapper, num_results: int = 4, kwargs: dict = None, **extra_data: Any) -> None\n",
      "     |  \n",
      "     |  Tool that has the capability to query a Searx instance and get back json.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SearxSearchResults\n",
      "     |      langchain.tools.base.BaseTool\n",
      "     |      abc.ABC\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.tools.searx_search.tool.SearxSearchResults....\n",
      "     |      Pydantic config.\n",
      "     |  \n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'kwargs': <class 'dict'>, 'num_results': <class 'in...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.tools.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'args_schema': ModelField(name='args_schema', type=Optio...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function BaseTool.raise_deprecati...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {}\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, name: str = 'Searx Search Results... kw...\n",
      "     |  \n",
      "     |  __validators__ = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  __call__(self, tool_input: 'str', callbacks: 'Callbacks' = None) -> 'str'\n",
      "     |      Make tool callable.\n",
      "     |  \n",
      "     |  async arun(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool asynchronously.\n",
      "     |  \n",
      "     |  run(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  raise_deprecation(values: 'Dict') -> 'Dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  args\n",
      "     |  \n",
      "     |  is_single_input\n",
      "     |      Whether the tool only accepts a single input.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __init__(__pydantic_self__, **data: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  dict(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> 'DictStrAny'\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class SearxSearchRun(langchain.tools.base.BaseTool)\n",
      "     |  SearxSearchRun(*, name: str = 'searx_search', description: str = 'A meta search engine.Useful for when you need to answer questions about current events.Input should be a search query.', args_schema: Optional[Type[pydantic.main.BaseModel]] = None, return_direct: bool = False, verbose: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, handle_tool_error: Union[bool, str, Callable[[langchain.tools.base.ToolException], str], NoneType] = False, wrapper: langchain.utilities.searx_search.SearxSearchWrapper, kwargs: dict = None) -> None\n",
      "     |  \n",
      "     |  Tool that adds the capability to query a Searx instance.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SearxSearchRun\n",
      "     |      langchain.tools.base.BaseTool\n",
      "     |      abc.ABC\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'kwargs': <class 'dict'>, 'wrapper': <class 'langch...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.tools.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'args_schema': ModelField(name='args_schema', type=Optio...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function BaseTool.raise_deprecati...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {}\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, name: str = 'searx_search', descr...Sea...\n",
      "     |  \n",
      "     |  __validators__ = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  __call__(self, tool_input: 'str', callbacks: 'Callbacks' = None) -> 'str'\n",
      "     |      Make tool callable.\n",
      "     |  \n",
      "     |  async arun(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool asynchronously.\n",
      "     |  \n",
      "     |  run(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  raise_deprecation(values: 'Dict') -> 'Dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  args\n",
      "     |  \n",
      "     |  is_single_input\n",
      "     |      Whether the tool only accepts a single input.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.tools.base.BaseTool.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __init__(__pydantic_self__, **data: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  dict(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> 'DictStrAny'\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class ShellTool(langchain.tools.base.BaseTool)\n",
      "     |  ShellTool(*, name: str = 'terminal', description: str = 'Run shell commands on this Windows machine.', args_schema: Type[pydantic.main.BaseModel] = <class 'langchain.tools.shell.tool.ShellInput'>, return_direct: bool = False, verbose: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, handle_tool_error: Union[bool, str, Callable[[langchain.tools.base.ToolException], str], NoneType] = False, process: langchain.utilities.bash.BashProcess = None) -> None\n",
      "     |  \n",
      "     |  Tool to run shell commands.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ShellTool\n",
      "     |      langchain.tools.base.BaseTool\n",
      "     |      abc.ABC\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'args_schema': typing.Type[pydantic.main.BaseModel]...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.tools.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'args_schema': ModelField(name='args_schema', type=Type[...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function BaseTool.raise_deprecati...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {}\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, name: str = 'terminal', descripti...cha...\n",
      "     |  \n",
      "     |  __validators__ = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  __call__(self, tool_input: 'str', callbacks: 'Callbacks' = None) -> 'str'\n",
      "     |      Make tool callable.\n",
      "     |  \n",
      "     |  async arun(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool asynchronously.\n",
      "     |  \n",
      "     |  run(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  raise_deprecation(values: 'Dict') -> 'Dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  args\n",
      "     |  \n",
      "     |  is_single_input\n",
      "     |      Whether the tool only accepts a single input.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.tools.base.BaseTool.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __init__(__pydantic_self__, **data: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  dict(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> 'DictStrAny'\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class SleepTool(langchain.tools.base.BaseTool)\n",
      "     |  SleepTool(*, name: str = 'sleep', description: str = 'Make agent sleep for a specified number of seconds.', args_schema: Type[pydantic.main.BaseModel] = <class 'langchain.tools.sleep.tool.SleepInput'>, return_direct: bool = False, verbose: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, handle_tool_error: Union[bool, str, Callable[[langchain.tools.base.ToolException], str], NoneType] = False) -> None\n",
      "     |  \n",
      "     |  Tool that adds the capability to sleep.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SleepTool\n",
      "     |      langchain.tools.base.BaseTool\n",
      "     |      abc.ABC\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'args_schema': typing.Type[pydantic.main.BaseModel]...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.tools.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'args_schema': ModelField(name='args_schema', type=Type[...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function BaseTool.raise_deprecati...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {}\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, name: str = 'sleep', description:...Too...\n",
      "     |  \n",
      "     |  __validators__ = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  __call__(self, tool_input: 'str', callbacks: 'Callbacks' = None) -> 'str'\n",
      "     |      Make tool callable.\n",
      "     |  \n",
      "     |  async arun(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool asynchronously.\n",
      "     |  \n",
      "     |  run(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  raise_deprecation(values: 'Dict') -> 'Dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  args\n",
      "     |  \n",
      "     |  is_single_input\n",
      "     |      Whether the tool only accepts a single input.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.tools.base.BaseTool.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __init__(__pydantic_self__, **data: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  dict(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> 'DictStrAny'\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class SteamshipImageGenerationTool(langchain.tools.base.BaseTool)\n",
      "     |  SteamshipImageGenerationTool(*, name: str = 'GenerateImage', description: str = 'Useful for when you need to generate an image.Input: A detailed text-2-image prompt describing an imageOutput: the UUID of a generated image', args_schema: Optional[Type[pydantic.main.BaseModel]] = None, return_direct: bool = False, verbose: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, handle_tool_error: Union[bool, str, Callable[[langchain.tools.base.ToolException], str], NoneType] = False, model_name: langchain.tools.steamship_image_generation.tool.ModelName, size: Optional[str] = '512x512', steamship: ForwardRef('Steamship'), return_urls: Optional[bool] = False) -> None\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SteamshipImageGenerationTool\n",
      "     |      langchain.tools.base.BaseTool\n",
      "     |      abc.ABC\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  validate_environment(values: 'Dict') -> 'Dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Validate that api key and python package exists in environment.\n",
      "     |  \n",
      "     |  validate_size(values: 'Dict') -> 'Dict' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'model_name': 'ModelName', 'return_urls': 'Optional...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.tools.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'args_schema': ModelField(name='args_schema', type=Optio...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function BaseTool.raise_deprecati...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = [<function SteamshipImageGenerationTool.vali...\n",
      "     |  \n",
      "     |  __private_attributes__ = {}\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, name: str = 'GenerateImage', desc...'),...\n",
      "     |  \n",
      "     |  __validators__ = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  __call__(self, tool_input: 'str', callbacks: 'Callbacks' = None) -> 'str'\n",
      "     |      Make tool callable.\n",
      "     |  \n",
      "     |  async arun(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool asynchronously.\n",
      "     |  \n",
      "     |  run(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  raise_deprecation(values: 'Dict') -> 'Dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  args\n",
      "     |  \n",
      "     |  is_single_input\n",
      "     |      Whether the tool only accepts a single input.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.tools.base.BaseTool.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __init__(__pydantic_self__, **data: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  dict(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> 'DictStrAny'\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class StructuredTool(BaseTool)\n",
      "     |  StructuredTool(*, name: str, description: str = '', args_schema: Type[pydantic.main.BaseModel], return_direct: bool = False, verbose: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, handle_tool_error: Union[bool, str, Callable[[langchain.tools.base.ToolException], str], NoneType] = False, func: Callable[..., Any], coroutine: Optional[Callable[..., Awaitable[Any]]] = None) -> None\n",
      "     |  \n",
      "     |  Tool that can operate on any number of inputs.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      StructuredTool\n",
      "     |      BaseTool\n",
      "     |      abc.ABC\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  from_function(func: 'Callable', name: 'Optional[str]' = None, description: 'Optional[str]' = None, return_direct: 'bool' = False, args_schema: 'Optional[Type[BaseModel]]' = None, infer_schema: 'bool' = True, **kwargs: 'Any') -> 'StructuredTool' from langchain.tools.base.ToolMetaclass\n",
      "     |      Create tool from a given function.\n",
      "     |      \n",
      "     |      A classmethod that helps to create a tool from a function.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          func: The function from which to create a tool\n",
      "     |          name: The name of the tool. Defaults to the function name\n",
      "     |          description: The description of the tool. Defaults to the function docstring\n",
      "     |          return_direct: Whether to return the result directly or as a callback\n",
      "     |          args_schema: The schema of the tool's input arguments\n",
      "     |          infer_schema: Whether to infer the schema from the function's signature\n",
      "     |          **kwargs: Additional arguments to pass to the tool\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The tool\n",
      "     |      \n",
      "     |      Examples:\n",
      "     |          ... code-block:: python\n",
      "     |              def add(a: int, b: int) -> int:\n",
      "     |                  \"\"\"Add two numbers\"\"\"\n",
      "     |                  return a + b\n",
      "     |              tool = StructuredTool.from_function(add)\n",
      "     |              tool.run(1, 2) # 3\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  args\n",
      "     |      The tool's input arguments.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'args_schema': 'Type[BaseModel]', 'coroutine': 'Opt...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.tools.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'args_schema': ModelField(name='args_schema', type=Type[...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function BaseTool.raise_deprecati...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {}\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, name: str, description: str = '',...l[C...\n",
      "     |  \n",
      "     |  __validators__ = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from BaseTool:\n",
      "     |  \n",
      "     |  __call__(self, tool_input: 'str', callbacks: 'Callbacks' = None) -> 'str'\n",
      "     |      Make tool callable.\n",
      "     |  \n",
      "     |  async arun(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool asynchronously.\n",
      "     |  \n",
      "     |  run(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from BaseTool:\n",
      "     |  \n",
      "     |  raise_deprecation(values: 'Dict') -> 'Dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from BaseTool:\n",
      "     |  \n",
      "     |  is_single_input\n",
      "     |      Whether the tool only accepts a single input.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from BaseTool:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.tools.base.BaseTool.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __init__(__pydantic_self__, **data: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  dict(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> 'DictStrAny'\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class Tool(BaseTool)\n",
      "     |  Tool(name: 'str', func: 'Callable', description: 'str', *, args_schema: Optional[Type[pydantic.main.BaseModel]] = None, return_direct: bool = False, verbose: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, handle_tool_error: Union[bool, str, Callable[[langchain.tools.base.ToolException], str], NoneType] = False, coroutine: Optional[Callable[..., Awaitable[str]]] = None) -> None\n",
      "     |  \n",
      "     |  Tool that takes in function or coroutine directly.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Tool\n",
      "     |      BaseTool\n",
      "     |      abc.ABC\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, name: 'str', func: 'Callable', description: 'str', **kwargs: 'Any') -> 'None'\n",
      "     |      Initialize tool.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  from_function(func: 'Callable', name: 'str', description: 'str', return_direct: 'bool' = False, args_schema: 'Optional[Type[BaseModel]]' = None, **kwargs: 'Any') -> 'Tool' from langchain.tools.base.ToolMetaclass\n",
      "     |      Initialize tool from a function.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  args\n",
      "     |      The tool's input arguments.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'coroutine': 'Optional[Callable[..., Awaitable[str]...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.tools.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'args_schema': ModelField(name='args_schema', type=Optio...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function BaseTool.raise_deprecati...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {}\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (name: 'str', func: 'Callable', descr...l[C...\n",
      "     |  \n",
      "     |  __validators__ = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from BaseTool:\n",
      "     |  \n",
      "     |  __call__(self, tool_input: 'str', callbacks: 'Callbacks' = None) -> 'str'\n",
      "     |      Make tool callable.\n",
      "     |  \n",
      "     |  async arun(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool asynchronously.\n",
      "     |  \n",
      "     |  run(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from BaseTool:\n",
      "     |  \n",
      "     |  raise_deprecation(values: 'Dict') -> 'Dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from BaseTool:\n",
      "     |  \n",
      "     |  is_single_input\n",
      "     |      Whether the tool only accepts a single input.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from BaseTool:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.tools.base.BaseTool.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  dict(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> 'DictStrAny'\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class VectorStoreQATool(BaseVectorStoreTool, langchain.tools.base.BaseTool)\n",
      "     |  VectorStoreQATool(*, name: str, description: str, args_schema: Optional[Type[pydantic.main.BaseModel]] = None, return_direct: bool = False, verbose: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, handle_tool_error: Union[bool, str, Callable[[langchain.tools.base.ToolException], str], NoneType] = False, vectorstore: langchain.vectorstores.base.VectorStore, llm: langchain.base_language.BaseLanguageModel = None) -> None\n",
      "     |  \n",
      "     |  Tool for the VectorDBQA chain. To be initialized with name and chain.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      VectorStoreQATool\n",
      "     |      BaseVectorStoreTool\n",
      "     |      langchain.tools.base.BaseTool\n",
      "     |      abc.ABC\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  get_description(name: str, description: str) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.tools.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True, 've...\n",
      "     |  \n",
      "     |  __fields__ = {'args_schema': ModelField(name='args_schema', type=Optio...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function BaseTool.raise_deprecati...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {}\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, name: str, description: str, args....ba...\n",
      "     |  \n",
      "     |  __validators__ = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from BaseVectorStoreTool:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.tools.vectorstore.tool.BaseVectorStoreTool....\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  __call__(self, tool_input: 'str', callbacks: 'Callbacks' = None) -> 'str'\n",
      "     |      Make tool callable.\n",
      "     |  \n",
      "     |  async arun(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool asynchronously.\n",
      "     |  \n",
      "     |  run(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  raise_deprecation(values: 'Dict') -> 'Dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  args\n",
      "     |  \n",
      "     |  is_single_input\n",
      "     |      Whether the tool only accepts a single input.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __init__(__pydantic_self__, **data: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  dict(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> 'DictStrAny'\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class VectorStoreQAWithSourcesTool(BaseVectorStoreTool, langchain.tools.base.BaseTool)\n",
      "     |  VectorStoreQAWithSourcesTool(*, name: str, description: str, args_schema: Optional[Type[pydantic.main.BaseModel]] = None, return_direct: bool = False, verbose: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, handle_tool_error: Union[bool, str, Callable[[langchain.tools.base.ToolException], str], NoneType] = False, vectorstore: langchain.vectorstores.base.VectorStore, llm: langchain.base_language.BaseLanguageModel = None) -> None\n",
      "     |  \n",
      "     |  Tool for the VectorDBQAWithSources chain.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      VectorStoreQAWithSourcesTool\n",
      "     |      BaseVectorStoreTool\n",
      "     |      langchain.tools.base.BaseTool\n",
      "     |      abc.ABC\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  get_description(name: str, description: str) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.tools.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True, 've...\n",
      "     |  \n",
      "     |  __fields__ = {'args_schema': ModelField(name='args_schema', type=Optio...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function BaseTool.raise_deprecati...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {}\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, name: str, description: str, args....ba...\n",
      "     |  \n",
      "     |  __validators__ = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from BaseVectorStoreTool:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.tools.vectorstore.tool.BaseVectorStoreTool....\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  __call__(self, tool_input: 'str', callbacks: 'Callbacks' = None) -> 'str'\n",
      "     |      Make tool callable.\n",
      "     |  \n",
      "     |  async arun(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool asynchronously.\n",
      "     |  \n",
      "     |  run(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  raise_deprecation(values: 'Dict') -> 'Dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  args\n",
      "     |  \n",
      "     |  is_single_input\n",
      "     |      Whether the tool only accepts a single input.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __init__(__pydantic_self__, **data: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  dict(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> 'DictStrAny'\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class WikipediaQueryRun(langchain.tools.base.BaseTool)\n",
      "     |  WikipediaQueryRun(*, name: str = 'Wikipedia', description: str = 'A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.', args_schema: Optional[Type[pydantic.main.BaseModel]] = None, return_direct: bool = False, verbose: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, handle_tool_error: Union[bool, str, Callable[[langchain.tools.base.ToolException], str], NoneType] = False, api_wrapper: langchain.utilities.wikipedia.WikipediaAPIWrapper) -> None\n",
      "     |  \n",
      "     |  Tool that adds the capability to search using the Wikipedia API.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      WikipediaQueryRun\n",
      "     |      langchain.tools.base.BaseTool\n",
      "     |      abc.ABC\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'api_wrapper': <class 'langchain.utilities.wikipedi...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.tools.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'api_wrapper': ModelField(name='api_wrapper', type=Wikip...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function BaseTool.raise_deprecati...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {}\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, name: str = 'Wikipedia', descript...uti...\n",
      "     |  \n",
      "     |  __validators__ = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  __call__(self, tool_input: 'str', callbacks: 'Callbacks' = None) -> 'str'\n",
      "     |      Make tool callable.\n",
      "     |  \n",
      "     |  async arun(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool asynchronously.\n",
      "     |  \n",
      "     |  run(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  raise_deprecation(values: 'Dict') -> 'Dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  args\n",
      "     |  \n",
      "     |  is_single_input\n",
      "     |      Whether the tool only accepts a single input.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.tools.base.BaseTool.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __init__(__pydantic_self__, **data: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  dict(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> 'DictStrAny'\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class WolframAlphaQueryRun(langchain.tools.base.BaseTool)\n",
      "     |  WolframAlphaQueryRun(*, name: str = 'wolfram_alpha', description: str = 'A wrapper around Wolfram Alpha. Useful for when you need to answer questions about Math, Science, Technology, Culture, Society and Everyday Life. Input should be a search query.', args_schema: Optional[Type[pydantic.main.BaseModel]] = None, return_direct: bool = False, verbose: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, handle_tool_error: Union[bool, str, Callable[[langchain.tools.base.ToolException], str], NoneType] = False, api_wrapper: langchain.utilities.wolfram_alpha.WolframAlphaAPIWrapper) -> None\n",
      "     |  \n",
      "     |  Tool that adds the capability to query using the Wolfram Alpha SDK.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      WolframAlphaQueryRun\n",
      "     |      langchain.tools.base.BaseTool\n",
      "     |      abc.ABC\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'api_wrapper': <class 'langchain.utilities.wolfram_...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.tools.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'api_wrapper': ModelField(name='api_wrapper', type=Wolfr...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function BaseTool.raise_deprecati...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {}\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, name: str = 'wolfram_alpha', desc...es....\n",
      "     |  \n",
      "     |  __validators__ = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  __call__(self, tool_input: 'str', callbacks: 'Callbacks' = None) -> 'str'\n",
      "     |      Make tool callable.\n",
      "     |  \n",
      "     |  async arun(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool asynchronously.\n",
      "     |  \n",
      "     |  run(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  raise_deprecation(values: 'Dict') -> 'Dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  args\n",
      "     |  \n",
      "     |  is_single_input\n",
      "     |      Whether the tool only accepts a single input.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.tools.base.BaseTool.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __init__(__pydantic_self__, **data: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  dict(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> 'DictStrAny'\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class WriteFileTool(langchain.tools.file_management.utils.BaseFileToolMixin, langchain.tools.base.BaseTool)\n",
      "     |  WriteFileTool(*, name: str = 'write_file', description: str = 'Write file to disk', args_schema: Type[pydantic.main.BaseModel] = <class 'langchain.tools.file_management.write.WriteFileInput'>, return_direct: bool = False, verbose: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, handle_tool_error: Union[bool, str, Callable[[langchain.tools.base.ToolException], str], NoneType] = False, root_dir: Optional[str] = None) -> None\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      WriteFileTool\n",
      "     |      langchain.tools.file_management.utils.BaseFileToolMixin\n",
      "     |      langchain.tools.base.BaseTool\n",
      "     |      abc.ABC\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'args_schema': typing.Type[pydantic.main.BaseModel]...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.tools.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'args_schema': ModelField(name='args_schema', type=Type[...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function BaseTool.raise_deprecati...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {}\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, name: str = 'write_file', descrip...= F...\n",
      "     |  \n",
      "     |  __validators__ = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.tools.file_management.utils.BaseFileToolMixin:\n",
      "     |  \n",
      "     |  get_relative_path(self, file_path: str) -> pathlib.Path\n",
      "     |      Get the relative path, returning an error if unsupported.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  __call__(self, tool_input: 'str', callbacks: 'Callbacks' = None) -> 'str'\n",
      "     |      Make tool callable.\n",
      "     |  \n",
      "     |  async arun(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool asynchronously.\n",
      "     |  \n",
      "     |  run(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  raise_deprecation(values: 'Dict') -> 'Dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  args\n",
      "     |  \n",
      "     |  is_single_input\n",
      "     |      Whether the tool only accepts a single input.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.tools.base.BaseTool.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __init__(__pydantic_self__, **data: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  dict(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> 'DictStrAny'\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class YouTubeSearchTool(langchain.tools.base.BaseTool)\n",
      "     |  YouTubeSearchTool(*, name: str = 'youtube_search', description: str = 'search for youtube videos associated with a person. the input to this tool should be a comma separated list, the first part contains a person name and the second a number that is the maximum number of video results to return aka num_results. the second part is optional', args_schema: Optional[Type[pydantic.main.BaseModel]] = None, return_direct: bool = False, verbose: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, handle_tool_error: Union[bool, str, Callable[[langchain.tools.base.ToolException], str], NoneType] = False) -> None\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      YouTubeSearchTool\n",
      "     |      langchain.tools.base.BaseTool\n",
      "     |      abc.ABC\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.tools.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'args_schema': ModelField(name='args_schema', type=Optio...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function BaseTool.raise_deprecati...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {}\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, name: str = 'youtube_search', des...Too...\n",
      "     |  \n",
      "     |  __validators__ = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  __call__(self, tool_input: 'str', callbacks: 'Callbacks' = None) -> 'str'\n",
      "     |      Make tool callable.\n",
      "     |  \n",
      "     |  async arun(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool asynchronously.\n",
      "     |  \n",
      "     |  run(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  raise_deprecation(values: 'Dict') -> 'Dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  args\n",
      "     |  \n",
      "     |  is_single_input\n",
      "     |      Whether the tool only accepts a single input.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.tools.base.BaseTool.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __init__(__pydantic_self__, **data: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  dict(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> 'DictStrAny'\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class ZapierNLAListActions(langchain.tools.base.BaseTool)\n",
      "     |  ZapierNLAListActions(*, name: str = 'ZapierNLA_list_actions', description: str = 'A wrapper around Zapier NLA actions. The input to this tool is a natural language instruction, for example \"get the latest email from my bank\" or \"send a slack message to the #general channel\". Each tool will have params associated with it that are specified as a list. You MUST take into account the params when creating the instruction. For example, if the params are [\\'Message_Text\\', \\'Channel\\'], your instruction should be something like \\'send a slack message to the #general channel with the text hello world\\'. Another example: if the params are [\\'Calendar\\', \\'Search_Term\\'], your instruction should be something like \\'find the meeting in my personal calendar at 3pm\\'. Do not make up params, they will be explicitly specified in the tool description. If you do not have enough information to fill in the params, just say \\'not enough information provided in the instruction, missing <param>\\'. If you get a none or null response, STOP EXECUTION, do not try to another tool!This tool specifically used for: {zapier_description}, and has params: {params}This tool returns a list of the user\\'s exposed actions.', args_schema: Optional[Type[pydantic.main.BaseModel]] = None, return_direct: bool = False, verbose: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, handle_tool_error: Union[bool, str, Callable[[langchain.tools.base.ToolException], str], NoneType] = False, api_wrapper: langchain.utilities.zapier.ZapierNLAWrapper = None) -> None\n",
      "     |  \n",
      "     |  Returns a list of all exposed (enabled) actions associated with\n",
      "     |      current user (associated with the set api_key). Change your exposed\n",
      "     |      actions here: https://nla.zapier.com/demo/start/\n",
      "     |  \n",
      "     |      The return list can be empty if no actions exposed. Else will contain\n",
      "     |      a list of action objects:\n",
      "     |  \n",
      "     |      [{\n",
      "     |          \"id\": str,\n",
      "     |          \"description\": str,\n",
      "     |          \"params\": Dict[str, str]\n",
      "     |      }]\n",
      "     |  \n",
      "     |      `params` will always contain an `instructions` key, the only required\n",
      "     |      param. All others optional and if provided will override any AI guesses\n",
      "     |      (see \"understanding the AI guessing flow\" here:\n",
      "     |      https://nla.zapier.com/api/v1/docs)\n",
      "     |      \n",
      "     |  Args:\n",
      "     |      None\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ZapierNLAListActions\n",
      "     |      langchain.tools.base.BaseTool\n",
      "     |      abc.ABC\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'api_wrapper': <class 'langchain.utilities.zapier.Z...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.tools.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'api_wrapper': ModelField(name='api_wrapper', type=Zapie...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function BaseTool.raise_deprecati...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {}\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, name: str = 'ZapierNLA_list_actio...til...\n",
      "     |  \n",
      "     |  __validators__ = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  __call__(self, tool_input: 'str', callbacks: 'Callbacks' = None) -> 'str'\n",
      "     |      Make tool callable.\n",
      "     |  \n",
      "     |  async arun(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool asynchronously.\n",
      "     |  \n",
      "     |  run(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  raise_deprecation(values: 'Dict') -> 'Dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  args\n",
      "     |  \n",
      "     |  is_single_input\n",
      "     |      Whether the tool only accepts a single input.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.tools.base.BaseTool.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __init__(__pydantic_self__, **data: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  dict(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> 'DictStrAny'\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class ZapierNLARunAction(langchain.tools.base.BaseTool)\n",
      "     |  ZapierNLARunAction(*, name: str = '', description: str = '', args_schema: Optional[Type[pydantic.main.BaseModel]] = None, return_direct: bool = False, verbose: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, handle_tool_error: Union[bool, str, Callable[[langchain.tools.base.ToolException], str], NoneType] = False, api_wrapper: langchain.utilities.zapier.ZapierNLAWrapper = None, action_id: str, params: Optional[dict] = None, base_prompt: str = 'A wrapper around Zapier NLA actions. The input to this tool is a natural language instruction, for example \"get the latest email from my bank\" or \"send a slack message to the #general channel\". Each tool will have params associated with it that are specified as a list. You MUST take into account the params when creating the instruction. For example, if the params are [\\'Message_Text\\', \\'Channel\\'], your instruction should be something like \\'send a slack message to the #general channel with the text hello world\\'. Another example: if the params are [\\'Calendar\\', \\'Search_Term\\'], your instruction should be something like \\'find the meeting in my personal calendar at 3pm\\'. Do not make up params, they will be explicitly specified in the tool description. If you do not have enough information to fill in the params, just say \\'not enough information provided in the instruction, missing <param>\\'. If you get a none or null response, STOP EXECUTION, do not try to another tool!This tool specifically used for: {zapier_description}, and has params: {params}', zapier_description: str, params_schema: Dict[str, str] = None) -> None\n",
      "     |  \n",
      "     |  Executes an action that is identified by action_id, must be exposed\n",
      "     |      (enabled) by the current user (associated with the set api_key). Change\n",
      "     |      your exposed actions here: https://nla.zapier.com/demo/start/\n",
      "     |  \n",
      "     |      The return JSON is guaranteed to be less than ~500 words (350\n",
      "     |      tokens) making it safe to inject into the prompt of another LLM\n",
      "     |      call.\n",
      "     |      \n",
      "     |  Args:\n",
      "     |      action_id: a specific action ID (from list actions) of the action to execute\n",
      "     |          (the set api_key must be associated with the action owner)\n",
      "     |      instructions: a natural language instruction string for using the action\n",
      "     |          (eg. \"get the latest email from Mike Knoop\" for \"Gmail: find email\" action)\n",
      "     |      params: a dict, optional. Any params provided will *override* AI guesses\n",
      "     |          from `instructions` (see \"understanding the AI guessing flow\" here:\n",
      "     |          https://nla.zapier.com/api/v1/docs)\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ZapierNLARunAction\n",
      "     |      langchain.tools.base.BaseTool\n",
      "     |      abc.ABC\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  set_name_description(values: Dict[str, Any]) -> Dict[str, Any] from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'action_id': <class 'str'>, 'api_wrapper': <class '...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.tools.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'action_id': ModelField(name='action_id', type=str, requ...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function BaseTool.raise_deprecati...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {}\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, name: str = '', description: str ...r, ...\n",
      "     |  \n",
      "     |  __validators__ = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  __call__(self, tool_input: 'str', callbacks: 'Callbacks' = None) -> 'str'\n",
      "     |      Make tool callable.\n",
      "     |  \n",
      "     |  async arun(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool asynchronously.\n",
      "     |  \n",
      "     |  run(self, tool_input: 'Union[str, Dict]', verbose: 'Optional[bool]' = None, start_color: 'Optional[str]' = 'green', color: 'Optional[str]' = 'green', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Any'\n",
      "     |      Run the tool.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  raise_deprecation(values: 'Dict') -> 'Dict' from langchain.tools.base.ToolMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  args\n",
      "     |  \n",
      "     |  is_single_input\n",
      "     |      Whether the tool only accepts a single input.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from langchain.tools.base.BaseTool:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.tools.base.BaseTool.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __init__(__pydantic_self__, **data: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  dict(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> 'DictStrAny'\n",
      "     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from langchain.tools.base.ToolMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from langchain.tools.base.ToolMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "\n",
      "FUNCTIONS\n",
      "    StdInInquireTool(*args: Any, **kwargs: Any) -> langchain.tools.human.tool.HumanInputRun\n",
      "        Tool for asking the user for input.\n",
      "    \n",
      "    format_tool_to_openai_function(tool: langchain.tools.base.BaseTool) -> langchain.tools.convert_to_openai.FunctionDescription\n",
      "        Format tool into the OpenAI function API.\n",
      "    \n",
      "    tool(*args: 'Union[str, Callable]', return_direct: 'bool' = False, args_schema: 'Optional[Type[BaseModel]]' = None, infer_schema: 'bool' = True) -> 'Callable'\n",
      "        Make tools out of functions, can be used with or without arguments.\n",
      "        \n",
      "        Args:\n",
      "            *args: The arguments to the tool.\n",
      "            return_direct: Whether to return directly from the tool rather\n",
      "                than continuing the agent loop.\n",
      "            args_schema: optional argument schema for user to specify\n",
      "            infer_schema: Whether to infer the schema of the arguments from\n",
      "                the function's signature. This also makes the resultant tool\n",
      "                accept a dictionary input to its `run()` function.\n",
      "        \n",
      "        Requires:\n",
      "            - Function must be of type (str) -> str\n",
      "            - Function must have a docstring\n",
      "        \n",
      "        Examples:\n",
      "            .. code-block:: python\n",
      "        \n",
      "                @tool\n",
      "                def search_api(query: str) -> str:\n",
      "                    # Searches the API for the query.\n",
      "                    return\n",
      "        \n",
      "                @tool(\"search\", return_direct=True)\n",
      "                def search_api(query: str) -> str:\n",
      "                    # Searches the API for the query.\n",
      "                    return\n",
      "\n",
      "DATA\n",
      "    __all__ = ['AIPluginTool', 'APIOperation', 'ArxivQueryRun', 'AzureCogs...\n",
      "\n",
      "FILE\n",
      "    c:\\users\\dipjyoti\\.conda\\envs\\langchain-webapp\\lib\\site-packages\\langchain\\tools\\__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import langchain.tools as lt\n",
    "help(lt)\n",
    "# if we create an agent it can interact with all the tools below to do specific tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0ad406-2be3-4820-aa1e-c75ddb25617e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# arxiv : what is happening around latest research papers, arxiv query run tool\n",
    "# shell tool : will be doing it in a shell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c67be5b8-73c5-4c69-aa3c-398cc6538c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tool list\n",
    "# we can use multiple tools for multiple tasks\n",
    "papers = ArxivQueryRun()\n",
    "shell = ShellTool()\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"papers\",\n",
    "        func=papers.run,\n",
    "        description=\"useful for when you need to answer about research paper\",\n",
    "\n",
    "        ),\n",
    "    Tool(\n",
    "        name=\"shell\",\n",
    "        func=shell.run,\n",
    "        description =\"useful for shell scripting and related stuff\",\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc62f7e2-a8b6-414e-a095-d9d11d0a9c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Designing a prompt\n",
    "prefix = \"\"\"Have a conversation with a human, answering the following questions as best you can. You have access to the following tools: \"\"\"\n",
    "suffix = \"\"\"Begin!\"\n",
    "\n",
    "{chat_history}\n",
    "Question: {input}\n",
    "{agent_scratchpad}\"\"\"\n",
    "\n",
    "# chat_history : is to provide memory to the agent \n",
    "# input : prompt\n",
    "# agent scratchpad : what the agent is actually doing in the background\n",
    "prompt = ZeroShotAgent.create_prompt(\n",
    "    tools,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=[\"input\", \"chat_history\", \"agent_scratchpad\"],\n",
    "\n",
    ")\n",
    "# ZeroShotAgent : agent which has no examples to learn from the particular tools\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "# provide chat history to the agent, it will remember the response of the previous questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c308c50-6461-495a-bbef-07f037105809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a LLM agent:\n",
    "llm_chain = LLMChain(llm=OpenAI(temperature=0, openai_api_key=api_key), prompt=prompt)\n",
    "agent = ZeroShotAgent(llm_chain=llm_chain, tools=tools, verbose=True)\n",
    "# creating a final chain:\n",
    "agent_chain = AgentExecutor.from_agent_and_tools(\n",
    "    agent= agent, tools=tools, verbose = True, memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "78e5e5de-38b5-4979-bf18-202c7e6992e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I should research the latest developments in LLMs.\n",
      "Action: papers\n",
      "Action Input: Latest developments in LLMs\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mPublished: 2023-10-09\n",
      "Title: A Survey of Large Language Models for Healthcare: from Data, Technology, and Applications to Accountability and Ethics\n",
      "Authors: Kai He, Rui Mao, Qika Lin, Yucheng Ruan, Xiang Lan, Mengling Feng, Erik Cambria\n",
      "Summary: The utilization of large language models (LLMs) in the Healthcare domain has\n",
      "generated both excitement and concern due to their ability to effectively\n",
      "respond to freetext queries with certain professional knowledge. This survey\n",
      "outlines the capabilities of the currently developed LLMs for Healthcare and\n",
      "explicates their development process, with the aim of providing an overview of\n",
      "the development roadmap from traditional Pretrained Language Models (PLMs) to\n",
      "LLMs. Specifically, we first explore the potential of LLMs to enhance the\n",
      "efficiency and effectiveness of various Healthcare applications highlighting\n",
      "both the strengths and limitations. Secondly, we conduct a comparison between\n",
      "the previous PLMs and the latest LLMs, as well as comparing various LLMs with\n",
      "each other. Then we summarize related Healthcare training data, training\n",
      "methods, optimization strategies, and usage. Finally, the unique concerns\n",
      "associated with deploying LLMs in Healthcare settings are investigated,\n",
      "particularly regarding fairness, accountability, transparency and ethics. Our\n",
      "survey provide a comprehensive investigation from perspectives of both computer\n",
      "science and Healthcare specialty. Besides the discussion about Healthcare\n",
      "concerns, we supports the computer science community by compiling a collection\n",
      "of open source resources, such as accessible datasets, the latest\n",
      "methodologies, code implementations, and evaluation benchmarks in the Github.\n",
      "Summarily, we contend that a significant paradigm shift is underway,\n",
      "transitioning from PLMs to LLMs. This shift encompasses a move from\n",
      "discriminative AI approaches to generative AI approaches, as well as a shift\n",
      "from model-centered methodologies to datacentered methodologies.\n",
      "\n",
      "Published: 2023-09-20\n",
      "Title: Safurai 001: New Qualitative Approach for Code LLM Evaluation\n",
      "Authors: Davide Cifarelli, Leonardo Boiardi, Alessandro Puppo\n",
      "Summary: This paper presents Safurai-001, a new Large Language Model (LLM) with\n",
      "significant potential in the domain of coding assistance. Driven by recent\n",
      "advancements in coding LLMs, Safurai-001 competes in performance with the\n",
      "latest models like WizardCoder [Xu et al., 2023], PanguCoder [Shen et al.,\n",
      "2023] and Phi-1 [Gunasekar et al., 2023] but aims to deliver a more\n",
      "conversational interaction. By capitalizing on the progress in data engineering\n",
      "(including latest techniques of data transformation and prompt engineering) and\n",
      "instruction tuning, this new model promises to stand toe-to-toe with recent\n",
      "closed and open source developments. Recognizing the need for an efficacious\n",
      "evaluation metric for coding LLMs, this paper also introduces GPT4-based\n",
      "MultiParameters, an evaluation benchmark that harnesses varied parameters to\n",
      "present a comprehensive insight into the models functioning and performance.\n",
      "Our assessment shows that Safurai-001 can outperform GPT-3.5 by 1.58% and\n",
      "WizardCoder by 18.78% in the Code Readability parameter and more.\n",
      "\n",
      "Published: 2023-09-07\n",
      "Title: Enhancing Pipeline-Based Conversational Agents with Large Language Models\n",
      "Authors: Mina Foosherian, Hendrik Purwins, Purna Rathnayake, Touhidul Alam, Rui Teimao, Klaus-Dieter Thoben\n",
      "Summary: The latest advancements in AI and deep learning have led to a breakthrough in\n",
      "large language model (LLM)-based agents such as GPT-4. However, many commercial\n",
      "conversational agent development tools are pipeline-based and have limitations\n",
      "in holding a human-like conversation. This paper investigates the capabilities\n",
      "of LLMs to enhance pipeline-based conversational agents during two phases: 1)\n",
      "in the design and development phase and 2) during operations. In 1) LLMs can\n",
      "aid in generating training data, extracting entities and synonyms,\n",
      "localization, and persona design. In 2) LLMs can assist in contextu\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: The latest developments in LLMs include a survey of large language models for healthcare, a new qualitative approach for code LLM evaluation, and enhancing pipeline-based conversational agents with large language models.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The latest developments in LLMs include a survey of large language models for healthcare, a new qualitative approach for code LLM evaluation, and enhancing pipeline-based conversational agents with large language models.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_chain.run(input=\"Suggest the latest developments around LLMs?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6980c1-756f-4735-995a-39be8cd4911f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we won't get an answer like this if we use ChatGpt 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83da7239-9bd6-4424-8561-ecae81a62674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the shell tool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e3ceae2b-0b87-4285-af15-6feae0d1b453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to find the code to print 'Hello World' and execute hello.py\n",
      "Action: shell\n",
      "Action Input: echo \"print('Hello World')\" > hello.py followed by python hello.py\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: echo \"print('Hello World')\" > hello.py followed by python hello.py\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'echo \"print(\\'Hello World\\')\" > hello.py followed by python hello.py'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_chain.run(input= \" code to print 'hello world' and execute hello.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81259dd-7330-4d67-9a22-91b98ba0ee8b",
   "metadata": {},
   "source": [
    "#### How to create Custom tools for Langchain Agent ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aefd23a-6db0-427b-aa4a-3e7b30c6f6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install langchain openai langchain-experimental yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f9827cb-3a45-40bd-bf47-1768fd2f8c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "babf752b-9ed7-44c4-abf4-d3cc1d60b8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_stock_price(ticker):\n",
    "    \n",
    "    \"\"\"Method to get current stock price\"\"\"\n",
    "\n",
    "    ticker_data = yf.Ticker(ticker)\n",
    "    recent = ticker_data.history(period=\"1d\")\n",
    "    return {\"price\": recent.iloc[0][\"Close\"], \"currency\": ticker_data.info[\"currency\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "760a1f99-c01b-452d-a7b9-9ad14cb73974",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stock_performance(ticker, days):\n",
    "    \"\"\"Method to get stock price change in percentage\"\"\"\n",
    "    past_date = datetime.today() - timedelta(days=days)\n",
    "    ticker_data = yf.Ticker(ticker)\n",
    "    history = ticker_data.history(start=past_date)\n",
    "    old_price = history.iloc[0][\"Close\"]\n",
    "    current_price = history.iloc[-1][\"Close\"]\n",
    "    return {\"percent_change\" : ((current_price - old_price)/ old_price) * 100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ef8bdee-da78-49b5-b0fb-70194dad7010",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Type\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.tools import BaseTool\n",
    "# for the tool we need two classes - input for the particular tool\n",
    "\n",
    "class CurrentStockPriceInput(BaseModel):\n",
    "    \"\"\"Inputs for get_current_stock_price\"\"\"\n",
    "    ticker: str = Field(description=\"Ticker symbol of the stock\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "289fbef8-1f4e-4902-889f-c8905f36d28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CurrentStockPriceTool(BaseTool):\n",
    "    # inheriting BaseTool which is coming from langchain.tools. So, we are not using an existing tool with LangChain, we are using custom tool\n",
    "    name = \"get_current_stock_price\"\n",
    "    description = \"\"\"\n",
    "        Useful when you want to get current stock price.\n",
    "        You should enter the stock ticker symbol recognized by the yahoo finance\n",
    "        \"\"\"\n",
    "    args_schema: Type[BaseModel] = CurrentStockPriceInput\n",
    "\n",
    "    def _run(self, ticker: str):\n",
    "        price_response = get_current_stock_price(ticker)\n",
    "        return price_response\n",
    "    \n",
    "    def _arun(self, ticker: str):\n",
    "        raise NotImplementedError(\"get_current_stock_price does not support async\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ccfcd79-bc91-47ee-927e-21b7a18ecb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StockPercentChangeInput(BaseModel):\n",
    "    \"\"\"Inputs for get_stock_performance\"\"\"\n",
    "    ticker: str = Field(description=\"Ticker symbol of the stock\")\n",
    "    days: int = Field(description=\"Timedelta days to get past date from current date\")\n",
    "\n",
    "class StockPerformanceTool(BaseTool):\n",
    "    name=\"get_stock_performance\"\"\"\n",
    "    description = \"\"\"\n",
    "        Useful when you want to check performance of the stock.\n",
    "        You should enter the stock ticker symbol recognized by the yahoo finance.\n",
    "        You should enter days as number of days from today from which performance needs to be checked. \n",
    "        output will be the change in the stock price represented as a percentage.\n",
    "        \"\"\"\n",
    "    args_schema: Type[BaseModel] = StockPercentChangeInput\n",
    "\n",
    "    def _run(self, ticker: str, days: int):\n",
    "        response = get_stock_performance(ticker,days)\n",
    "        return response\n",
    "        \n",
    "    def _arun(self, ticker: str):\n",
    "        raise NotImplementedError(\"get_stock_performance does not support async\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4123391c-9a7f-43a4-8d16-e11a6115fec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentType\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.agents import initialize_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "303cc94b-8794-48ab-a420-3562e985a655",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(openai_api_key=api_key)\n",
    "#using the custom tools\n",
    "tools = [CurrentStockPriceTool(), StockPerformanceTool()]\n",
    "agent = initialize_agent(tools, llm, agent=AgentType.OPENAI_FUNCTIONS, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ae36362-9714-45d2-8e96-a3ced414dae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `get_current_stock_price` with `{'ticker': 'MSFT'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m{'price': 329.32000732421875, 'currency': 'USD'}\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `get_stock_performance` with `{'ticker': 'MSFT', 'days': 180}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m{'percent_change': 11.974368403663815}\u001b[0m\u001b[32;1m\u001b[1;3mThe current price of Microsoft stock is $329.32 USD. \n",
      "\n",
      "Over the past 6 months, Microsoft stock has performed well with a 11.97% increase in its price.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The current price of Microsoft stock is $329.32 USD. \\n\\nOver the past 6 months, Microsoft stock has performed well with a 11.97% increase in its price.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"What is the current price of Microsoft stock? How it has performed over past 6 months?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130792f9-668d-459e-ad0e-66043c63f072",
   "metadata": {},
   "source": [
    "#### Callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007e2f0b-56a1-4ec6-b804-a28262a2e3b7",
   "metadata": {},
   "source": [
    "LangChain offers a callback system enabling us to integrate with different phases of our Language Model application, serving purposes such as logging, monitoring, streaming, and other essential functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ab75c47-83fa-4668-8094-b8cd4dca5dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks import StdOutCallbackHandler\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b8f9b70-3be3-412e-bf50-3f2462f4441c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code snippet explains how to log every event using the Standard Output callback\n",
    "handler = StdOutCallbackHandler()\n",
    "llm = OpenAI()\n",
    "prompt = PromptTemplate.from_template(\"Write {number} lines about {animal} \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "819ca3d6-0007-47fa-83f4-b10619f8d4bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite 3 lines about tiger \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\n1. Tigers are the biggest species of cats in the world. \\n2. They are native to Asia and are known for their striped coats. \\n3. Tigers are apex predators, relying on their strength and power to hunt and survive.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Constructor callback: First, let's explicitly set the StdOutCallbackHandler when initializing our chain\n",
    "chain = LLMChain(llm=llm, prompt=prompt, callbacks=[handler])\n",
    "chain.run(number=3,animal='tiger')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa78eec2-78b2-4840-9a50-4a9c945e46ef",
   "metadata": {},
   "source": [
    "#### End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
